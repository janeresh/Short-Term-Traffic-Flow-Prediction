{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from tensorflow.contrib.rnn import RNNCell\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "#import matplotlib.pyplot as plt\n",
    "import time\n",
    "time_start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of Dataset-SZ Traffic\n",
    "def load_sz_data():\n",
    "    sz_adj = pd.read_csv('sz_adj.csv',header=None)\n",
    "    adj = np.mat(sz_adj)\n",
    "    sz_tf = pd.read_csv('sz_speed.csv')\n",
    "    return sz_tf, adj\n",
    "\n",
    "data, adj = load_sz_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2976, 156)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "time_len=data.shape[0] # Time sequence length\n",
    "num_nodes=data.shape[1] #Number of Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the variables\n",
    "output_dim=pre_len=2\n",
    "seq_len=4\n",
    "num_units=64\n",
    "train_rate=0.8\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0980221  0.21353212 0.23823702 ... 0.19194394 0.37707424 0.        ]\n",
      " [0.09032986 0.18181142 0.31845367 ... 0.45834997 0.37705195 0.        ]\n",
      " [0.10192686 0.10389599 0.23464748 ... 0.3856561  0.43354756 0.        ]\n",
      " ...\n",
      " [0.37947276 0.141638   0.10453826 ... 0.13605069 0.1998609  0.        ]\n",
      " [0.39722532 0.18600048 0.121989   ... 0.16306393 0.16957766 0.        ]\n",
      " [0.38101357 0.14001252 0.10420388 ... 0.19054307 0.1845446  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Normalization : Traffic Speed Data\n",
    "\n",
    "data1 =np.mat(data,dtype=np.float32)\n",
    "\n",
    "max_value = np.max(data1)\n",
    "data1  = data1/max_value\n",
    "print(data1)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 156) -----> (596, 156)\n",
      "Train Test Split Details :\n",
      "Train x ---->  2375\n",
      "Train y ---->  2375\n",
      "(2375, 4, 156)\n",
      "Test x ---->  591\n",
      "Test y ---->  591\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data, time_len, rate, seq_len, pre_len):\n",
    "    train_size = int(time_len * rate) #2976 *0.8 =2380\n",
    "    train_data = data[0:train_size] #  [0:2380]\n",
    "    test_data = data[train_size:time_len] #[2380:2976]\n",
    "    print(train_data.shape,'----->',test_data.shape)\n",
    "\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(train_data) - seq_len - pre_len): #(2380-4-1)=2375\n",
    "        a = train_data[i: i + seq_len + pre_len] #[0:0+4+1] \n",
    "        trainX.append(a[0 : seq_len]) #a[0:4] 4 time * 156 roads\n",
    "        trainY.append(a[seq_len : seq_len + pre_len]) #a[4:4+1] 1 time*156 \n",
    "    for i in range(len(test_data) - seq_len -pre_len):\n",
    "        b = test_data[i: i + seq_len + pre_len]\n",
    "        testX.append(b[0 : seq_len])\n",
    "        testY.append(b[seq_len : seq_len + pre_len])\n",
    "      \n",
    "    trainX1 = np.array(trainX) \n",
    "    trainY1 = np.array(trainY)\n",
    "    testX1 = np.array(testX)\n",
    "    testY1 = np.array(testY)\n",
    "    return trainX1, trainY1, testX1, testY1\n",
    "\n",
    "trainX, trainY, testX, testY = preprocess_data(data1, time_len, train_rate, seq_len, pre_len)\n",
    "\n",
    "totalbatch = int(trainX.shape[0]/batch_size)\n",
    "training_data_count = len(trainX)  \n",
    "print('Train Test Split Details :')\n",
    "print('Train x ----> ',len(trainX))\n",
    "print('Train y ----> ',len(trainY))\n",
    "print(trainX.shape)\n",
    "print('Test x ----> ',len(testX))\n",
    "print('Test y ----> ',len(testY))\n",
    "#print('\\nTrain Sample Details :')\n",
    "#print(trainX[0],'--->',trainY[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
    "        init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "        initial = tf.random_uniform([input_dim, output_dim], minval=-init_range, maxval=init_range, dtype=tf.float32)\n",
    "        return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stgcnCell(RNNCell):\n",
    "    \"\"\"Temporal Graph Convolutional Network \"\"\"\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __init__(self, num_units, adj, num_nodes, input_size=None,\n",
    "                 act=tf.nn.tanh, reuse=None):\n",
    "\n",
    "        super(stgcnCell, self).__init__(_reuse=reuse)\n",
    "        self._act = act\n",
    "        self._nodes = num_nodes\n",
    "        self._units = num_units\n",
    "        self._adj = []\n",
    "        self._adj.append(self.calculate_laplacian(adj))\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_sparse_matrix(L):\n",
    "        L = L.tocoo()\n",
    "        indices = np.column_stack((L.row, L.col))\n",
    "        L = tf.SparseTensor(indices, L.data, L.shape)\n",
    "        return tf.sparse_reorder(L)\n",
    "\n",
    "    def calculate_laplacian(self,adj, lambda_max=1):  \n",
    "        adj = self.normalized_adj(adj + sp.eye(adj.shape[0])) # normalisation(self identity matrix + adj)\n",
    "        adj = sp.csr_matrix(adj) #compressed sparse matrix\n",
    "        adj = adj.astype(np.float32)\n",
    "        return self.sparse_to_tuple(adj)\n",
    "    \n",
    "    def normalized_adj(self,adj):\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        degree = np.array(adj.sum(1)) # Degree Matrix row wise sum\n",
    "        d_inv_sqrt = np.power(degree, -0.5).flatten() # D inv = Degree ^-0.5 \n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt) #substitution of the 1D array degree in a 2D matrix diagonals\n",
    "        normalized_adj = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo() # norm= D^-0.5 * adj * D^-0.5\n",
    "        normalized_adj = normalized_adj.astype(np.float32) \n",
    "        return normalized_adj\n",
    "    \n",
    "    def sparse_to_tuple(self,mx):\n",
    "        mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose() #coordinate stacking row and column wise and transpose\n",
    "        L = tf.SparseTensor(coords, mx.data, mx.shape) # mx.shape= (156,156)\n",
    "        #print('shape ---->',mx.shape)\n",
    "        return tf.sparse_reorder(L) #row major ordering\n",
    "        \n",
    "    def init_state(self,batch_size):       \n",
    "        state = tf.zeros(shape=[batch_size, self._num_nodes*self._num_units], dtype=tf.float32)\n",
    "        return state  \n",
    "               \n",
    "    @staticmethod\n",
    "    def _concat(x, x_):\n",
    "        x_ = tf.expand_dims(x_, 0)\n",
    "        return tf.concat([x, x_], axis=0)   \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._nodes * self._units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "\n",
    "        with tf.variable_scope(scope or \"tgcn\"):\n",
    "            with tf.variable_scope(\"gates\"):  \n",
    "                value = tf.nn.sigmoid(\n",
    "                    self._gc(inputs, state, 2 * self._units, bias=1.0, scope=scope)) #ut (or) rt = sigma(Wu [f(A;Xt); h{t-1}] + bu)\n",
    "                r, u = tf.split(value=value, num_or_size_splits=2, axis=1)\n",
    "            with tf.variable_scope(\"candidate\"):\n",
    "                r_state = r * state #r* h{t-1}\n",
    "                c = self._act(self._gc(inputs, r_state, self._units, scope=scope))#ct = tanh(Wc [f(A;Xt); r_state] + bc) \n",
    "            new_h = u * state + (1 - u) * c #ht = ut * h{t-1} + (1 - u{t}) * ct\n",
    "        return new_h, new_h\n",
    "\n",
    "\n",
    "    def _gc(self, inputs, state, output_size, bias=0.0, scope=None):\n",
    "        ## inputs:(-1,num_nodes)\n",
    "        inputs = tf.expand_dims(inputs, 2)#None,156,None\n",
    "        ## state:(batch,num_node,gru_units)\n",
    "        state = tf.reshape(state, (-1, self._nodes, self._units)) #32,156,64\n",
    "        ## concat\n",
    "        x_s = tf.concat([inputs, state], axis=2) #32,156,65\n",
    "        input_size = x_s.get_shape()[2].value #65\n",
    "        ## (num_node,input_size,-1)\n",
    "        x0 = tf.transpose(x_s, perm=[1, 2, 0]) #156,65,32\n",
    "        x0 = tf.reshape(x0, shape=[self._nodes, -1]) #156,65*32\n",
    "        scope = tf.get_variable_scope()\n",
    "        with tf.variable_scope(scope):\n",
    "            for m in self._adj:#1,156\n",
    "                x1 = tf.sparse_tensor_dense_matmul(m, x0) #1,65*32\n",
    "#                print(x1)\n",
    "            x = tf.reshape(x1, shape=[self._nodes, input_size,-1]) #156,65,32\n",
    "            x = tf.transpose(x,perm=[2,0,1]) #32,156,65\n",
    "            x = tf.reshape(x, shape=[-1, input_size]) #156*32,65\n",
    "            weights = tf.get_variable( # 65,64\n",
    "                'weights', [input_size, output_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            x = tf.matmul(x, weights)  # (batch_size * self._nodes, output_size) \n",
    "            biases = tf.get_variable( #64\n",
    "                \"biases\", [output_size], initializer=tf.constant_initializer(bias, dtype=tf.float32))\n",
    "            x = tf.nn.bias_add(x, biases) #biases added\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes, output_size]) #32,156,64\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes * output_size])#32,156*64\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STGCN(_X, _weights, _biases):\n",
    "    ###\n",
    "    cell_1 = stgcnCell(num_units, adj, num_nodes=num_nodes)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([cell_1], state_is_tuple=True) #stack rnn cells\n",
    "    _X = tf.unstack(_X, axis=1) # 4 tensorflow arrays of shape None,156 (seq_len=4)\n",
    "    outputs, states = tf.nn.static_rnn(cell, _X, dtype=tf.float32) #Creates a recurrent neural network specified by RNNCell cell\n",
    "    #4 ouputs and 1 state None,9984(156*64)\n",
    "    m = []\n",
    "    for i in outputs:\n",
    "        o = tf.reshape(i,shape=[-1,num_nodes,num_units])#None,156,64\n",
    "        o = tf.reshape(o,shape=[-1,num_units])#None*156,64\n",
    "        m.append(o) #4 objects\n",
    "    last_output = m[-1] #last one\n",
    "    output = tf.matmul(last_output, _weights['out']) + _biases['out'] #multiply with weights and add bias None*156,1+len(1)=156,1\n",
    "    output = tf.reshape(output,shape=[-1,num_nodes,pre_len]) # None,156,1\n",
    "    output = tf.transpose(output, perm=[0,2,1])#None,1,156\n",
    "    output = tf.reshape(output, shape=[-1,num_nodes]) #None*1,156\n",
    "    return output, m, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Lema Labs ML Workshop x64\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "WARNING:tensorflow:From <ipython-input-9-dfd1196d70e3>:4: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-dfd1196d70e3>:6: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=[None, seq_len, num_nodes])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, pre_len, num_nodes])\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_units, pre_len], mean=1.0), name='weight_o')} #64,1\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([pre_len]),name='bias_o')} #1\n",
    "print(type(inputs))\n",
    "pred,ttts,ttto = STGCN(inputs, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_loss = 0.0015\n",
    "Lreg = lambda_loss * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "label = tf.reshape(labels, [-1,num_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.l2_loss(y_pred-label) + Lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = tf.sqrt(tf.reduce_mean(tf.square(y_pred-label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tf.global_variables()\n",
    "training_epoch=675\n",
    "saver = tf.train.Saver(tf.global_variables()) #\n",
    "#sess = tf.Session()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "out = 'out/%s'%(\"STGCN\")\n",
    "#out = 'out/%s_%s'%(model_name,'perturbation')\n",
    "path1 = '%s_%s_lr%r_batch%r_unit%r_seq%r_pre%r_epoch%r'%(\"STGCN\",\"sz\",lr,batch_size,num_units,seq_len,pre_len,training_epoch)\n",
    "path = os.path.join(out,path1)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(a,b):\n",
    "    rmse = math.sqrt(mean_squared_error(a,b))\n",
    "    mae = mean_absolute_error(a, b)\n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    r2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\n",
    "    var = 1-(np.var(a-b))/np.var(a)\n",
    "    return rmse, mae, 1-F_norm, r2, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axe,batch_loss,batch_rmse,batch_pred = [], [], [], []\n",
    "test_loss,test_rmse,test_mae,test_acc,test_r2,test_var,test_pred = [],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(a,b):  \n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    train_acc=1-F_norm\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy ---->  0.5841507613658905\n",
      "Iter:0 train_rmse:6.001 test_loss:248.3 test_rmse:0.07334 test_acc:0.5585\n",
      "Epoch  1\n",
      "Accuracy ---->  0.5971542000770569\n",
      "Iter:1 train_rmse:5.813 test_loss:238.6 test_rmse:0.0719 test_acc:0.5672\n",
      "Epoch  2\n",
      "Accuracy ---->  0.600890576839447\n",
      "Iter:2 train_rmse:5.759 test_loss:233.8 test_rmse:0.07117 test_acc:0.5715\n",
      "Epoch  3\n",
      "Accuracy ---->  0.6040544211864471\n",
      "Iter:3 train_rmse:5.714 test_loss:229.8 test_rmse:0.07055 test_acc:0.5752\n",
      "Epoch  4\n",
      "Accuracy ---->  0.6067211627960205\n",
      "Iter:4 train_rmse:5.675 test_loss:226.4 test_rmse:0.07003 test_acc:0.5784\n",
      "Epoch  5\n",
      "Accuracy ---->  0.6090414822101593\n",
      "Iter:5 train_rmse:5.642 test_loss:223.5 test_rmse:0.06957 test_acc:0.5811\n",
      "Epoch  6\n",
      "Accuracy ---->  0.6110879182815552\n",
      "Iter:6 train_rmse:5.612 test_loss:221.0 test_rmse:0.06919 test_acc:0.5835\n",
      "Epoch  7\n",
      "Accuracy ---->  0.6128761768341064\n",
      "Iter:7 train_rmse:5.586 test_loss:218.9 test_rmse:0.06885 test_acc:0.5855\n",
      "Epoch  8\n",
      "Accuracy ---->  0.6144394278526306\n",
      "Iter:8 train_rmse:5.564 test_loss:217.0 test_rmse:0.06856 test_acc:0.5872\n",
      "Epoch  9\n",
      "Accuracy ---->  0.6158320009708405\n",
      "Iter:9 train_rmse:5.544 test_loss:215.4 test_rmse:0.0683 test_acc:0.5888\n",
      "Epoch  10\n",
      "Accuracy ---->  0.6171019375324249\n",
      "Iter:10 train_rmse:5.525 test_loss:213.9 test_rmse:0.06806 test_acc:0.5902\n",
      "Epoch  11\n",
      "Accuracy ---->  0.6182843446731567\n",
      "Iter:11 train_rmse:5.508 test_loss:212.5 test_rmse:0.06785 test_acc:0.5915\n",
      "Epoch  12\n",
      "Accuracy ---->  0.6194072365760803\n",
      "Iter:12 train_rmse:5.492 test_loss:211.3 test_rmse:0.06765 test_acc:0.5927\n",
      "Epoch  13\n",
      "Accuracy ---->  0.6204875707626343\n",
      "Iter:13 train_rmse:5.477 test_loss:210.2 test_rmse:0.06747 test_acc:0.5938\n",
      "Epoch  14\n",
      "Accuracy ---->  0.6215230226516724\n",
      "Iter:14 train_rmse:5.462 test_loss:209.1 test_rmse:0.0673 test_acc:0.5948\n",
      "Epoch  15\n",
      "Accuracy ---->  0.6225031316280365\n",
      "Iter:15 train_rmse:5.448 test_loss:208.2 test_rmse:0.06715 test_acc:0.5957\n",
      "Epoch  16\n",
      "Accuracy ---->  0.6234243214130402\n",
      "Iter:16 train_rmse:5.434 test_loss:207.3 test_rmse:0.06701 test_acc:0.5966\n",
      "Epoch  17\n",
      "Accuracy ---->  0.6242942214012146\n",
      "Iter:17 train_rmse:5.422 test_loss:206.6 test_rmse:0.06689 test_acc:0.5973\n",
      "Epoch  18\n",
      "Accuracy ---->  0.6251200437545776\n",
      "Iter:18 train_rmse:5.41 test_loss:205.9 test_rmse:0.06678 test_acc:0.598\n",
      "Epoch  19\n",
      "Accuracy ---->  0.6258913576602936\n",
      "Iter:19 train_rmse:5.399 test_loss:205.3 test_rmse:0.06668 test_acc:0.5985\n",
      "Epoch  20\n",
      "Accuracy ---->  0.6265996098518372\n",
      "Iter:20 train_rmse:5.388 test_loss:204.8 test_rmse:0.0666 test_acc:0.599\n",
      "Epoch  21\n",
      "Accuracy ---->  0.627251535654068\n",
      "Iter:21 train_rmse:5.379 test_loss:204.3 test_rmse:0.06652 test_acc:0.5995\n",
      "Epoch  22\n",
      "Accuracy ---->  0.6278571486473083\n",
      "Iter:22 train_rmse:5.37 test_loss:203.9 test_rmse:0.06645 test_acc:0.5999\n",
      "Epoch  23\n",
      "Accuracy ---->  0.6284250319004059\n",
      "Iter:23 train_rmse:5.362 test_loss:203.5 test_rmse:0.06639 test_acc:0.6003\n",
      "Epoch  24\n",
      "Accuracy ---->  0.6289635598659515\n",
      "Iter:24 train_rmse:5.354 test_loss:203.1 test_rmse:0.06633 test_acc:0.6007\n",
      "Epoch  25\n",
      "Accuracy ---->  0.6294800043106079\n",
      "Iter:25 train_rmse:5.347 test_loss:202.8 test_rmse:0.06627 test_acc:0.601\n",
      "Epoch  26\n",
      "Accuracy ---->  0.6299823522567749\n",
      "Iter:26 train_rmse:5.34 test_loss:202.4 test_rmse:0.06622 test_acc:0.6014\n",
      "Epoch  27\n",
      "Accuracy ---->  0.6304810345172882\n",
      "Iter:27 train_rmse:5.332 test_loss:202.1 test_rmse:0.06616 test_acc:0.6017\n",
      "Epoch  28\n",
      "Accuracy ---->  0.6309792697429657\n",
      "Iter:28 train_rmse:5.325 test_loss:201.8 test_rmse:0.06611 test_acc:0.602\n",
      "Epoch  29\n",
      "Accuracy ---->  0.6314654052257538\n",
      "Iter:29 train_rmse:5.318 test_loss:201.5 test_rmse:0.06607 test_acc:0.6023\n",
      "Epoch  30\n",
      "Accuracy ---->  0.6319297254085541\n",
      "Iter:30 train_rmse:5.312 test_loss:201.2 test_rmse:0.06602 test_acc:0.6025\n",
      "Epoch  31\n",
      "Accuracy ---->  0.6323708295822144\n",
      "Iter:31 train_rmse:5.305 test_loss:200.9 test_rmse:0.06597 test_acc:0.6028\n",
      "Epoch  32\n",
      "Accuracy ---->  0.6327876150608063\n",
      "Iter:32 train_rmse:5.299 test_loss:200.7 test_rmse:0.06593 test_acc:0.6031\n",
      "Epoch  33\n",
      "Accuracy ---->  0.6331804394721985\n",
      "Iter:33 train_rmse:5.293 test_loss:200.4 test_rmse:0.06589 test_acc:0.6033\n",
      "Epoch  34\n",
      "Accuracy ---->  0.6335575878620148\n",
      "Iter:34 train_rmse:5.288 test_loss:200.2 test_rmse:0.06585 test_acc:0.6036\n",
      "Epoch  35\n",
      "Accuracy ---->  0.6339296400547028\n",
      "Iter:35 train_rmse:5.283 test_loss:200.0 test_rmse:0.06581 test_acc:0.6038\n",
      "Epoch  36\n",
      "Accuracy ---->  0.6343013346195221\n",
      "Iter:36 train_rmse:5.277 test_loss:199.7 test_rmse:0.06577 test_acc:0.604\n",
      "Epoch  37\n",
      "Accuracy ---->  0.6346719563007355\n",
      "Iter:37 train_rmse:5.272 test_loss:199.5 test_rmse:0.06574 test_acc:0.6042\n",
      "Epoch  38\n",
      "Accuracy ---->  0.6350309550762177\n",
      "Iter:38 train_rmse:5.267 test_loss:199.3 test_rmse:0.0657 test_acc:0.6044\n",
      "Epoch  39\n",
      "Accuracy ---->  0.63536736369133\n",
      "Iter:39 train_rmse:5.262 test_loss:199.1 test_rmse:0.06567 test_acc:0.6046\n",
      "Epoch  40\n",
      "Accuracy ---->  0.6356793344020844\n",
      "Iter:40 train_rmse:5.257 test_loss:198.9 test_rmse:0.06563 test_acc:0.6049\n",
      "Epoch  41\n",
      "Accuracy ---->  0.63596510887146\n",
      "Iter:41 train_rmse:5.253 test_loss:198.7 test_rmse:0.0656 test_acc:0.6051\n",
      "Epoch  42\n",
      "Accuracy ---->  0.6362221539020538\n",
      "Iter:42 train_rmse:5.25 test_loss:198.5 test_rmse:0.06557 test_acc:0.6052\n",
      "Epoch  43\n",
      "Accuracy ---->  0.6364652812480927\n",
      "Iter:43 train_rmse:5.246 test_loss:198.3 test_rmse:0.06554 test_acc:0.6054\n",
      "Epoch  44\n",
      "Accuracy ---->  0.6367242932319641\n",
      "Iter:44 train_rmse:5.242 test_loss:198.1 test_rmse:0.06551 test_acc:0.6056\n",
      "Epoch  45\n",
      "Accuracy ---->  0.6369992792606354\n",
      "Iter:45 train_rmse:5.238 test_loss:198.0 test_rmse:0.06548 test_acc:0.6058\n",
      "Epoch  46\n",
      "Accuracy ---->  0.6372694075107574\n",
      "Iter:46 train_rmse:5.234 test_loss:197.8 test_rmse:0.06545 test_acc:0.606\n",
      "Epoch  47\n",
      "Accuracy ---->  0.6375202536582947\n",
      "Iter:47 train_rmse:5.231 test_loss:197.6 test_rmse:0.06542 test_acc:0.6061\n",
      "Epoch  48\n",
      "Accuracy ---->  0.6377512812614441\n",
      "Iter:48 train_rmse:5.227 test_loss:197.4 test_rmse:0.06539 test_acc:0.6063\n",
      "Epoch  49\n",
      "Accuracy ---->  0.6379721760749817\n",
      "Iter:49 train_rmse:5.224 test_loss:197.3 test_rmse:0.06536 test_acc:0.6065\n",
      "Epoch  50\n",
      "Accuracy ---->  0.6381880640983582\n",
      "Iter:50 train_rmse:5.221 test_loss:197.1 test_rmse:0.06533 test_acc:0.6067\n",
      "Epoch  51\n",
      "Accuracy ---->  0.6383974850177765\n",
      "Iter:51 train_rmse:5.218 test_loss:196.9 test_rmse:0.0653 test_acc:0.6068\n",
      "Epoch  52\n",
      "Accuracy ---->  0.6386075615882874\n",
      "Iter:52 train_rmse:5.215 test_loss:196.7 test_rmse:0.06527 test_acc:0.607\n",
      "Epoch  53\n",
      "Accuracy ---->  0.6388366520404816\n",
      "Iter:53 train_rmse:5.212 test_loss:196.6 test_rmse:0.06525 test_acc:0.6072\n",
      "Epoch  54\n",
      "Accuracy ---->  0.6390833854675293\n",
      "Iter:54 train_rmse:5.208 test_loss:196.4 test_rmse:0.06522 test_acc:0.6073\n",
      "Epoch  55\n",
      "Accuracy ---->  0.6393225491046906\n",
      "Iter:55 train_rmse:5.205 test_loss:196.2 test_rmse:0.06519 test_acc:0.6075\n",
      "Epoch  56\n",
      "Accuracy ---->  0.6395489275455475\n",
      "Iter:56 train_rmse:5.202 test_loss:196.0 test_rmse:0.06515 test_acc:0.6077\n",
      "Epoch  57\n",
      "Accuracy ---->  0.6397903859615326\n",
      "Iter:57 train_rmse:5.198 test_loss:195.7 test_rmse:0.06511 test_acc:0.608\n",
      "Epoch  58\n",
      "Accuracy ---->  0.6400441825389862\n",
      "Iter:58 train_rmse:5.194 test_loss:195.5 test_rmse:0.06507 test_acc:0.6083\n",
      "Epoch  59\n",
      "Accuracy ---->  0.6402819156646729\n",
      "Iter:59 train_rmse:5.191 test_loss:195.3 test_rmse:0.06503 test_acc:0.6085\n",
      "Epoch  60\n",
      "Accuracy ---->  0.6405332088470459\n",
      "Iter:60 train_rmse:5.187 test_loss:195.0 test_rmse:0.06499 test_acc:0.6087\n",
      "Epoch  61\n",
      "Accuracy ---->  0.6408429443836212\n",
      "Iter:61 train_rmse:5.183 test_loss:194.8 test_rmse:0.06496 test_acc:0.6089\n",
      "Epoch  62\n",
      "Accuracy ---->  0.6411645114421844\n",
      "Iter:62 train_rmse:5.178 test_loss:194.6 test_rmse:0.06492 test_acc:0.6092\n",
      "Epoch  63\n",
      "Accuracy ---->  0.641461580991745\n",
      "Iter:63 train_rmse:5.174 test_loss:194.3 test_rmse:0.06487 test_acc:0.6094\n",
      "Epoch  64\n",
      "Accuracy ---->  0.6417669057846069\n",
      "Iter:64 train_rmse:5.17 test_loss:194.0 test_rmse:0.06482 test_acc:0.6098\n",
      "Epoch  65\n",
      "Accuracy ---->  0.6421032845973969\n",
      "Iter:65 train_rmse:5.165 test_loss:193.7 test_rmse:0.06477 test_acc:0.6101\n",
      "Epoch  66\n",
      "Accuracy ---->  0.6424293518066406\n",
      "Iter:66 train_rmse:5.16 test_loss:193.4 test_rmse:0.06472 test_acc:0.6104\n",
      "Epoch  67\n",
      "Accuracy ---->  0.642768532037735\n",
      "Iter:67 train_rmse:5.155 test_loss:193.1 test_rmse:0.06467 test_acc:0.6107\n",
      "Epoch  68\n",
      "Accuracy ---->  0.6431220769882202\n",
      "Iter:68 train_rmse:5.15 test_loss:192.8 test_rmse:0.06462 test_acc:0.611\n",
      "Epoch  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6434734165668488\n",
      "Iter:69 train_rmse:5.145 test_loss:192.5 test_rmse:0.06456 test_acc:0.6113\n",
      "Epoch  70\n",
      "Accuracy ---->  0.6438254415988922\n",
      "Iter:70 train_rmse:5.14 test_loss:192.2 test_rmse:0.06451 test_acc:0.6116\n",
      "Epoch  71\n",
      "Accuracy ---->  0.6441767513751984\n",
      "Iter:71 train_rmse:5.135 test_loss:191.9 test_rmse:0.06445 test_acc:0.612\n",
      "Epoch  72\n",
      "Accuracy ---->  0.6445198953151703\n",
      "Iter:72 train_rmse:5.13 test_loss:191.5 test_rmse:0.0644 test_acc:0.6123\n",
      "Epoch  73\n",
      "Accuracy ---->  0.6448730826377869\n",
      "Iter:73 train_rmse:5.125 test_loss:191.2 test_rmse:0.06434 test_acc:0.6126\n",
      "Epoch  74\n",
      "Accuracy ---->  0.6452615559101105\n",
      "Iter:74 train_rmse:5.119 test_loss:190.9 test_rmse:0.06429 test_acc:0.613\n",
      "Epoch  75\n",
      "Accuracy ---->  0.6456575989723206\n",
      "Iter:75 train_rmse:5.113 test_loss:190.5 test_rmse:0.06423 test_acc:0.6133\n",
      "Epoch  76\n",
      "Accuracy ---->  0.6460438668727875\n",
      "Iter:76 train_rmse:5.108 test_loss:190.2 test_rmse:0.06417 test_acc:0.6137\n",
      "Epoch  77\n",
      "Accuracy ---->  0.6464333832263947\n",
      "Iter:77 train_rmse:5.102 test_loss:189.8 test_rmse:0.0641 test_acc:0.6141\n",
      "Epoch  78\n",
      "Accuracy ---->  0.6468393206596375\n",
      "Iter:78 train_rmse:5.096 test_loss:189.4 test_rmse:0.06404 test_acc:0.6144\n",
      "Epoch  79\n",
      "Accuracy ---->  0.6472629010677338\n",
      "Iter:79 train_rmse:5.09 test_loss:189.1 test_rmse:0.06398 test_acc:0.6148\n",
      "Epoch  80\n",
      "Accuracy ---->  0.6477023959159851\n",
      "Iter:80 train_rmse:5.084 test_loss:188.7 test_rmse:0.06391 test_acc:0.6152\n",
      "Epoch  81\n",
      "Accuracy ---->  0.6481590569019318\n",
      "Iter:81 train_rmse:5.077 test_loss:188.3 test_rmse:0.06385 test_acc:0.6156\n",
      "Epoch  82\n",
      "Accuracy ---->  0.6486354172229767\n",
      "Iter:82 train_rmse:5.07 test_loss:187.9 test_rmse:0.06378 test_acc:0.616\n",
      "Epoch  83\n",
      "Accuracy ---->  0.6491318047046661\n",
      "Iter:83 train_rmse:5.063 test_loss:187.5 test_rmse:0.06371 test_acc:0.6165\n",
      "Epoch  84\n",
      "Accuracy ---->  0.6496451497077942\n",
      "Iter:84 train_rmse:5.056 test_loss:187.1 test_rmse:0.06363 test_acc:0.6169\n",
      "Epoch  85\n",
      "Accuracy ---->  0.6501687169075012\n",
      "Iter:85 train_rmse:5.048 test_loss:186.6 test_rmse:0.06355 test_acc:0.6174\n",
      "Epoch  86\n",
      "Accuracy ---->  0.6506946682929993\n",
      "Iter:86 train_rmse:5.041 test_loss:186.1 test_rmse:0.06346 test_acc:0.6179\n",
      "Epoch  87\n",
      "Accuracy ---->  0.6512207388877869\n",
      "Iter:87 train_rmse:5.033 test_loss:185.5 test_rmse:0.06336 test_acc:0.6185\n",
      "Epoch  88\n",
      "Accuracy ---->  0.6517608761787415\n",
      "Iter:88 train_rmse:5.025 test_loss:184.9 test_rmse:0.06325 test_acc:0.6192\n",
      "Epoch  89\n",
      "Accuracy ---->  0.6523481607437134\n",
      "Iter:89 train_rmse:5.017 test_loss:184.2 test_rmse:0.06313 test_acc:0.6199\n",
      "Epoch  90\n",
      "Accuracy ---->  0.6530178189277649\n",
      "Iter:90 train_rmse:5.007 test_loss:183.4 test_rmse:0.06301 test_acc:0.6207\n",
      "Epoch  91\n",
      "Accuracy ---->  0.6537832617759705\n",
      "Iter:91 train_rmse:4.996 test_loss:182.7 test_rmse:0.06288 test_acc:0.6214\n",
      "Epoch  92\n",
      "Accuracy ---->  0.6546320617198944\n",
      "Iter:92 train_rmse:4.984 test_loss:182.0 test_rmse:0.06275 test_acc:0.6222\n",
      "Epoch  93\n",
      "Accuracy ---->  0.6555393934249878\n",
      "Iter:93 train_rmse:4.971 test_loss:181.2 test_rmse:0.06262 test_acc:0.623\n",
      "Epoch  94\n",
      "Accuracy ---->  0.6564823091030121\n",
      "Iter:94 train_rmse:4.957 test_loss:180.4 test_rmse:0.06249 test_acc:0.6238\n",
      "Epoch  95\n",
      "Accuracy ---->  0.6574435532093048\n",
      "Iter:95 train_rmse:4.943 test_loss:179.6 test_rmse:0.06235 test_acc:0.6246\n",
      "Epoch  96\n",
      "Accuracy ---->  0.6584105491638184\n",
      "Iter:96 train_rmse:4.929 test_loss:178.8 test_rmse:0.06221 test_acc:0.6255\n",
      "Epoch  97\n",
      "Accuracy ---->  0.659373015165329\n",
      "Iter:97 train_rmse:4.915 test_loss:178.0 test_rmse:0.06206 test_acc:0.6264\n",
      "Epoch  98\n",
      "Accuracy ---->  0.6603226065635681\n",
      "Iter:98 train_rmse:4.902 test_loss:177.2 test_rmse:0.06192 test_acc:0.6272\n",
      "Epoch  99\n",
      "Accuracy ---->  0.661251962184906\n",
      "Iter:99 train_rmse:4.888 test_loss:176.4 test_rmse:0.06177 test_acc:0.6281\n",
      "Epoch  100\n",
      "Accuracy ---->  0.6621553301811218\n",
      "Iter:100 train_rmse:4.875 test_loss:175.6 test_rmse:0.06163 test_acc:0.629\n",
      "Epoch  101\n",
      "Accuracy ---->  0.6630277931690216\n",
      "Iter:101 train_rmse:4.863 test_loss:174.8 test_rmse:0.06149 test_acc:0.6298\n",
      "Epoch  102\n",
      "Accuracy ---->  0.6638652384281158\n",
      "Iter:102 train_rmse:4.851 test_loss:174.0 test_rmse:0.06135 test_acc:0.6306\n",
      "Epoch  103\n",
      "Accuracy ---->  0.6646644771099091\n",
      "Iter:103 train_rmse:4.839 test_loss:173.2 test_rmse:0.06122 test_acc:0.6314\n",
      "Epoch  104\n",
      "Accuracy ---->  0.665422797203064\n",
      "Iter:104 train_rmse:4.828 test_loss:172.5 test_rmse:0.06109 test_acc:0.6322\n",
      "Epoch  105\n",
      "Accuracy ---->  0.6661385893821716\n",
      "Iter:105 train_rmse:4.818 test_loss:171.9 test_rmse:0.06097 test_acc:0.6329\n",
      "Epoch  106\n",
      "Accuracy ---->  0.6668121218681335\n",
      "Iter:106 train_rmse:4.808 test_loss:171.2 test_rmse:0.06086 test_acc:0.6336\n",
      "Epoch  107\n",
      "Accuracy ---->  0.6674460470676422\n",
      "Iter:107 train_rmse:4.799 test_loss:170.6 test_rmse:0.06075 test_acc:0.6343\n",
      "Epoch  108\n",
      "Accuracy ---->  0.6680449843406677\n",
      "Iter:108 train_rmse:4.79 test_loss:170.0 test_rmse:0.06065 test_acc:0.6349\n",
      "Epoch  109\n",
      "Accuracy ---->  0.6686146855354309\n",
      "Iter:109 train_rmse:4.782 test_loss:169.5 test_rmse:0.06055 test_acc:0.6355\n",
      "Epoch  110\n",
      "Accuracy ---->  0.669160008430481\n",
      "Iter:110 train_rmse:4.774 test_loss:169.0 test_rmse:0.06045 test_acc:0.636\n",
      "Epoch  111\n",
      "Accuracy ---->  0.6696847975254059\n",
      "Iter:111 train_rmse:4.767 test_loss:168.5 test_rmse:0.06037 test_acc:0.6366\n",
      "Epoch  112\n",
      "Accuracy ---->  0.6701912879943848\n",
      "Iter:112 train_rmse:4.759 test_loss:168.0 test_rmse:0.06028 test_acc:0.6371\n",
      "Epoch  113\n",
      "Accuracy ---->  0.6706812977790833\n",
      "Iter:113 train_rmse:4.752 test_loss:167.5 test_rmse:0.0602 test_acc:0.6376\n",
      "Epoch  114\n",
      "Accuracy ---->  0.6711563467979431\n",
      "Iter:114 train_rmse:4.745 test_loss:167.1 test_rmse:0.06012 test_acc:0.638\n",
      "Epoch  115\n",
      "Accuracy ---->  0.6716180145740509\n",
      "Iter:115 train_rmse:4.739 test_loss:166.7 test_rmse:0.06005 test_acc:0.6385\n",
      "Epoch  116\n",
      "Accuracy ---->  0.6720680594444275\n",
      "Iter:116 train_rmse:4.732 test_loss:166.3 test_rmse:0.05998 test_acc:0.6389\n",
      "Epoch  117\n",
      "Accuracy ---->  0.6725083887577057\n",
      "Iter:117 train_rmse:4.726 test_loss:165.9 test_rmse:0.05991 test_acc:0.6393\n",
      "Epoch  118\n",
      "Accuracy ---->  0.672940731048584\n",
      "Iter:118 train_rmse:4.72 test_loss:165.6 test_rmse:0.05984 test_acc:0.6397\n",
      "Epoch  119\n",
      "Accuracy ---->  0.6733667254447937\n",
      "Iter:119 train_rmse:4.714 test_loss:165.2 test_rmse:0.05978 test_acc:0.6401\n",
      "Epoch  120\n",
      "Accuracy ---->  0.673787534236908\n",
      "Iter:120 train_rmse:4.707 test_loss:164.9 test_rmse:0.05972 test_acc:0.6405\n",
      "Epoch  121\n",
      "Accuracy ---->  0.6742039620876312\n",
      "Iter:121 train_rmse:4.701 test_loss:164.5 test_rmse:0.05965 test_acc:0.6409\n",
      "Epoch  122\n",
      "Accuracy ---->  0.6746161580085754\n",
      "Iter:122 train_rmse:4.696 test_loss:164.2 test_rmse:0.05959 test_acc:0.6412\n",
      "Epoch  123\n",
      "Accuracy ---->  0.6750239431858063\n",
      "Iter:123 train_rmse:4.69 test_loss:163.9 test_rmse:0.05953 test_acc:0.6416\n",
      "Epoch  124\n",
      "Accuracy ---->  0.6754266023635864\n",
      "Iter:124 train_rmse:4.684 test_loss:163.5 test_rmse:0.05948 test_acc:0.6419\n",
      "Epoch  125\n",
      "Accuracy ---->  0.6758232712745667\n",
      "Iter:125 train_rmse:4.678 test_loss:163.2 test_rmse:0.05942 test_acc:0.6423\n",
      "Epoch  126\n",
      "Accuracy ---->  0.6762124001979828\n",
      "Iter:126 train_rmse:4.672 test_loss:162.9 test_rmse:0.05936 test_acc:0.6426\n",
      "Epoch  127\n",
      "Accuracy ---->  0.6765930354595184\n",
      "Iter:127 train_rmse:4.667 test_loss:162.7 test_rmse:0.05931 test_acc:0.6429\n",
      "Epoch  128\n",
      "Accuracy ---->  0.6769642531871796\n",
      "Iter:128 train_rmse:4.662 test_loss:162.4 test_rmse:0.05926 test_acc:0.6432\n",
      "Epoch  129\n",
      "Accuracy ---->  0.6773256361484528\n",
      "Iter:129 train_rmse:4.656 test_loss:162.1 test_rmse:0.05921 test_acc:0.6435\n",
      "Epoch  130\n",
      "Accuracy ---->  0.6776783466339111\n",
      "Iter:130 train_rmse:4.651 test_loss:161.8 test_rmse:0.05916 test_acc:0.6438\n",
      "Epoch  131\n",
      "Accuracy ---->  0.6780232787132263\n",
      "Iter:131 train_rmse:4.646 test_loss:161.5 test_rmse:0.05911 test_acc:0.6442\n",
      "Epoch  132\n",
      "Accuracy ---->  0.6783625483512878\n",
      "Iter:132 train_rmse:4.641 test_loss:161.3 test_rmse:0.05905 test_acc:0.6445\n",
      "Epoch  133\n",
      "Accuracy ---->  0.6786978840827942\n",
      "Iter:133 train_rmse:4.637 test_loss:161.0 test_rmse:0.059 test_acc:0.6448\n",
      "Epoch  134\n",
      "Accuracy ---->  0.6790301203727722\n",
      "Iter:134 train_rmse:4.632 test_loss:160.7 test_rmse:0.05895 test_acc:0.6451\n",
      "Epoch  135\n",
      "Accuracy ---->  0.6793599426746368\n",
      "Iter:135 train_rmse:4.627 test_loss:160.4 test_rmse:0.0589 test_acc:0.6454\n",
      "Epoch  136\n",
      "Accuracy ---->  0.679686576128006\n",
      "Iter:136 train_rmse:4.622 test_loss:160.1 test_rmse:0.05885 test_acc:0.6457\n",
      "Epoch  137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6800089776515961\n",
      "Iter:137 train_rmse:4.618 test_loss:159.9 test_rmse:0.0588 test_acc:0.646\n",
      "Epoch  138\n",
      "Accuracy ---->  0.6803255379199982\n",
      "Iter:138 train_rmse:4.613 test_loss:159.6 test_rmse:0.05874 test_acc:0.6463\n",
      "Epoch  139\n",
      "Accuracy ---->  0.6806350946426392\n",
      "Iter:139 train_rmse:4.609 test_loss:159.3 test_rmse:0.05869 test_acc:0.6466\n",
      "Epoch  140\n",
      "Accuracy ---->  0.6809363067150116\n",
      "Iter:140 train_rmse:4.604 test_loss:159.0 test_rmse:0.05864 test_acc:0.6469\n",
      "Epoch  141\n",
      "Accuracy ---->  0.6812286972999573\n",
      "Iter:141 train_rmse:4.6 test_loss:158.8 test_rmse:0.05859 test_acc:0.6472\n",
      "Epoch  142\n",
      "Accuracy ---->  0.681512326002121\n",
      "Iter:142 train_rmse:4.596 test_loss:158.5 test_rmse:0.05854 test_acc:0.6475\n",
      "Epoch  143\n",
      "Accuracy ---->  0.6817883253097534\n",
      "Iter:143 train_rmse:4.592 test_loss:158.2 test_rmse:0.05849 test_acc:0.6478\n",
      "Epoch  144\n",
      "Accuracy ---->  0.6820586025714874\n",
      "Iter:144 train_rmse:4.588 test_loss:158.0 test_rmse:0.05845 test_acc:0.6481\n",
      "Epoch  145\n",
      "Accuracy ---->  0.6823256313800812\n",
      "Iter:145 train_rmse:4.584 test_loss:157.7 test_rmse:0.0584 test_acc:0.6484\n",
      "Epoch  146\n",
      "Accuracy ---->  0.6825922429561615\n",
      "Iter:146 train_rmse:4.58 test_loss:157.5 test_rmse:0.05835 test_acc:0.6487\n",
      "Epoch  147\n",
      "Accuracy ---->  0.682860255241394\n",
      "Iter:147 train_rmse:4.577 test_loss:157.2 test_rmse:0.05831 test_acc:0.649\n",
      "Epoch  148\n",
      "Accuracy ---->  0.6831305027008057\n",
      "Iter:148 train_rmse:4.573 test_loss:157.0 test_rmse:0.05826 test_acc:0.6492\n",
      "Epoch  149\n",
      "Accuracy ---->  0.6834031045436859\n",
      "Iter:149 train_rmse:4.569 test_loss:156.7 test_rmse:0.05822 test_acc:0.6495\n",
      "Epoch  150\n",
      "Accuracy ---->  0.6836769282817841\n",
      "Iter:150 train_rmse:4.565 test_loss:156.5 test_rmse:0.05817 test_acc:0.6498\n",
      "Epoch  151\n",
      "Accuracy ---->  0.6839503347873688\n",
      "Iter:151 train_rmse:4.561 test_loss:156.3 test_rmse:0.05813 test_acc:0.65\n",
      "Epoch  152\n",
      "Accuracy ---->  0.6842217147350311\n",
      "Iter:152 train_rmse:4.557 test_loss:156.1 test_rmse:0.05809 test_acc:0.6503\n",
      "Epoch  153\n",
      "Accuracy ---->  0.6844892799854279\n",
      "Iter:153 train_rmse:4.553 test_loss:155.9 test_rmse:0.05805 test_acc:0.6505\n",
      "Epoch  154\n",
      "Accuracy ---->  0.6847514510154724\n",
      "Iter:154 train_rmse:4.549 test_loss:155.6 test_rmse:0.05801 test_acc:0.6507\n",
      "Epoch  155\n",
      "Accuracy ---->  0.6850073933601379\n",
      "Iter:155 train_rmse:4.546 test_loss:155.4 test_rmse:0.05797 test_acc:0.651\n",
      "Epoch  156\n",
      "Accuracy ---->  0.6852562427520752\n",
      "Iter:156 train_rmse:4.542 test_loss:155.2 test_rmse:0.05793 test_acc:0.6512\n",
      "Epoch  157\n",
      "Accuracy ---->  0.6854976415634155\n",
      "Iter:157 train_rmse:4.538 test_loss:155.0 test_rmse:0.0579 test_acc:0.6514\n",
      "Epoch  158\n",
      "Accuracy ---->  0.6857320070266724\n",
      "Iter:158 train_rmse:4.535 test_loss:154.8 test_rmse:0.05786 test_acc:0.6517\n",
      "Epoch  159\n",
      "Accuracy ---->  0.6859597265720367\n",
      "Iter:159 train_rmse:4.532 test_loss:154.6 test_rmse:0.05782 test_acc:0.6519\n",
      "Epoch  160\n",
      "Accuracy ---->  0.686181902885437\n",
      "Iter:160 train_rmse:4.529 test_loss:154.4 test_rmse:0.05778 test_acc:0.6521\n",
      "Epoch  161\n",
      "Accuracy ---->  0.6863991916179657\n",
      "Iter:161 train_rmse:4.525 test_loss:154.2 test_rmse:0.05774 test_acc:0.6524\n",
      "Epoch  162\n",
      "Accuracy ---->  0.6866129040718079\n",
      "Iter:162 train_rmse:4.522 test_loss:154.0 test_rmse:0.0577 test_acc:0.6526\n",
      "Epoch  163\n",
      "Accuracy ---->  0.6868237257003784\n",
      "Iter:163 train_rmse:4.519 test_loss:153.8 test_rmse:0.05767 test_acc:0.6528\n",
      "Epoch  164\n",
      "Accuracy ---->  0.6870323717594147\n",
      "Iter:164 train_rmse:4.516 test_loss:153.6 test_rmse:0.05763 test_acc:0.6531\n",
      "Epoch  165\n",
      "Accuracy ---->  0.68723925948143\n",
      "Iter:165 train_rmse:4.513 test_loss:153.4 test_rmse:0.05759 test_acc:0.6533\n",
      "Epoch  166\n",
      "Accuracy ---->  0.6874450147151947\n",
      "Iter:166 train_rmse:4.51 test_loss:153.2 test_rmse:0.05755 test_acc:0.6535\n",
      "Epoch  167\n",
      "Accuracy ---->  0.6876496374607086\n",
      "Iter:167 train_rmse:4.507 test_loss:153.0 test_rmse:0.05751 test_acc:0.6538\n",
      "Epoch  168\n",
      "Accuracy ---->  0.6878533661365509\n",
      "Iter:168 train_rmse:4.504 test_loss:152.8 test_rmse:0.05747 test_acc:0.654\n",
      "Epoch  169\n",
      "Accuracy ---->  0.688056230545044\n",
      "Iter:169 train_rmse:4.502 test_loss:152.5 test_rmse:0.05743 test_acc:0.6543\n",
      "Epoch  170\n",
      "Accuracy ---->  0.6882585287094116\n",
      "Iter:170 train_rmse:4.499 test_loss:152.3 test_rmse:0.05739 test_acc:0.6545\n",
      "Epoch  171\n",
      "Accuracy ---->  0.6884601712226868\n",
      "Iter:171 train_rmse:4.496 test_loss:152.1 test_rmse:0.05735 test_acc:0.6547\n",
      "Epoch  172\n",
      "Accuracy ---->  0.6886610388755798\n",
      "Iter:172 train_rmse:4.493 test_loss:151.9 test_rmse:0.05731 test_acc:0.655\n",
      "Epoch  173\n",
      "Accuracy ---->  0.6888611614704132\n",
      "Iter:173 train_rmse:4.49 test_loss:151.7 test_rmse:0.05727 test_acc:0.6552\n",
      "Epoch  174\n",
      "Accuracy ---->  0.6890607178211212\n",
      "Iter:174 train_rmse:4.487 test_loss:151.5 test_rmse:0.05724 test_acc:0.6554\n",
      "Epoch  175\n",
      "Accuracy ---->  0.6892594993114471\n",
      "Iter:175 train_rmse:4.484 test_loss:151.3 test_rmse:0.0572 test_acc:0.6556\n",
      "Epoch  176\n",
      "Accuracy ---->  0.689457505941391\n",
      "Iter:176 train_rmse:4.481 test_loss:151.1 test_rmse:0.05716 test_acc:0.6559\n",
      "Epoch  177\n",
      "Accuracy ---->  0.6896547675132751\n",
      "Iter:177 train_rmse:4.478 test_loss:150.9 test_rmse:0.05712 test_acc:0.6561\n",
      "Epoch  178\n",
      "Accuracy ---->  0.689851313829422\n",
      "Iter:178 train_rmse:4.476 test_loss:150.8 test_rmse:0.05709 test_acc:0.6563\n",
      "Epoch  179\n",
      "Accuracy ---->  0.6900469064712524\n",
      "Iter:179 train_rmse:4.473 test_loss:150.6 test_rmse:0.05705 test_acc:0.6565\n",
      "Epoch  180\n",
      "Accuracy ---->  0.6902417838573456\n",
      "Iter:180 train_rmse:4.47 test_loss:150.4 test_rmse:0.05701 test_acc:0.6567\n",
      "Epoch  181\n",
      "Accuracy ---->  0.6904358863830566\n",
      "Iter:181 train_rmse:4.467 test_loss:150.2 test_rmse:0.05698 test_acc:0.657\n",
      "Epoch  182\n",
      "Accuracy ---->  0.6906291544437408\n",
      "Iter:182 train_rmse:4.464 test_loss:150.0 test_rmse:0.05694 test_acc:0.6572\n",
      "Epoch  183\n",
      "Accuracy ---->  0.6908216178417206\n",
      "Iter:183 train_rmse:4.462 test_loss:149.8 test_rmse:0.05691 test_acc:0.6574\n",
      "Epoch  184\n",
      "Accuracy ---->  0.6910132765769958\n",
      "Iter:184 train_rmse:4.459 test_loss:149.6 test_rmse:0.05687 test_acc:0.6576\n",
      "Epoch  185\n",
      "Accuracy ---->  0.6912040412425995\n",
      "Iter:185 train_rmse:4.456 test_loss:149.5 test_rmse:0.05684 test_acc:0.6578\n",
      "Epoch  186\n",
      "Accuracy ---->  0.6913940012454987\n",
      "Iter:186 train_rmse:4.453 test_loss:149.3 test_rmse:0.0568 test_acc:0.658\n",
      "Epoch  187\n",
      "Accuracy ---->  0.6915831565856934\n",
      "Iter:187 train_rmse:4.451 test_loss:149.1 test_rmse:0.05677 test_acc:0.6582\n",
      "Epoch  188\n",
      "Accuracy ---->  0.6917714476585388\n",
      "Iter:188 train_rmse:4.448 test_loss:148.9 test_rmse:0.05674 test_acc:0.6584\n",
      "Epoch  189\n",
      "Accuracy ---->  0.691959023475647\n",
      "Iter:189 train_rmse:4.445 test_loss:148.7 test_rmse:0.0567 test_acc:0.6586\n",
      "Epoch  190\n",
      "Accuracy ---->  0.6921456158161163\n",
      "Iter:190 train_rmse:4.443 test_loss:148.6 test_rmse:0.05667 test_acc:0.6588\n",
      "Epoch  191\n",
      "Accuracy ---->  0.6923312842845917\n",
      "Iter:191 train_rmse:4.44 test_loss:148.4 test_rmse:0.05664 test_acc:0.659\n",
      "Epoch  192\n",
      "Accuracy ---->  0.6925158500671387\n",
      "Iter:192 train_rmse:4.437 test_loss:148.2 test_rmse:0.0566 test_acc:0.6592\n",
      "Epoch  193\n",
      "Accuracy ---->  0.6926992535591125\n",
      "Iter:193 train_rmse:4.435 test_loss:148.1 test_rmse:0.05657 test_acc:0.6594\n",
      "Epoch  194\n",
      "Accuracy ---->  0.6928812265396118\n",
      "Iter:194 train_rmse:4.432 test_loss:147.9 test_rmse:0.05654 test_acc:0.6596\n",
      "Epoch  195\n",
      "Accuracy ---->  0.6930616199970245\n",
      "Iter:195 train_rmse:4.429 test_loss:147.7 test_rmse:0.05651 test_acc:0.6598\n",
      "Epoch  196\n",
      "Accuracy ---->  0.6932400763034821\n",
      "Iter:196 train_rmse:4.427 test_loss:147.6 test_rmse:0.05648 test_acc:0.66\n",
      "Epoch  197\n",
      "Accuracy ---->  0.6934163868427277\n",
      "Iter:197 train_rmse:4.424 test_loss:147.4 test_rmse:0.05644 test_acc:0.6602\n",
      "Epoch  198\n",
      "Accuracy ---->  0.6935901343822479\n",
      "Iter:198 train_rmse:4.422 test_loss:147.2 test_rmse:0.05641 test_acc:0.6604\n",
      "Epoch  199\n",
      "Accuracy ---->  0.6937611103057861\n",
      "Iter:199 train_rmse:4.419 test_loss:147.1 test_rmse:0.05638 test_acc:0.6605\n",
      "Epoch  200\n",
      "Accuracy ---->  0.6939294040203094\n",
      "Iter:200 train_rmse:4.417 test_loss:146.9 test_rmse:0.05635 test_acc:0.6607\n",
      "Epoch  201\n",
      "Accuracy ---->  0.6940950751304626\n",
      "Iter:201 train_rmse:4.414 test_loss:146.8 test_rmse:0.05633 test_acc:0.6609\n",
      "Epoch  202\n",
      "Accuracy ---->  0.6942589581012726\n",
      "Iter:202 train_rmse:4.412 test_loss:146.6 test_rmse:0.0563 test_acc:0.6611\n",
      "Epoch  203\n",
      "Accuracy ---->  0.6944223344326019\n",
      "Iter:203 train_rmse:4.41 test_loss:146.5 test_rmse:0.05627 test_acc:0.6612\n",
      "Epoch  204\n",
      "Accuracy ---->  0.6945870220661163\n",
      "Iter:204 train_rmse:4.407 test_loss:146.4 test_rmse:0.05625 test_acc:0.6613\n",
      "Epoch  205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6947554349899292\n",
      "Iter:205 train_rmse:4.405 test_loss:146.3 test_rmse:0.05623 test_acc:0.6615\n",
      "Epoch  206\n",
      "Accuracy ---->  0.6949296593666077\n",
      "Iter:206 train_rmse:4.402 test_loss:146.2 test_rmse:0.05621 test_acc:0.6616\n",
      "Epoch  207\n",
      "Accuracy ---->  0.6951117217540741\n",
      "Iter:207 train_rmse:4.4 test_loss:146.1 test_rmse:0.05619 test_acc:0.6617\n",
      "Epoch  208\n",
      "Accuracy ---->  0.6953026652336121\n",
      "Iter:208 train_rmse:4.397 test_loss:146.0 test_rmse:0.05618 test_acc:0.6618\n",
      "Epoch  209\n",
      "Accuracy ---->  0.6955020725727081\n",
      "Iter:209 train_rmse:4.394 test_loss:146.0 test_rmse:0.05617 test_acc:0.6618\n",
      "Epoch  210\n",
      "Accuracy ---->  0.6957076489925385\n",
      "Iter:210 train_rmse:4.391 test_loss:146.0 test_rmse:0.05617 test_acc:0.6619\n",
      "Epoch  211\n",
      "Accuracy ---->  0.6959140300750732\n",
      "Iter:211 train_rmse:4.388 test_loss:145.9 test_rmse:0.05616 test_acc:0.6619\n",
      "Epoch  212\n",
      "Accuracy ---->  0.6961103677749634\n",
      "Iter:212 train_rmse:4.385 test_loss:145.9 test_rmse:0.05615 test_acc:0.6619\n",
      "Epoch  213\n",
      "Accuracy ---->  0.6962769329547882\n",
      "Iter:213 train_rmse:4.383 test_loss:145.9 test_rmse:0.05614 test_acc:0.662\n",
      "Epoch  214\n",
      "Accuracy ---->  0.6963804662227631\n",
      "Iter:214 train_rmse:4.381 test_loss:145.8 test_rmse:0.05612 test_acc:0.6621\n",
      "Epoch  215\n",
      "Accuracy ---->  0.6963765919208527\n",
      "Iter:215 train_rmse:4.381 test_loss:145.5 test_rmse:0.05609 test_acc:0.6623\n",
      "Epoch  216\n",
      "Accuracy ---->  0.6962407529354095\n",
      "Iter:216 train_rmse:4.383 test_loss:145.2 test_rmse:0.05602 test_acc:0.6627\n",
      "Epoch  217\n",
      "Accuracy ---->  0.6960527002811432\n",
      "Iter:217 train_rmse:4.386 test_loss:144.7 test_rmse:0.05592 test_acc:0.6633\n",
      "Epoch  218\n",
      "Accuracy ---->  0.6960248649120331\n",
      "Iter:218 train_rmse:4.387 test_loss:144.3 test_rmse:0.05584 test_acc:0.6638\n",
      "Epoch  219\n",
      "Accuracy ---->  0.6962526142597198\n",
      "Iter:219 train_rmse:4.383 test_loss:144.0 test_rmse:0.05578 test_acc:0.6642\n",
      "Epoch  220\n",
      "Accuracy ---->  0.6965692937374115\n",
      "Iter:220 train_rmse:4.379 test_loss:143.8 test_rmse:0.05574 test_acc:0.6644\n",
      "Epoch  221\n",
      "Accuracy ---->  0.69684237241745\n",
      "Iter:221 train_rmse:4.375 test_loss:143.6 test_rmse:0.05571 test_acc:0.6646\n",
      "Epoch  222\n",
      "Accuracy ---->  0.6970662176609039\n",
      "Iter:222 train_rmse:4.372 test_loss:143.5 test_rmse:0.05569 test_acc:0.6647\n",
      "Epoch  223\n",
      "Accuracy ---->  0.6972624957561493\n",
      "Iter:223 train_rmse:4.369 test_loss:143.4 test_rmse:0.05566 test_acc:0.6649\n",
      "Epoch  224\n",
      "Accuracy ---->  0.6974450945854187\n",
      "Iter:224 train_rmse:4.366 test_loss:143.2 test_rmse:0.05563 test_acc:0.6651\n",
      "Epoch  225\n",
      "Accuracy ---->  0.6976206302642822\n",
      "Iter:225 train_rmse:4.364 test_loss:143.1 test_rmse:0.05561 test_acc:0.6652\n",
      "Epoch  226\n",
      "Accuracy ---->  0.6977922916412354\n",
      "Iter:226 train_rmse:4.361 test_loss:143.0 test_rmse:0.05558 test_acc:0.6654\n",
      "Epoch  227\n",
      "Accuracy ---->  0.6979619860649109\n",
      "Iter:227 train_rmse:4.359 test_loss:142.8 test_rmse:0.05556 test_acc:0.6655\n",
      "Epoch  228\n",
      "Accuracy ---->  0.6981303691864014\n",
      "Iter:228 train_rmse:4.356 test_loss:142.7 test_rmse:0.05553 test_acc:0.6657\n",
      "Epoch  229\n",
      "Accuracy ---->  0.6982981860637665\n",
      "Iter:229 train_rmse:4.354 test_loss:142.6 test_rmse:0.0555 test_acc:0.6658\n",
      "Epoch  230\n",
      "Accuracy ---->  0.6984654366970062\n",
      "Iter:230 train_rmse:4.351 test_loss:142.4 test_rmse:0.05548 test_acc:0.666\n",
      "Epoch  231\n",
      "Accuracy ---->  0.6986321210861206\n",
      "Iter:231 train_rmse:4.349 test_loss:142.3 test_rmse:0.05545 test_acc:0.6662\n",
      "Epoch  232\n",
      "Accuracy ---->  0.698798269033432\n",
      "Iter:232 train_rmse:4.347 test_loss:142.2 test_rmse:0.05543 test_acc:0.6663\n",
      "Epoch  233\n",
      "Accuracy ---->  0.69896399974823\n",
      "Iter:233 train_rmse:4.344 test_loss:142.0 test_rmse:0.0554 test_acc:0.6665\n",
      "Epoch  234\n",
      "Accuracy ---->  0.6991290748119354\n",
      "Iter:234 train_rmse:4.342 test_loss:141.9 test_rmse:0.05538 test_acc:0.6666\n",
      "Epoch  235\n",
      "Accuracy ---->  0.6992934048175812\n",
      "Iter:235 train_rmse:4.339 test_loss:141.8 test_rmse:0.05535 test_acc:0.6668\n",
      "Epoch  236\n",
      "Accuracy ---->  0.6994569897651672\n",
      "Iter:236 train_rmse:4.337 test_loss:141.6 test_rmse:0.05532 test_acc:0.6669\n",
      "Epoch  237\n",
      "Accuracy ---->  0.699619859457016\n",
      "Iter:237 train_rmse:4.335 test_loss:141.5 test_rmse:0.0553 test_acc:0.6671\n",
      "Epoch  238\n",
      "Accuracy ---->  0.6997819244861603\n",
      "Iter:238 train_rmse:4.332 test_loss:141.4 test_rmse:0.05527 test_acc:0.6672\n",
      "Epoch  239\n",
      "Accuracy ---->  0.6999430656433105\n",
      "Iter:239 train_rmse:4.33 test_loss:141.3 test_rmse:0.05525 test_acc:0.6674\n",
      "Epoch  240\n",
      "Accuracy ---->  0.7001032531261444\n",
      "Iter:240 train_rmse:4.328 test_loss:141.1 test_rmse:0.05522 test_acc:0.6675\n",
      "Epoch  241\n",
      "Accuracy ---->  0.7002626955509186\n",
      "Iter:241 train_rmse:4.325 test_loss:141.0 test_rmse:0.05519 test_acc:0.6677\n",
      "Epoch  242\n",
      "Accuracy ---->  0.7004211843013763\n",
      "Iter:242 train_rmse:4.323 test_loss:140.9 test_rmse:0.05517 test_acc:0.6679\n",
      "Epoch  243\n",
      "Accuracy ---->  0.7005788087844849\n",
      "Iter:243 train_rmse:4.321 test_loss:140.7 test_rmse:0.05514 test_acc:0.668\n",
      "Epoch  244\n",
      "Accuracy ---->  0.7007356286048889\n",
      "Iter:244 train_rmse:4.319 test_loss:140.6 test_rmse:0.05511 test_acc:0.6682\n",
      "Epoch  245\n",
      "Accuracy ---->  0.7008916437625885\n",
      "Iter:245 train_rmse:4.316 test_loss:140.4 test_rmse:0.05509 test_acc:0.6683\n",
      "Epoch  246\n",
      "Accuracy ---->  0.7010469138622284\n",
      "Iter:246 train_rmse:4.314 test_loss:140.3 test_rmse:0.05506 test_acc:0.6685\n",
      "Epoch  247\n",
      "Accuracy ---->  0.7012015581130981\n",
      "Iter:247 train_rmse:4.312 test_loss:140.2 test_rmse:0.05503 test_acc:0.6687\n",
      "Epoch  248\n",
      "Accuracy ---->  0.7013554573059082\n",
      "Iter:248 train_rmse:4.31 test_loss:140.0 test_rmse:0.05501 test_acc:0.6688\n",
      "Epoch  249\n",
      "Accuracy ---->  0.7015089094638824\n",
      "Iter:249 train_rmse:4.307 test_loss:139.9 test_rmse:0.05498 test_acc:0.669\n",
      "Epoch  250\n",
      "Accuracy ---->  0.7016616463661194\n",
      "Iter:250 train_rmse:4.305 test_loss:139.8 test_rmse:0.05495 test_acc:0.6692\n",
      "Epoch  251\n",
      "Accuracy ---->  0.7018138468265533\n",
      "Iter:251 train_rmse:4.303 test_loss:139.6 test_rmse:0.05492 test_acc:0.6693\n",
      "Epoch  252\n",
      "Accuracy ---->  0.7019656002521515\n",
      "Iter:252 train_rmse:4.301 test_loss:139.5 test_rmse:0.05489 test_acc:0.6695\n",
      "Epoch  253\n",
      "Accuracy ---->  0.7021168768405914\n",
      "Iter:253 train_rmse:4.299 test_loss:139.3 test_rmse:0.05487 test_acc:0.6697\n",
      "Epoch  254\n",
      "Accuracy ---->  0.7022678256034851\n",
      "Iter:254 train_rmse:4.296 test_loss:139.2 test_rmse:0.05484 test_acc:0.6698\n",
      "Epoch  255\n",
      "Accuracy ---->  0.7024182677268982\n",
      "Iter:255 train_rmse:4.294 test_loss:139.0 test_rmse:0.05481 test_acc:0.67\n",
      "Epoch  256\n",
      "Accuracy ---->  0.7025684118270874\n",
      "Iter:256 train_rmse:4.292 test_loss:138.9 test_rmse:0.05478 test_acc:0.6702\n",
      "Epoch  257\n",
      "Accuracy ---->  0.7027180194854736\n",
      "Iter:257 train_rmse:4.29 test_loss:138.8 test_rmse:0.05475 test_acc:0.6704\n",
      "Epoch  258\n",
      "Accuracy ---->  0.7028672993183136\n",
      "Iter:258 train_rmse:4.288 test_loss:138.6 test_rmse:0.05473 test_acc:0.6705\n",
      "Epoch  259\n",
      "Accuracy ---->  0.703016072511673\n",
      "Iter:259 train_rmse:4.286 test_loss:138.5 test_rmse:0.0547 test_acc:0.6707\n",
      "Epoch  260\n",
      "Accuracy ---->  0.7031642198562622\n",
      "Iter:260 train_rmse:4.284 test_loss:138.3 test_rmse:0.05467 test_acc:0.6709\n",
      "Epoch  261\n",
      "Accuracy ---->  0.7033119201660156\n",
      "Iter:261 train_rmse:4.281 test_loss:138.2 test_rmse:0.05464 test_acc:0.671\n",
      "Epoch  262\n",
      "Accuracy ---->  0.7034591138362885\n",
      "Iter:262 train_rmse:4.279 test_loss:138.1 test_rmse:0.05461 test_acc:0.6712\n",
      "Epoch  263\n",
      "Accuracy ---->  0.7036055326461792\n",
      "Iter:263 train_rmse:4.277 test_loss:137.9 test_rmse:0.05459 test_acc:0.6714\n",
      "Epoch  264\n",
      "Accuracy ---->  0.703751266002655\n",
      "Iter:264 train_rmse:4.275 test_loss:137.8 test_rmse:0.05456 test_acc:0.6715\n",
      "Epoch  265\n",
      "Accuracy ---->  0.7038960754871368\n",
      "Iter:265 train_rmse:4.273 test_loss:137.6 test_rmse:0.05453 test_acc:0.6717\n",
      "Epoch  266\n",
      "Accuracy ---->  0.7040403485298157\n",
      "Iter:266 train_rmse:4.271 test_loss:137.5 test_rmse:0.0545 test_acc:0.6719\n",
      "Epoch  267\n",
      "Accuracy ---->  0.7041834592819214\n",
      "Iter:267 train_rmse:4.269 test_loss:137.4 test_rmse:0.05448 test_acc:0.672\n",
      "Epoch  268\n",
      "Accuracy ---->  0.7043257355690002\n",
      "Iter:268 train_rmse:4.267 test_loss:137.2 test_rmse:0.05445 test_acc:0.6722\n",
      "Epoch  269\n",
      "Accuracy ---->  0.7044673264026642\n",
      "Iter:269 train_rmse:4.265 test_loss:137.1 test_rmse:0.05442 test_acc:0.6723\n",
      "Epoch  270\n",
      "Accuracy ---->  0.7046079337596893\n",
      "Iter:270 train_rmse:4.263 test_loss:137.0 test_rmse:0.0544 test_acc:0.6725\n",
      "Epoch  271\n",
      "Accuracy ---->  0.7047477066516876\n",
      "Iter:271 train_rmse:4.261 test_loss:136.9 test_rmse:0.05437 test_acc:0.6726\n",
      "Epoch  272\n",
      "Accuracy ---->  0.7048868536949158\n",
      "Iter:272 train_rmse:4.259 test_loss:136.7 test_rmse:0.05435 test_acc:0.6728\n",
      "Epoch  273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.7050253450870514\n",
      "Iter:273 train_rmse:4.257 test_loss:136.6 test_rmse:0.05432 test_acc:0.673\n",
      "Epoch  274\n",
      "Accuracy ---->  0.7051633894443512\n",
      "Iter:274 train_rmse:4.255 test_loss:136.5 test_rmse:0.0543 test_acc:0.6731\n",
      "Epoch  275\n",
      "Accuracy ---->  0.7053012549877167\n",
      "Iter:275 train_rmse:4.253 test_loss:136.4 test_rmse:0.05427 test_acc:0.6732\n",
      "Epoch  276\n",
      "Accuracy ---->  0.7054388225078583\n",
      "Iter:276 train_rmse:4.251 test_loss:136.2 test_rmse:0.05425 test_acc:0.6734\n",
      "Epoch  277\n",
      "Accuracy ---->  0.7055764198303223\n",
      "Iter:277 train_rmse:4.249 test_loss:136.1 test_rmse:0.05423 test_acc:0.6735\n",
      "Epoch  278\n",
      "Accuracy ---->  0.7057143449783325\n",
      "Iter:278 train_rmse:4.247 test_loss:136.0 test_rmse:0.0542 test_acc:0.6737\n",
      "Epoch  279\n",
      "Accuracy ---->  0.7058527171611786\n",
      "Iter:279 train_rmse:4.245 test_loss:135.9 test_rmse:0.05418 test_acc:0.6738\n",
      "Epoch  280\n",
      "Accuracy ---->  0.7059915959835052\n",
      "Iter:280 train_rmse:4.243 test_loss:135.8 test_rmse:0.05416 test_acc:0.6739\n",
      "Epoch  281\n",
      "Accuracy ---->  0.7061311900615692\n",
      "Iter:281 train_rmse:4.241 test_loss:135.7 test_rmse:0.05413 test_acc:0.6741\n",
      "Epoch  282\n",
      "Accuracy ---->  0.7062720060348511\n",
      "Iter:282 train_rmse:4.239 test_loss:135.6 test_rmse:0.05411 test_acc:0.6742\n",
      "Epoch  283\n",
      "Accuracy ---->  0.7064142823219299\n",
      "Iter:283 train_rmse:4.237 test_loss:135.5 test_rmse:0.05409 test_acc:0.6743\n",
      "Epoch  284\n",
      "Accuracy ---->  0.7065582573413849\n",
      "Iter:284 train_rmse:4.235 test_loss:135.3 test_rmse:0.05407 test_acc:0.6745\n",
      "Epoch  285\n",
      "Accuracy ---->  0.7067047655582428\n",
      "Iter:285 train_rmse:4.232 test_loss:135.2 test_rmse:0.05405 test_acc:0.6746\n",
      "Epoch  286\n",
      "Accuracy ---->  0.7068541049957275\n",
      "Iter:286 train_rmse:4.23 test_loss:135.1 test_rmse:0.05403 test_acc:0.6747\n",
      "Epoch  287\n",
      "Accuracy ---->  0.7070074677467346\n",
      "Iter:287 train_rmse:4.228 test_loss:135.0 test_rmse:0.054 test_acc:0.6749\n",
      "Epoch  288\n",
      "Accuracy ---->  0.7071656584739685\n",
      "Iter:288 train_rmse:4.226 test_loss:134.9 test_rmse:0.05398 test_acc:0.675\n",
      "Epoch  289\n",
      "Accuracy ---->  0.707330048084259\n",
      "Iter:289 train_rmse:4.223 test_loss:134.8 test_rmse:0.05396 test_acc:0.6751\n",
      "Epoch  290\n",
      "Accuracy ---->  0.7075016498565674\n",
      "Iter:290 train_rmse:4.221 test_loss:134.7 test_rmse:0.05394 test_acc:0.6752\n",
      "Epoch  291\n",
      "Accuracy ---->  0.7076813280582428\n",
      "Iter:291 train_rmse:4.218 test_loss:134.6 test_rmse:0.05392 test_acc:0.6754\n",
      "Epoch  292\n",
      "Accuracy ---->  0.7078684866428375\n",
      "Iter:292 train_rmse:4.216 test_loss:134.5 test_rmse:0.0539 test_acc:0.6755\n",
      "Epoch  293\n",
      "Accuracy ---->  0.7080607414245605\n",
      "Iter:293 train_rmse:4.213 test_loss:134.4 test_rmse:0.05388 test_acc:0.6756\n",
      "Epoch  294\n",
      "Accuracy ---->  0.7082529962062836\n",
      "Iter:294 train_rmse:4.21 test_loss:134.3 test_rmse:0.05386 test_acc:0.6757\n",
      "Epoch  295\n",
      "Accuracy ---->  0.7084383964538574\n",
      "Iter:295 train_rmse:4.207 test_loss:134.2 test_rmse:0.05384 test_acc:0.6759\n",
      "Epoch  296\n",
      "Accuracy ---->  0.7086097002029419\n",
      "Iter:296 train_rmse:4.205 test_loss:134.1 test_rmse:0.05382 test_acc:0.676\n",
      "Epoch  297\n",
      "Accuracy ---->  0.7087631225585938\n",
      "Iter:297 train_rmse:4.203 test_loss:134.0 test_rmse:0.0538 test_acc:0.6761\n",
      "Epoch  298\n",
      "Accuracy ---->  0.7088990807533264\n",
      "Iter:298 train_rmse:4.201 test_loss:133.9 test_rmse:0.05378 test_acc:0.6762\n",
      "Epoch  299\n",
      "Accuracy ---->  0.7090200781822205\n",
      "Iter:299 train_rmse:4.199 test_loss:133.9 test_rmse:0.05377 test_acc:0.6763\n",
      "Epoch  300\n",
      "Accuracy ---->  0.7091265916824341\n",
      "Iter:300 train_rmse:4.198 test_loss:133.8 test_rmse:0.05376 test_acc:0.6763\n",
      "Epoch  301\n",
      "Accuracy ---->  0.7092116177082062\n",
      "Iter:301 train_rmse:4.196 test_loss:133.8 test_rmse:0.05376 test_acc:0.6763\n",
      "Epoch  302\n",
      "Accuracy ---->  0.7092553079128265\n",
      "Iter:302 train_rmse:4.196 test_loss:133.8 test_rmse:0.05375 test_acc:0.6764\n",
      "Epoch  303\n",
      "Accuracy ---->  0.7092166543006897\n",
      "Iter:303 train_rmse:4.196 test_loss:133.7 test_rmse:0.05374 test_acc:0.6764\n",
      "Epoch  304\n",
      "Accuracy ---->  0.7090301513671875\n",
      "Iter:304 train_rmse:4.199 test_loss:133.6 test_rmse:0.05372 test_acc:0.6766\n",
      "Epoch  305\n",
      "Accuracy ---->  0.7086530327796936\n",
      "Iter:305 train_rmse:4.204 test_loss:133.4 test_rmse:0.05367 test_acc:0.6769\n",
      "Epoch  306\n",
      "Accuracy ---->  0.7082731127738953\n",
      "Iter:306 train_rmse:4.21 test_loss:133.2 test_rmse:0.05363 test_acc:0.6771\n",
      "Epoch  307\n",
      "Accuracy ---->  0.7084493339061737\n",
      "Iter:307 train_rmse:4.207 test_loss:133.2 test_rmse:0.05363 test_acc:0.6771\n",
      "Epoch  308\n",
      "Accuracy ---->  0.709171861410141\n",
      "Iter:308 train_rmse:4.197 test_loss:133.3 test_rmse:0.05365 test_acc:0.677\n",
      "Epoch  309\n",
      "Accuracy ---->  0.7096944451332092\n",
      "Iter:309 train_rmse:4.189 test_loss:133.2 test_rmse:0.05364 test_acc:0.6771\n",
      "Epoch  310\n",
      "Accuracy ---->  0.7099432945251465\n",
      "Iter:310 train_rmse:4.186 test_loss:133.1 test_rmse:0.05361 test_acc:0.6772\n",
      "Epoch  311\n",
      "Accuracy ---->  0.7100943624973297\n",
      "Iter:311 train_rmse:4.184 test_loss:133.0 test_rmse:0.05359 test_acc:0.6773\n",
      "Epoch  312\n",
      "Accuracy ---->  0.7102155685424805\n",
      "Iter:312 train_rmse:4.182 test_loss:132.9 test_rmse:0.05358 test_acc:0.6774\n",
      "Epoch  313\n",
      "Accuracy ---->  0.7103258967399597\n",
      "Iter:313 train_rmse:4.18 test_loss:132.8 test_rmse:0.05356 test_acc:0.6775\n",
      "Epoch  314\n",
      "Accuracy ---->  0.7104316651821136\n",
      "Iter:314 train_rmse:4.179 test_loss:132.7 test_rmse:0.05354 test_acc:0.6776\n",
      "Epoch  315\n",
      "Accuracy ---->  0.7105354964733124\n",
      "Iter:315 train_rmse:4.177 test_loss:132.7 test_rmse:0.05353 test_acc:0.6777\n",
      "Epoch  316\n",
      "Accuracy ---->  0.710638552904129\n",
      "Iter:316 train_rmse:4.176 test_loss:132.6 test_rmse:0.05351 test_acc:0.6778\n",
      "Epoch  317\n",
      "Accuracy ---->  0.7107414305210114\n",
      "Iter:317 train_rmse:4.174 test_loss:132.5 test_rmse:0.0535 test_acc:0.6779\n",
      "Epoch  318\n",
      "Accuracy ---->  0.7108442187309265\n",
      "Iter:318 train_rmse:4.173 test_loss:132.4 test_rmse:0.05348 test_acc:0.678\n",
      "Epoch  319\n",
      "Accuracy ---->  0.7109469771385193\n",
      "Iter:319 train_rmse:4.171 test_loss:132.4 test_rmse:0.05347 test_acc:0.6781\n",
      "Epoch  320\n",
      "Accuracy ---->  0.7110498547554016\n",
      "Iter:320 train_rmse:4.17 test_loss:132.3 test_rmse:0.05345 test_acc:0.6782\n",
      "Epoch  321\n",
      "Accuracy ---->  0.7111527323722839\n",
      "Iter:321 train_rmse:4.168 test_loss:132.2 test_rmse:0.05344 test_acc:0.6783\n",
      "Epoch  322\n",
      "Accuracy ---->  0.7112554609775543\n",
      "Iter:322 train_rmse:4.167 test_loss:132.1 test_rmse:0.05342 test_acc:0.6784\n",
      "Epoch  323\n",
      "Accuracy ---->  0.711357980966568\n",
      "Iter:323 train_rmse:4.165 test_loss:132.1 test_rmse:0.05341 test_acc:0.6785\n",
      "Epoch  324\n",
      "Accuracy ---->  0.711460292339325\n",
      "Iter:324 train_rmse:4.164 test_loss:132.0 test_rmse:0.05339 test_acc:0.6786\n",
      "Epoch  325\n",
      "Accuracy ---->  0.7115621864795685\n",
      "Iter:325 train_rmse:4.162 test_loss:131.9 test_rmse:0.05338 test_acc:0.6787\n",
      "Epoch  326\n",
      "Accuracy ---->  0.7116638123989105\n",
      "Iter:326 train_rmse:4.161 test_loss:131.9 test_rmse:0.05336 test_acc:0.6787\n",
      "Epoch  327\n",
      "Accuracy ---->  0.7117648124694824\n",
      "Iter:327 train_rmse:4.159 test_loss:131.8 test_rmse:0.05335 test_acc:0.6788\n",
      "Epoch  328\n",
      "Accuracy ---->  0.7118654549121857\n",
      "Iter:328 train_rmse:4.158 test_loss:131.7 test_rmse:0.05333 test_acc:0.6789\n",
      "Epoch  329\n",
      "Accuracy ---->  0.7119655311107635\n",
      "Iter:329 train_rmse:4.157 test_loss:131.6 test_rmse:0.05332 test_acc:0.679\n",
      "Epoch  330\n",
      "Accuracy ---->  0.7120650112628937\n",
      "Iter:330 train_rmse:4.155 test_loss:131.6 test_rmse:0.0533 test_acc:0.6791\n",
      "Epoch  331\n",
      "Accuracy ---->  0.7121637761592865\n",
      "Iter:331 train_rmse:4.154 test_loss:131.5 test_rmse:0.05329 test_acc:0.6792\n",
      "Epoch  332\n",
      "Accuracy ---->  0.7122620046138763\n",
      "Iter:332 train_rmse:4.152 test_loss:131.4 test_rmse:0.05327 test_acc:0.6793\n",
      "Epoch  333\n",
      "Accuracy ---->  0.7123594880104065\n",
      "Iter:333 train_rmse:4.151 test_loss:131.3 test_rmse:0.05326 test_acc:0.6794\n",
      "Epoch  334\n",
      "Accuracy ---->  0.7124563455581665\n",
      "Iter:334 train_rmse:4.149 test_loss:131.3 test_rmse:0.05324 test_acc:0.6795\n",
      "Epoch  335\n",
      "Accuracy ---->  0.7125525772571564\n",
      "Iter:335 train_rmse:4.148 test_loss:131.2 test_rmse:0.05323 test_acc:0.6795\n",
      "Epoch  336\n",
      "Accuracy ---->  0.7126481533050537\n",
      "Iter:336 train_rmse:4.147 test_loss:131.1 test_rmse:0.05321 test_acc:0.6796\n",
      "Epoch  337\n",
      "Accuracy ---->  0.7127430438995361\n",
      "Iter:337 train_rmse:4.145 test_loss:131.1 test_rmse:0.0532 test_acc:0.6797\n",
      "Epoch  338\n",
      "Accuracy ---->  0.7128373682498932\n",
      "Iter:338 train_rmse:4.144 test_loss:131.0 test_rmse:0.05318 test_acc:0.6798\n",
      "Epoch  339\n",
      "Accuracy ---->  0.7129310667514801\n",
      "Iter:339 train_rmse:4.143 test_loss:130.9 test_rmse:0.05317 test_acc:0.6799\n",
      "Epoch  340\n",
      "Accuracy ---->  0.7130241096019745\n",
      "Iter:340 train_rmse:4.141 test_loss:130.8 test_rmse:0.05315 test_acc:0.68\n",
      "Epoch  341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.7131167352199554\n",
      "Iter:341 train_rmse:4.14 test_loss:130.8 test_rmse:0.05314 test_acc:0.6801\n",
      "Epoch  342\n",
      "Accuracy ---->  0.7132087647914886\n",
      "Iter:342 train_rmse:4.139 test_loss:130.7 test_rmse:0.05312 test_acc:0.6802\n",
      "Epoch  343\n",
      "Accuracy ---->  0.7133003175258636\n",
      "Iter:343 train_rmse:4.137 test_loss:130.6 test_rmse:0.05311 test_acc:0.6803\n",
      "Epoch  344\n",
      "Accuracy ---->  0.7133914828300476\n",
      "Iter:344 train_rmse:4.136 test_loss:130.5 test_rmse:0.05309 test_acc:0.6804\n",
      "Epoch  345\n",
      "Accuracy ---->  0.713482141494751\n",
      "Iter:345 train_rmse:4.135 test_loss:130.5 test_rmse:0.05307 test_acc:0.6805\n",
      "Epoch  346\n",
      "Accuracy ---->  0.7135725319385529\n",
      "Iter:346 train_rmse:4.133 test_loss:130.4 test_rmse:0.05306 test_acc:0.6806\n",
      "Epoch  347\n",
      "Accuracy ---->  0.7136625349521637\n",
      "Iter:347 train_rmse:4.132 test_loss:130.3 test_rmse:0.05304 test_acc:0.6807\n",
      "Epoch  348\n",
      "Accuracy ---->  0.7137522399425507\n",
      "Iter:348 train_rmse:4.131 test_loss:130.2 test_rmse:0.05303 test_acc:0.6808\n",
      "Epoch  349\n",
      "Accuracy ---->  0.7138416171073914\n",
      "Iter:349 train_rmse:4.129 test_loss:130.1 test_rmse:0.05301 test_acc:0.6808\n",
      "Epoch  350\n",
      "Accuracy ---->  0.7139308154582977\n",
      "Iter:350 train_rmse:4.128 test_loss:130.1 test_rmse:0.053 test_acc:0.6809\n",
      "Epoch  351\n",
      "Accuracy ---->  0.714019775390625\n",
      "Iter:351 train_rmse:4.127 test_loss:130.0 test_rmse:0.05298 test_acc:0.681\n",
      "Epoch  352\n",
      "Accuracy ---->  0.7141086459159851\n",
      "Iter:352 train_rmse:4.126 test_loss:129.9 test_rmse:0.05296 test_acc:0.6811\n",
      "Epoch  353\n",
      "Accuracy ---->  0.7141972482204437\n",
      "Iter:353 train_rmse:4.124 test_loss:129.8 test_rmse:0.05295 test_acc:0.6812\n",
      "Epoch  354\n",
      "Accuracy ---->  0.7142856419086456\n",
      "Iter:354 train_rmse:4.123 test_loss:129.8 test_rmse:0.05293 test_acc:0.6813\n",
      "Epoch  355\n",
      "Accuracy ---->  0.7143740057945251\n",
      "Iter:355 train_rmse:4.122 test_loss:129.7 test_rmse:0.05291 test_acc:0.6814\n",
      "Epoch  356\n",
      "Accuracy ---->  0.714462161064148\n",
      "Iter:356 train_rmse:4.121 test_loss:129.6 test_rmse:0.0529 test_acc:0.6815\n",
      "Epoch  357\n",
      "Accuracy ---->  0.7145501971244812\n",
      "Iter:357 train_rmse:4.119 test_loss:129.5 test_rmse:0.05288 test_acc:0.6816\n",
      "Epoch  358\n",
      "Accuracy ---->  0.7146381437778473\n",
      "Iter:358 train_rmse:4.118 test_loss:129.4 test_rmse:0.05287 test_acc:0.6817\n",
      "Epoch  359\n",
      "Accuracy ---->  0.7147258520126343\n",
      "Iter:359 train_rmse:4.117 test_loss:129.4 test_rmse:0.05285 test_acc:0.6818\n",
      "Epoch  360\n",
      "Accuracy ---->  0.7148135006427765\n",
      "Iter:360 train_rmse:4.115 test_loss:129.3 test_rmse:0.05283 test_acc:0.6819\n",
      "Epoch  361\n",
      "Accuracy ---->  0.7149009704589844\n",
      "Iter:361 train_rmse:4.114 test_loss:129.2 test_rmse:0.05282 test_acc:0.682\n",
      "Epoch  362\n",
      "Accuracy ---->  0.7149882912635803\n",
      "Iter:362 train_rmse:4.113 test_loss:129.1 test_rmse:0.0528 test_acc:0.6821\n",
      "Epoch  363\n",
      "Accuracy ---->  0.7150754332542419\n",
      "Iter:363 train_rmse:4.112 test_loss:129.1 test_rmse:0.05279 test_acc:0.6822\n",
      "Epoch  364\n",
      "Accuracy ---->  0.7151624262332916\n",
      "Iter:364 train_rmse:4.11 test_loss:129.0 test_rmse:0.05277 test_acc:0.6823\n",
      "Epoch  365\n",
      "Accuracy ---->  0.7152491509914398\n",
      "Iter:365 train_rmse:4.109 test_loss:128.9 test_rmse:0.05275 test_acc:0.6824\n",
      "Epoch  366\n",
      "Accuracy ---->  0.7153358161449432\n",
      "Iter:366 train_rmse:4.108 test_loss:128.8 test_rmse:0.05274 test_acc:0.6825\n",
      "Epoch  367\n",
      "Accuracy ---->  0.7154222726821899\n",
      "Iter:367 train_rmse:4.107 test_loss:128.7 test_rmse:0.05272 test_acc:0.6826\n",
      "Epoch  368\n",
      "Accuracy ---->  0.7155084609985352\n",
      "Iter:368 train_rmse:4.105 test_loss:128.7 test_rmse:0.05271 test_acc:0.6827\n",
      "Epoch  369\n",
      "Accuracy ---->  0.715594470500946\n",
      "Iter:369 train_rmse:4.104 test_loss:128.6 test_rmse:0.05269 test_acc:0.6828\n",
      "Epoch  370\n",
      "Accuracy ---->  0.7156801223754883\n",
      "Iter:370 train_rmse:4.103 test_loss:128.5 test_rmse:0.05268 test_acc:0.6829\n",
      "Epoch  371\n",
      "Accuracy ---->  0.715765655040741\n",
      "Iter:371 train_rmse:4.102 test_loss:128.4 test_rmse:0.05266 test_acc:0.683\n",
      "Epoch  372\n",
      "Accuracy ---->  0.7158508598804474\n",
      "Iter:372 train_rmse:4.1 test_loss:128.4 test_rmse:0.05265 test_acc:0.683\n",
      "Epoch  373\n",
      "Accuracy ---->  0.7159357666969299\n",
      "Iter:373 train_rmse:4.099 test_loss:128.3 test_rmse:0.05263 test_acc:0.6831\n",
      "Epoch  374\n",
      "Accuracy ---->  0.7160205245018005\n",
      "Iter:374 train_rmse:4.098 test_loss:128.2 test_rmse:0.05261 test_acc:0.6832\n",
      "Epoch  375\n",
      "Accuracy ---->  0.7161048948764801\n",
      "Iter:375 train_rmse:4.097 test_loss:128.1 test_rmse:0.0526 test_acc:0.6833\n",
      "Epoch  376\n",
      "Accuracy ---->  0.716189056634903\n",
      "Iter:376 train_rmse:4.096 test_loss:128.1 test_rmse:0.05258 test_acc:0.6834\n",
      "Epoch  377\n",
      "Accuracy ---->  0.71627277135849\n",
      "Iter:377 train_rmse:4.094 test_loss:128.0 test_rmse:0.05257 test_acc:0.6835\n",
      "Epoch  378\n",
      "Accuracy ---->  0.7163563072681427\n",
      "Iter:378 train_rmse:4.093 test_loss:127.9 test_rmse:0.05255 test_acc:0.6836\n",
      "Epoch  379\n",
      "Accuracy ---->  0.7164394557476044\n",
      "Iter:379 train_rmse:4.092 test_loss:127.9 test_rmse:0.05254 test_acc:0.6837\n",
      "Epoch  380\n",
      "Accuracy ---->  0.7165222764015198\n",
      "Iter:380 train_rmse:4.091 test_loss:127.8 test_rmse:0.05252 test_acc:0.6838\n",
      "Epoch  381\n",
      "Accuracy ---->  0.7166047096252441\n",
      "Iter:381 train_rmse:4.09 test_loss:127.7 test_rmse:0.05251 test_acc:0.6839\n",
      "Epoch  382\n",
      "Accuracy ---->  0.7166868448257446\n",
      "Iter:382 train_rmse:4.088 test_loss:127.6 test_rmse:0.0525 test_acc:0.684\n",
      "Epoch  383\n",
      "Accuracy ---->  0.7167684733867645\n",
      "Iter:383 train_rmse:4.087 test_loss:127.6 test_rmse:0.05248 test_acc:0.684\n",
      "Epoch  384\n",
      "Accuracy ---->  0.7168499231338501\n",
      "Iter:384 train_rmse:4.086 test_loss:127.5 test_rmse:0.05247 test_acc:0.6841\n",
      "Epoch  385\n",
      "Accuracy ---->  0.7169308066368103\n",
      "Iter:385 train_rmse:4.085 test_loss:127.4 test_rmse:0.05245 test_acc:0.6842\n",
      "Epoch  386\n",
      "Accuracy ---->  0.7170113027095795\n",
      "Iter:386 train_rmse:4.084 test_loss:127.4 test_rmse:0.05244 test_acc:0.6843\n",
      "Epoch  387\n",
      "Accuracy ---->  0.7170913219451904\n",
      "Iter:387 train_rmse:4.083 test_loss:127.3 test_rmse:0.05242 test_acc:0.6844\n",
      "Epoch  388\n",
      "Accuracy ---->  0.7171710133552551\n",
      "Iter:388 train_rmse:4.081 test_loss:127.2 test_rmse:0.05241 test_acc:0.6845\n",
      "Epoch  389\n",
      "Accuracy ---->  0.7172502279281616\n",
      "Iter:389 train_rmse:4.08 test_loss:127.2 test_rmse:0.0524 test_acc:0.6846\n",
      "Epoch  390\n",
      "Accuracy ---->  0.7173289060592651\n",
      "Iter:390 train_rmse:4.079 test_loss:127.1 test_rmse:0.05238 test_acc:0.6846\n",
      "Epoch  391\n",
      "Accuracy ---->  0.7174071073532104\n",
      "Iter:391 train_rmse:4.078 test_loss:127.0 test_rmse:0.05237 test_acc:0.6847\n",
      "Epoch  392\n",
      "Accuracy ---->  0.7174848914146423\n",
      "Iter:392 train_rmse:4.077 test_loss:127.0 test_rmse:0.05235 test_acc:0.6848\n",
      "Epoch  393\n",
      "Accuracy ---->  0.7175622582435608\n",
      "Iter:393 train_rmse:4.076 test_loss:126.9 test_rmse:0.05234 test_acc:0.6849\n",
      "Epoch  394\n",
      "Accuracy ---->  0.7176389992237091\n",
      "Iter:394 train_rmse:4.075 test_loss:126.8 test_rmse:0.05233 test_acc:0.685\n",
      "Epoch  395\n",
      "Accuracy ---->  0.717715322971344\n",
      "Iter:395 train_rmse:4.074 test_loss:126.8 test_rmse:0.05231 test_acc:0.685\n",
      "Epoch  396\n",
      "Accuracy ---->  0.7177911698818207\n",
      "Iter:396 train_rmse:4.072 test_loss:126.7 test_rmse:0.0523 test_acc:0.6851\n",
      "Epoch  397\n",
      "Accuracy ---->  0.7178665399551392\n",
      "Iter:397 train_rmse:4.071 test_loss:126.6 test_rmse:0.05229 test_acc:0.6852\n",
      "Epoch  398\n",
      "Accuracy ---->  0.7179413735866547\n",
      "Iter:398 train_rmse:4.07 test_loss:126.6 test_rmse:0.05227 test_acc:0.6853\n",
      "Epoch  399\n",
      "Accuracy ---->  0.7180157601833344\n",
      "Iter:399 train_rmse:4.069 test_loss:126.5 test_rmse:0.05226 test_acc:0.6854\n",
      "Epoch  400\n",
      "Accuracy ---->  0.7180894911289215\n",
      "Iter:400 train_rmse:4.068 test_loss:126.5 test_rmse:0.05225 test_acc:0.6854\n",
      "Epoch  401\n",
      "Accuracy ---->  0.7181629538536072\n",
      "Iter:401 train_rmse:4.067 test_loss:126.4 test_rmse:0.05223 test_acc:0.6855\n",
      "Epoch  402\n",
      "Accuracy ---->  0.7182358205318451\n",
      "Iter:402 train_rmse:4.066 test_loss:126.3 test_rmse:0.05222 test_acc:0.6856\n",
      "Epoch  403\n",
      "Accuracy ---->  0.7183082401752472\n",
      "Iter:403 train_rmse:4.065 test_loss:126.3 test_rmse:0.05221 test_acc:0.6857\n",
      "Epoch  404\n",
      "Accuracy ---->  0.7183802723884583\n",
      "Iter:404 train_rmse:4.064 test_loss:126.2 test_rmse:0.0522 test_acc:0.6858\n",
      "Epoch  405\n",
      "Accuracy ---->  0.7184519469738007\n",
      "Iter:405 train_rmse:4.063 test_loss:126.1 test_rmse:0.05218 test_acc:0.6858\n",
      "Epoch  406\n",
      "Accuracy ---->  0.7185231149196625\n",
      "Iter:406 train_rmse:4.062 test_loss:126.1 test_rmse:0.05217 test_acc:0.6859\n",
      "Epoch  407\n",
      "Accuracy ---->  0.7185937464237213\n",
      "Iter:407 train_rmse:4.061 test_loss:126.0 test_rmse:0.05216 test_acc:0.686\n",
      "Epoch  408\n",
      "Accuracy ---->  0.7186641097068787\n",
      "Iter:408 train_rmse:4.06 test_loss:126.0 test_rmse:0.05215 test_acc:0.6861\n",
      "Epoch  409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.718734085559845\n",
      "Iter:409 train_rmse:4.059 test_loss:125.9 test_rmse:0.05213 test_acc:0.6861\n",
      "Epoch  410\n",
      "Accuracy ---->  0.7188036739826202\n",
      "Iter:410 train_rmse:4.058 test_loss:125.8 test_rmse:0.05212 test_acc:0.6862\n",
      "Epoch  411\n",
      "Accuracy ---->  0.7188729047775269\n",
      "Iter:411 train_rmse:4.057 test_loss:125.8 test_rmse:0.05211 test_acc:0.6863\n",
      "Epoch  412\n",
      "Accuracy ---->  0.7189417481422424\n",
      "Iter:412 train_rmse:4.056 test_loss:125.7 test_rmse:0.0521 test_acc:0.6863\n",
      "Epoch  413\n",
      "Accuracy ---->  0.7190103232860565\n",
      "Iter:413 train_rmse:4.055 test_loss:125.7 test_rmse:0.05208 test_acc:0.6864\n",
      "Epoch  414\n",
      "Accuracy ---->  0.7190785706043243\n",
      "Iter:414 train_rmse:4.054 test_loss:125.6 test_rmse:0.05207 test_acc:0.6865\n",
      "Epoch  415\n",
      "Accuracy ---->  0.7191464602947235\n",
      "Iter:415 train_rmse:4.053 test_loss:125.6 test_rmse:0.05206 test_acc:0.6866\n",
      "Epoch  416\n",
      "Accuracy ---->  0.7192140817642212\n",
      "Iter:416 train_rmse:4.052 test_loss:125.5 test_rmse:0.05205 test_acc:0.6866\n",
      "Epoch  417\n",
      "Accuracy ---->  0.719281405210495\n",
      "Iter:417 train_rmse:4.051 test_loss:125.4 test_rmse:0.05204 test_acc:0.6867\n",
      "Epoch  418\n",
      "Accuracy ---->  0.7193484008312225\n",
      "Iter:418 train_rmse:4.05 test_loss:125.4 test_rmse:0.05203 test_acc:0.6868\n",
      "Epoch  419\n",
      "Accuracy ---->  0.7194151282310486\n",
      "Iter:419 train_rmse:4.049 test_loss:125.3 test_rmse:0.05201 test_acc:0.6869\n",
      "Epoch  420\n",
      "Accuracy ---->  0.7194815874099731\n",
      "Iter:420 train_rmse:4.048 test_loss:125.3 test_rmse:0.052 test_acc:0.6869\n",
      "Epoch  421\n",
      "Accuracy ---->  0.7195477187633514\n",
      "Iter:421 train_rmse:4.047 test_loss:125.2 test_rmse:0.05199 test_acc:0.687\n",
      "Epoch  422\n",
      "Accuracy ---->  0.7196136713027954\n",
      "Iter:422 train_rmse:4.046 test_loss:125.2 test_rmse:0.05198 test_acc:0.6871\n",
      "Epoch  423\n",
      "Accuracy ---->  0.7196791768074036\n",
      "Iter:423 train_rmse:4.045 test_loss:125.1 test_rmse:0.05197 test_acc:0.6871\n",
      "Epoch  424\n",
      "Accuracy ---->  0.7197444438934326\n",
      "Iter:424 train_rmse:4.044 test_loss:125.1 test_rmse:0.05195 test_acc:0.6872\n",
      "Epoch  425\n",
      "Accuracy ---->  0.719809353351593\n",
      "Iter:425 train_rmse:4.043 test_loss:125.0 test_rmse:0.05194 test_acc:0.6873\n",
      "Epoch  426\n",
      "Accuracy ---->  0.7198740541934967\n",
      "Iter:426 train_rmse:4.042 test_loss:124.9 test_rmse:0.05193 test_acc:0.6873\n",
      "Epoch  427\n",
      "Accuracy ---->  0.7199384272098541\n",
      "Iter:427 train_rmse:4.041 test_loss:124.9 test_rmse:0.05192 test_acc:0.6874\n",
      "Epoch  428\n",
      "Accuracy ---->  0.7200024127960205\n",
      "Iter:428 train_rmse:4.041 test_loss:124.8 test_rmse:0.05191 test_acc:0.6875\n",
      "Epoch  429\n",
      "Accuracy ---->  0.7200661599636078\n",
      "Iter:429 train_rmse:4.04 test_loss:124.8 test_rmse:0.0519 test_acc:0.6875\n",
      "Epoch  430\n",
      "Accuracy ---->  0.7201294898986816\n",
      "Iter:430 train_rmse:4.039 test_loss:124.7 test_rmse:0.05189 test_acc:0.6876\n",
      "Epoch  431\n",
      "Accuracy ---->  0.720192551612854\n",
      "Iter:431 train_rmse:4.038 test_loss:124.7 test_rmse:0.05188 test_acc:0.6877\n",
      "Epoch  432\n",
      "Accuracy ---->  0.7202552258968353\n",
      "Iter:432 train_rmse:4.037 test_loss:124.6 test_rmse:0.05186 test_acc:0.6877\n",
      "Epoch  433\n",
      "Accuracy ---->  0.7203175723552704\n",
      "Iter:433 train_rmse:4.036 test_loss:124.6 test_rmse:0.05185 test_acc:0.6878\n",
      "Epoch  434\n",
      "Accuracy ---->  0.7203795611858368\n",
      "Iter:434 train_rmse:4.035 test_loss:124.5 test_rmse:0.05184 test_acc:0.6879\n",
      "Epoch  435\n",
      "Accuracy ---->  0.7204412519931793\n",
      "Iter:435 train_rmse:4.034 test_loss:124.5 test_rmse:0.05183 test_acc:0.6879\n",
      "Epoch  436\n",
      "Accuracy ---->  0.7205024063587189\n",
      "Iter:436 train_rmse:4.033 test_loss:124.4 test_rmse:0.05182 test_acc:0.688\n",
      "Epoch  437\n",
      "Accuracy ---->  0.7205633521080017\n",
      "Iter:437 train_rmse:4.032 test_loss:124.4 test_rmse:0.05181 test_acc:0.6881\n",
      "Epoch  438\n",
      "Accuracy ---->  0.7206239700317383\n",
      "Iter:438 train_rmse:4.032 test_loss:124.3 test_rmse:0.0518 test_acc:0.6881\n",
      "Epoch  439\n",
      "Accuracy ---->  0.720684140920639\n",
      "Iter:439 train_rmse:4.031 test_loss:124.3 test_rmse:0.05179 test_acc:0.6882\n",
      "Epoch  440\n",
      "Accuracy ---->  0.7207440733909607\n",
      "Iter:440 train_rmse:4.03 test_loss:124.2 test_rmse:0.05178 test_acc:0.6883\n",
      "Epoch  441\n",
      "Accuracy ---->  0.7208034992218018\n",
      "Iter:441 train_rmse:4.029 test_loss:124.2 test_rmse:0.05177 test_acc:0.6883\n",
      "Epoch  442\n",
      "Accuracy ---->  0.7208627462387085\n",
      "Iter:442 train_rmse:4.028 test_loss:124.1 test_rmse:0.05176 test_acc:0.6884\n",
      "Epoch  443\n",
      "Accuracy ---->  0.7209215462207794\n",
      "Iter:443 train_rmse:4.027 test_loss:124.1 test_rmse:0.05175 test_acc:0.6885\n",
      "Epoch  444\n",
      "Accuracy ---->  0.7209799885749817\n",
      "Iter:444 train_rmse:4.026 test_loss:124.0 test_rmse:0.05174 test_acc:0.6885\n",
      "Epoch  445\n",
      "Accuracy ---->  0.7210381031036377\n",
      "Iter:445 train_rmse:4.026 test_loss:124.0 test_rmse:0.05173 test_acc:0.6886\n",
      "Epoch  446\n",
      "Accuracy ---->  0.721096009016037\n",
      "Iter:446 train_rmse:4.025 test_loss:123.9 test_rmse:0.05172 test_acc:0.6886\n",
      "Epoch  447\n",
      "Accuracy ---->  0.7211534976959229\n",
      "Iter:447 train_rmse:4.024 test_loss:123.9 test_rmse:0.05171 test_acc:0.6887\n",
      "Epoch  448\n",
      "Accuracy ---->  0.721210777759552\n",
      "Iter:448 train_rmse:4.023 test_loss:123.8 test_rmse:0.0517 test_acc:0.6888\n",
      "Epoch  449\n",
      "Accuracy ---->  0.7212677299976349\n",
      "Iter:449 train_rmse:4.022 test_loss:123.8 test_rmse:0.05168 test_acc:0.6888\n",
      "Epoch  450\n",
      "Accuracy ---->  0.7213243842124939\n",
      "Iter:450 train_rmse:4.021 test_loss:123.7 test_rmse:0.05167 test_acc:0.6889\n",
      "Epoch  451\n",
      "Accuracy ---->  0.7213808000087738\n",
      "Iter:451 train_rmse:4.021 test_loss:123.7 test_rmse:0.05166 test_acc:0.689\n",
      "Epoch  452\n",
      "Accuracy ---->  0.7214369475841522\n",
      "Iter:452 train_rmse:4.02 test_loss:123.6 test_rmse:0.05165 test_acc:0.689\n",
      "Epoch  453\n",
      "Accuracy ---->  0.7214929759502411\n",
      "Iter:453 train_rmse:4.019 test_loss:123.6 test_rmse:0.05164 test_acc:0.6891\n",
      "Epoch  454\n",
      "Accuracy ---->  0.7215487957000732\n",
      "Iter:454 train_rmse:4.018 test_loss:123.5 test_rmse:0.05163 test_acc:0.6891\n",
      "Epoch  455\n",
      "Accuracy ---->  0.721604198217392\n",
      "Iter:455 train_rmse:4.017 test_loss:123.5 test_rmse:0.05162 test_acc:0.6892\n",
      "Epoch  456\n",
      "Accuracy ---->  0.7216595709323883\n",
      "Iter:456 train_rmse:4.017 test_loss:123.4 test_rmse:0.05161 test_acc:0.6893\n",
      "Epoch  457\n",
      "Accuracy ---->  0.7217146456241608\n",
      "Iter:457 train_rmse:4.016 test_loss:123.4 test_rmse:0.0516 test_acc:0.6893\n",
      "Epoch  458\n",
      "Accuracy ---->  0.7217695713043213\n",
      "Iter:458 train_rmse:4.015 test_loss:123.3 test_rmse:0.05159 test_acc:0.6894\n",
      "Epoch  459\n",
      "Accuracy ---->  0.7218243479728699\n",
      "Iter:459 train_rmse:4.014 test_loss:123.3 test_rmse:0.05158 test_acc:0.6894\n",
      "Epoch  460\n",
      "Accuracy ---->  0.7218789756298065\n",
      "Iter:460 train_rmse:4.013 test_loss:123.2 test_rmse:0.05157 test_acc:0.6895\n",
      "Epoch  461\n",
      "Accuracy ---->  0.7219333946704865\n",
      "Iter:461 train_rmse:4.013 test_loss:123.2 test_rmse:0.05156 test_acc:0.6896\n",
      "Epoch  462\n",
      "Accuracy ---->  0.7219879627227783\n",
      "Iter:462 train_rmse:4.012 test_loss:123.1 test_rmse:0.05155 test_acc:0.6896\n",
      "Epoch  463\n",
      "Accuracy ---->  0.7220421731472015\n",
      "Iter:463 train_rmse:4.011 test_loss:123.1 test_rmse:0.05155 test_acc:0.6897\n",
      "Epoch  464\n",
      "Accuracy ---->  0.7220962941646576\n",
      "Iter:464 train_rmse:4.01 test_loss:123.1 test_rmse:0.05154 test_acc:0.6897\n",
      "Epoch  465\n",
      "Accuracy ---->  0.722150444984436\n",
      "Iter:465 train_rmse:4.01 test_loss:123.0 test_rmse:0.05153 test_acc:0.6898\n",
      "Epoch  466\n",
      "Accuracy ---->  0.7222044467926025\n",
      "Iter:466 train_rmse:4.009 test_loss:123.0 test_rmse:0.05152 test_acc:0.6898\n",
      "Epoch  467\n",
      "Accuracy ---->  0.7222582995891571\n",
      "Iter:467 train_rmse:4.008 test_loss:122.9 test_rmse:0.05151 test_acc:0.6899\n",
      "Epoch  468\n",
      "Accuracy ---->  0.7223121225833893\n",
      "Iter:468 train_rmse:4.007 test_loss:122.9 test_rmse:0.0515 test_acc:0.69\n",
      "Epoch  469\n",
      "Accuracy ---->  0.7223660051822662\n",
      "Iter:469 train_rmse:4.006 test_loss:122.8 test_rmse:0.05149 test_acc:0.69\n",
      "Epoch  470\n",
      "Accuracy ---->  0.7224196493625641\n",
      "Iter:470 train_rmse:4.006 test_loss:122.8 test_rmse:0.05148 test_acc:0.6901\n",
      "Epoch  471\n",
      "Accuracy ---->  0.7224733531475067\n",
      "Iter:471 train_rmse:4.005 test_loss:122.7 test_rmse:0.05147 test_acc:0.6901\n",
      "Epoch  472\n",
      "Accuracy ---->  0.7225268185138702\n",
      "Iter:472 train_rmse:4.004 test_loss:122.7 test_rmse:0.05146 test_acc:0.6902\n",
      "Epoch  473\n",
      "Accuracy ---->  0.7225803434848785\n",
      "Iter:473 train_rmse:4.003 test_loss:122.6 test_rmse:0.05145 test_acc:0.6903\n",
      "Epoch  474\n",
      "Accuracy ---->  0.7226339280605316\n",
      "Iter:474 train_rmse:4.003 test_loss:122.6 test_rmse:0.05144 test_acc:0.6903\n",
      "Epoch  475\n",
      "Accuracy ---->  0.722687304019928\n",
      "Iter:475 train_rmse:4.002 test_loss:122.6 test_rmse:0.05143 test_acc:0.6904\n",
      "Epoch  476\n",
      "Accuracy ---->  0.722740650177002\n",
      "Iter:476 train_rmse:4.001 test_loss:122.5 test_rmse:0.05142 test_acc:0.6904\n",
      "Epoch  477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.7227940261363983\n",
      "Iter:477 train_rmse:4.0 test_loss:122.5 test_rmse:0.05141 test_acc:0.6905\n",
      "Epoch  478\n",
      "Accuracy ---->  0.722847193479538\n",
      "Iter:478 train_rmse:4.0 test_loss:122.4 test_rmse:0.0514 test_acc:0.6905\n",
      "Epoch  479\n",
      "Accuracy ---->  0.7229005098342896\n",
      "Iter:479 train_rmse:3.999 test_loss:122.4 test_rmse:0.05139 test_acc:0.6906\n",
      "Epoch  480\n",
      "Accuracy ---->  0.7229536473751068\n",
      "Iter:480 train_rmse:3.998 test_loss:122.3 test_rmse:0.05138 test_acc:0.6907\n",
      "Epoch  481\n",
      "Accuracy ---->  0.7230068147182465\n",
      "Iter:481 train_rmse:3.997 test_loss:122.3 test_rmse:0.05137 test_acc:0.6907\n",
      "Epoch  482\n",
      "Accuracy ---->  0.7230598330497742\n",
      "Iter:482 train_rmse:3.996 test_loss:122.2 test_rmse:0.05136 test_acc:0.6908\n",
      "Epoch  483\n",
      "Accuracy ---->  0.7231128811836243\n",
      "Iter:483 train_rmse:3.996 test_loss:122.2 test_rmse:0.05135 test_acc:0.6908\n",
      "Epoch  484\n",
      "Accuracy ---->  0.723165899515152\n",
      "Iter:484 train_rmse:3.995 test_loss:122.2 test_rmse:0.05134 test_acc:0.6909\n",
      "Epoch  485\n",
      "Accuracy ---->  0.7232188284397125\n",
      "Iter:485 train_rmse:3.994 test_loss:122.1 test_rmse:0.05134 test_acc:0.6909\n",
      "Epoch  486\n",
      "Accuracy ---->  0.7232716381549835\n",
      "Iter:486 train_rmse:3.993 test_loss:122.1 test_rmse:0.05133 test_acc:0.691\n",
      "Epoch  487\n",
      "Accuracy ---->  0.7233244478702545\n",
      "Iter:487 train_rmse:3.993 test_loss:122.0 test_rmse:0.05132 test_acc:0.691\n",
      "Epoch  488\n",
      "Accuracy ---->  0.7233770489692688\n",
      "Iter:488 train_rmse:3.992 test_loss:122.0 test_rmse:0.05131 test_acc:0.6911\n",
      "Epoch  489\n",
      "Accuracy ---->  0.7234297692775726\n",
      "Iter:489 train_rmse:3.991 test_loss:121.9 test_rmse:0.0513 test_acc:0.6912\n",
      "Epoch  490\n",
      "Accuracy ---->  0.7234823107719421\n",
      "Iter:490 train_rmse:3.99 test_loss:121.9 test_rmse:0.05129 test_acc:0.6912\n",
      "Epoch  491\n",
      "Accuracy ---->  0.7235347032546997\n",
      "Iter:491 train_rmse:3.99 test_loss:121.8 test_rmse:0.05128 test_acc:0.6913\n",
      "Epoch  492\n",
      "Accuracy ---->  0.7235872149467468\n",
      "Iter:492 train_rmse:3.989 test_loss:121.8 test_rmse:0.05127 test_acc:0.6913\n",
      "Epoch  493\n",
      "Accuracy ---->  0.7236394882202148\n",
      "Iter:493 train_rmse:3.988 test_loss:121.8 test_rmse:0.05126 test_acc:0.6914\n",
      "Epoch  494\n",
      "Accuracy ---->  0.7236917912960052\n",
      "Iter:494 train_rmse:3.987 test_loss:121.7 test_rmse:0.05125 test_acc:0.6914\n",
      "Epoch  495\n",
      "Accuracy ---->  0.7237438261508942\n",
      "Iter:495 train_rmse:3.987 test_loss:121.7 test_rmse:0.05124 test_acc:0.6915\n",
      "Epoch  496\n",
      "Accuracy ---->  0.7237959206104279\n",
      "Iter:496 train_rmse:3.986 test_loss:121.6 test_rmse:0.05123 test_acc:0.6915\n",
      "Epoch  497\n",
      "Accuracy ---->  0.7238477170467377\n",
      "Iter:497 train_rmse:3.985 test_loss:121.6 test_rmse:0.05123 test_acc:0.6916\n",
      "Epoch  498\n",
      "Accuracy ---->  0.7238994240760803\n",
      "Iter:498 train_rmse:3.984 test_loss:121.5 test_rmse:0.05122 test_acc:0.6916\n",
      "Epoch  499\n",
      "Accuracy ---->  0.7239513099193573\n",
      "Iter:499 train_rmse:3.984 test_loss:121.5 test_rmse:0.05121 test_acc:0.6917\n",
      "Epoch  500\n",
      "Accuracy ---->  0.7240027189254761\n",
      "Iter:500 train_rmse:3.983 test_loss:121.5 test_rmse:0.0512 test_acc:0.6918\n",
      "Epoch  501\n",
      "Accuracy ---->  0.7240541875362396\n",
      "Iter:501 train_rmse:3.982 test_loss:121.4 test_rmse:0.05119 test_acc:0.6918\n",
      "Epoch  502\n",
      "Accuracy ---->  0.7241053879261017\n",
      "Iter:502 train_rmse:3.981 test_loss:121.4 test_rmse:0.05118 test_acc:0.6919\n",
      "Epoch  503\n",
      "Accuracy ---->  0.724156528711319\n",
      "Iter:503 train_rmse:3.981 test_loss:121.3 test_rmse:0.05117 test_acc:0.6919\n",
      "Epoch  504\n",
      "Accuracy ---->  0.7242076694965363\n",
      "Iter:504 train_rmse:3.98 test_loss:121.3 test_rmse:0.05116 test_acc:0.692\n",
      "Epoch  505\n",
      "Accuracy ---->  0.724258542060852\n",
      "Iter:505 train_rmse:3.979 test_loss:121.3 test_rmse:0.05116 test_acc:0.692\n",
      "Epoch  506\n",
      "Accuracy ---->  0.7243093252182007\n",
      "Iter:506 train_rmse:3.978 test_loss:121.2 test_rmse:0.05115 test_acc:0.6921\n",
      "Epoch  507\n",
      "Accuracy ---->  0.7243598103523254\n",
      "Iter:507 train_rmse:3.978 test_loss:121.2 test_rmse:0.05114 test_acc:0.6921\n",
      "Epoch  508\n",
      "Accuracy ---->  0.7244104146957397\n",
      "Iter:508 train_rmse:3.977 test_loss:121.1 test_rmse:0.05113 test_acc:0.6922\n",
      "Epoch  509\n",
      "Accuracy ---->  0.7244606018066406\n",
      "Iter:509 train_rmse:3.976 test_loss:121.1 test_rmse:0.05112 test_acc:0.6922\n",
      "Epoch  510\n",
      "Accuracy ---->  0.7245106399059296\n",
      "Iter:510 train_rmse:3.975 test_loss:121.1 test_rmse:0.05111 test_acc:0.6923\n",
      "Epoch  511\n",
      "Accuracy ---->  0.7245607972145081\n",
      "Iter:511 train_rmse:3.975 test_loss:121.0 test_rmse:0.0511 test_acc:0.6923\n",
      "Epoch  512\n",
      "Accuracy ---->  0.7246104776859283\n",
      "Iter:512 train_rmse:3.974 test_loss:121.0 test_rmse:0.0511 test_acc:0.6924\n",
      "Epoch  513\n",
      "Accuracy ---->  0.7246600687503815\n",
      "Iter:513 train_rmse:3.973 test_loss:120.9 test_rmse:0.05109 test_acc:0.6924\n",
      "Epoch  514\n",
      "Accuracy ---->  0.7247096300125122\n",
      "Iter:514 train_rmse:3.973 test_loss:120.9 test_rmse:0.05108 test_acc:0.6925\n",
      "Epoch  515\n",
      "Accuracy ---->  0.7247587740421295\n",
      "Iter:515 train_rmse:3.972 test_loss:120.9 test_rmse:0.05107 test_acc:0.6925\n",
      "Epoch  516\n",
      "Accuracy ---->  0.7248080372810364\n",
      "Iter:516 train_rmse:3.971 test_loss:120.8 test_rmse:0.05106 test_acc:0.6926\n",
      "Epoch  517\n",
      "Accuracy ---->  0.7248569130897522\n",
      "Iter:517 train_rmse:3.971 test_loss:120.8 test_rmse:0.05105 test_acc:0.6926\n",
      "Epoch  518\n",
      "Accuracy ---->  0.7249056398868561\n",
      "Iter:518 train_rmse:3.97 test_loss:120.7 test_rmse:0.05105 test_acc:0.6927\n",
      "Epoch  519\n",
      "Accuracy ---->  0.7249541282653809\n",
      "Iter:519 train_rmse:3.969 test_loss:120.7 test_rmse:0.05104 test_acc:0.6927\n",
      "Epoch  520\n",
      "Accuracy ---->  0.7250025272369385\n",
      "Iter:520 train_rmse:3.968 test_loss:120.7 test_rmse:0.05103 test_acc:0.6928\n",
      "Epoch  521\n",
      "Accuracy ---->  0.7250507175922394\n",
      "Iter:521 train_rmse:3.968 test_loss:120.6 test_rmse:0.05102 test_acc:0.6928\n",
      "Epoch  522\n",
      "Accuracy ---->  0.725098729133606\n",
      "Iter:522 train_rmse:3.967 test_loss:120.6 test_rmse:0.05101 test_acc:0.6929\n",
      "Epoch  523\n",
      "Accuracy ---->  0.725146472454071\n",
      "Iter:523 train_rmse:3.966 test_loss:120.6 test_rmse:0.05101 test_acc:0.6929\n",
      "Epoch  524\n",
      "Accuracy ---->  0.725194126367569\n",
      "Iter:524 train_rmse:3.966 test_loss:120.5 test_rmse:0.051 test_acc:0.693\n",
      "Epoch  525\n",
      "Accuracy ---->  0.725241482257843\n",
      "Iter:525 train_rmse:3.965 test_loss:120.5 test_rmse:0.05099 test_acc:0.693\n",
      "Epoch  526\n",
      "Accuracy ---->  0.7252886891365051\n",
      "Iter:526 train_rmse:3.964 test_loss:120.4 test_rmse:0.05098 test_acc:0.6931\n",
      "Epoch  527\n",
      "Accuracy ---->  0.7253358066082001\n",
      "Iter:527 train_rmse:3.964 test_loss:120.4 test_rmse:0.05097 test_acc:0.6931\n",
      "Epoch  528\n",
      "Accuracy ---->  0.7253824174404144\n",
      "Iter:528 train_rmse:3.963 test_loss:120.4 test_rmse:0.05097 test_acc:0.6932\n",
      "Epoch  529\n",
      "Accuracy ---->  0.725429117679596\n",
      "Iter:529 train_rmse:3.962 test_loss:120.3 test_rmse:0.05096 test_acc:0.6932\n",
      "Epoch  530\n",
      "Accuracy ---->  0.7254755795001984\n",
      "Iter:530 train_rmse:3.962 test_loss:120.3 test_rmse:0.05095 test_acc:0.6933\n",
      "Epoch  531\n",
      "Accuracy ---->  0.7255218327045441\n",
      "Iter:531 train_rmse:3.961 test_loss:120.3 test_rmse:0.05094 test_acc:0.6933\n",
      "Epoch  532\n",
      "Accuracy ---->  0.7255677580833435\n",
      "Iter:532 train_rmse:3.96 test_loss:120.2 test_rmse:0.05093 test_acc:0.6933\n",
      "Epoch  533\n",
      "Accuracy ---->  0.7256137430667877\n",
      "Iter:533 train_rmse:3.96 test_loss:120.2 test_rmse:0.05093 test_acc:0.6934\n",
      "Epoch  534\n",
      "Accuracy ---->  0.7256593406200409\n",
      "Iter:534 train_rmse:3.959 test_loss:120.1 test_rmse:0.05092 test_acc:0.6934\n",
      "Epoch  535\n",
      "Accuracy ---->  0.7257047593593597\n",
      "Iter:535 train_rmse:3.958 test_loss:120.1 test_rmse:0.05091 test_acc:0.6935\n",
      "Epoch  536\n",
      "Accuracy ---->  0.7257499098777771\n",
      "Iter:536 train_rmse:3.958 test_loss:120.1 test_rmse:0.0509 test_acc:0.6935\n",
      "Epoch  537\n",
      "Accuracy ---->  0.7257950603961945\n",
      "Iter:537 train_rmse:3.957 test_loss:120.0 test_rmse:0.0509 test_acc:0.6936\n",
      "Epoch  538\n",
      "Accuracy ---->  0.7258398830890656\n",
      "Iter:538 train_rmse:3.956 test_loss:120.0 test_rmse:0.05089 test_acc:0.6936\n",
      "Epoch  539\n",
      "Accuracy ---->  0.7258844673633575\n",
      "Iter:539 train_rmse:3.956 test_loss:120.0 test_rmse:0.05088 test_acc:0.6937\n",
      "Epoch  540\n",
      "Accuracy ---->  0.7259290516376495\n",
      "Iter:540 train_rmse:3.955 test_loss:119.9 test_rmse:0.05087 test_acc:0.6937\n",
      "Epoch  541\n",
      "Accuracy ---->  0.7259732186794281\n",
      "Iter:541 train_rmse:3.954 test_loss:119.9 test_rmse:0.05087 test_acc:0.6938\n",
      "Epoch  542\n",
      "Accuracy ---->  0.7260172367095947\n",
      "Iter:542 train_rmse:3.954 test_loss:119.9 test_rmse:0.05086 test_acc:0.6938\n",
      "Epoch  543\n",
      "Accuracy ---->  0.7260611057281494\n",
      "Iter:543 train_rmse:3.953 test_loss:119.8 test_rmse:0.05085 test_acc:0.6938\n",
      "Epoch  544\n",
      "Accuracy ---->  0.7261048853397369\n",
      "Iter:544 train_rmse:3.952 test_loss:119.8 test_rmse:0.05084 test_acc:0.6939\n",
      "Epoch  545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.7261484563350677\n",
      "Iter:545 train_rmse:3.952 test_loss:119.8 test_rmse:0.05084 test_acc:0.6939\n",
      "Epoch  546\n",
      "Accuracy ---->  0.7261917293071747\n",
      "Iter:546 train_rmse:3.951 test_loss:119.7 test_rmse:0.05083 test_acc:0.694\n",
      "Epoch  547\n",
      "Accuracy ---->  0.7262347340583801\n",
      "Iter:547 train_rmse:3.951 test_loss:119.7 test_rmse:0.05082 test_acc:0.694\n",
      "Epoch  548\n",
      "Accuracy ---->  0.7262778282165527\n",
      "Iter:548 train_rmse:3.95 test_loss:119.7 test_rmse:0.05082 test_acc:0.6941\n",
      "Epoch  549\n",
      "Accuracy ---->  0.7263204455375671\n",
      "Iter:549 train_rmse:3.949 test_loss:119.6 test_rmse:0.05081 test_acc:0.6941\n",
      "Epoch  550\n",
      "Accuracy ---->  0.7263631522655487\n",
      "Iter:550 train_rmse:3.949 test_loss:119.6 test_rmse:0.0508 test_acc:0.6942\n",
      "Epoch  551\n",
      "Accuracy ---->  0.726405531167984\n",
      "Iter:551 train_rmse:3.948 test_loss:119.6 test_rmse:0.05079 test_acc:0.6942\n",
      "Epoch  552\n",
      "Accuracy ---->  0.7264477610588074\n",
      "Iter:552 train_rmse:3.948 test_loss:119.5 test_rmse:0.05079 test_acc:0.6942\n",
      "Epoch  553\n",
      "Accuracy ---->  0.7264897525310516\n",
      "Iter:553 train_rmse:3.947 test_loss:119.5 test_rmse:0.05078 test_acc:0.6943\n",
      "Epoch  554\n",
      "Accuracy ---->  0.7265316545963287\n",
      "Iter:554 train_rmse:3.946 test_loss:119.5 test_rmse:0.05077 test_acc:0.6943\n",
      "Epoch  555\n",
      "Accuracy ---->  0.7265734076499939\n",
      "Iter:555 train_rmse:3.946 test_loss:119.4 test_rmse:0.05077 test_acc:0.6944\n",
      "Epoch  556\n",
      "Accuracy ---->  0.7266149520874023\n",
      "Iter:556 train_rmse:3.945 test_loss:119.4 test_rmse:0.05076 test_acc:0.6944\n",
      "Epoch  557\n",
      "Accuracy ---->  0.7266564071178436\n",
      "Iter:557 train_rmse:3.945 test_loss:119.4 test_rmse:0.05075 test_acc:0.6945\n",
      "Epoch  558\n",
      "Accuracy ---->  0.7266975939273834\n",
      "Iter:558 train_rmse:3.944 test_loss:119.3 test_rmse:0.05074 test_acc:0.6945\n",
      "Epoch  559\n",
      "Accuracy ---->  0.726738691329956\n",
      "Iter:559 train_rmse:3.943 test_loss:119.3 test_rmse:0.05074 test_acc:0.6945\n",
      "Epoch  560\n",
      "Accuracy ---->  0.7267796099185944\n",
      "Iter:560 train_rmse:3.943 test_loss:119.3 test_rmse:0.05073 test_acc:0.6946\n",
      "Epoch  561\n",
      "Accuracy ---->  0.7268204391002655\n",
      "Iter:561 train_rmse:3.942 test_loss:119.2 test_rmse:0.05072 test_acc:0.6946\n",
      "Epoch  562\n",
      "Accuracy ---->  0.7268609404563904\n",
      "Iter:562 train_rmse:3.942 test_loss:119.2 test_rmse:0.05072 test_acc:0.6947\n",
      "Epoch  563\n",
      "Accuracy ---->  0.7269013822078705\n",
      "Iter:563 train_rmse:3.941 test_loss:119.2 test_rmse:0.05071 test_acc:0.6947\n",
      "Epoch  564\n",
      "Accuracy ---->  0.7269417941570282\n",
      "Iter:564 train_rmse:3.94 test_loss:119.1 test_rmse:0.0507 test_acc:0.6947\n",
      "Epoch  565\n",
      "Accuracy ---->  0.7269819378852844\n",
      "Iter:565 train_rmse:3.94 test_loss:119.1 test_rmse:0.0507 test_acc:0.6948\n",
      "Epoch  566\n",
      "Accuracy ---->  0.7270219326019287\n",
      "Iter:566 train_rmse:3.939 test_loss:119.1 test_rmse:0.05069 test_acc:0.6948\n",
      "Epoch  567\n",
      "Accuracy ---->  0.7270617187023163\n",
      "Iter:567 train_rmse:3.939 test_loss:119.0 test_rmse:0.05068 test_acc:0.6949\n",
      "Epoch  568\n",
      "Accuracy ---->  0.7271014451980591\n",
      "Iter:568 train_rmse:3.938 test_loss:119.0 test_rmse:0.05068 test_acc:0.6949\n",
      "Epoch  569\n",
      "Accuracy ---->  0.7271411120891571\n",
      "Iter:569 train_rmse:3.938 test_loss:119.0 test_rmse:0.05067 test_acc:0.6949\n",
      "Epoch  570\n",
      "Accuracy ---->  0.7271805703639984\n",
      "Iter:570 train_rmse:3.937 test_loss:118.9 test_rmse:0.05066 test_acc:0.695\n",
      "Epoch  571\n",
      "Accuracy ---->  0.7272199094295502\n",
      "Iter:571 train_rmse:3.936 test_loss:118.9 test_rmse:0.05066 test_acc:0.695\n",
      "Epoch  572\n",
      "Accuracy ---->  0.7272589802742004\n",
      "Iter:572 train_rmse:3.936 test_loss:118.9 test_rmse:0.05065 test_acc:0.6951\n",
      "Epoch  573\n",
      "Accuracy ---->  0.7272979915142059\n",
      "Iter:573 train_rmse:3.935 test_loss:118.9 test_rmse:0.05064 test_acc:0.6951\n",
      "Epoch  574\n",
      "Accuracy ---->  0.727336972951889\n",
      "Iter:574 train_rmse:3.935 test_loss:118.8 test_rmse:0.05064 test_acc:0.6951\n",
      "Epoch  575\n",
      "Accuracy ---->  0.7273757457733154\n",
      "Iter:575 train_rmse:3.934 test_loss:118.8 test_rmse:0.05063 test_acc:0.6952\n",
      "Epoch  576\n",
      "Accuracy ---->  0.7274143993854523\n",
      "Iter:576 train_rmse:3.934 test_loss:118.8 test_rmse:0.05062 test_acc:0.6952\n",
      "Epoch  577\n",
      "Accuracy ---->  0.7274530827999115\n",
      "Iter:577 train_rmse:3.933 test_loss:118.7 test_rmse:0.05062 test_acc:0.6953\n",
      "Epoch  578\n",
      "Accuracy ---->  0.7274913191795349\n",
      "Iter:578 train_rmse:3.932 test_loss:118.7 test_rmse:0.05061 test_acc:0.6953\n",
      "Epoch  579\n",
      "Accuracy ---->  0.7275294959545135\n",
      "Iter:579 train_rmse:3.932 test_loss:118.7 test_rmse:0.0506 test_acc:0.6953\n",
      "Epoch  580\n",
      "Accuracy ---->  0.7275678217411041\n",
      "Iter:580 train_rmse:3.931 test_loss:118.6 test_rmse:0.0506 test_acc:0.6954\n",
      "Epoch  581\n",
      "Accuracy ---->  0.7276059687137604\n",
      "Iter:581 train_rmse:3.931 test_loss:118.6 test_rmse:0.05059 test_acc:0.6954\n",
      "Epoch  582\n",
      "Accuracy ---->  0.7276439964771271\n",
      "Iter:582 train_rmse:3.93 test_loss:118.6 test_rmse:0.05058 test_acc:0.6955\n",
      "Epoch  583\n",
      "Accuracy ---->  0.7276816964149475\n",
      "Iter:583 train_rmse:3.93 test_loss:118.6 test_rmse:0.05058 test_acc:0.6955\n",
      "Epoch  584\n",
      "Accuracy ---->  0.7277194559574127\n",
      "Iter:584 train_rmse:3.929 test_loss:118.5 test_rmse:0.05057 test_acc:0.6955\n",
      "Epoch  585\n",
      "Accuracy ---->  0.7277570068836212\n",
      "Iter:585 train_rmse:3.929 test_loss:118.5 test_rmse:0.05056 test_acc:0.6956\n",
      "Epoch  586\n",
      "Accuracy ---->  0.7277945876121521\n",
      "Iter:586 train_rmse:3.928 test_loss:118.5 test_rmse:0.05056 test_acc:0.6956\n",
      "Epoch  587\n",
      "Accuracy ---->  0.7278320789337158\n",
      "Iter:587 train_rmse:3.928 test_loss:118.4 test_rmse:0.05055 test_acc:0.6957\n",
      "Epoch  588\n",
      "Accuracy ---->  0.7278692424297333\n",
      "Iter:588 train_rmse:3.927 test_loss:118.4 test_rmse:0.05055 test_acc:0.6957\n",
      "Epoch  589\n",
      "Accuracy ---->  0.7279064655303955\n",
      "Iter:589 train_rmse:3.926 test_loss:118.4 test_rmse:0.05054 test_acc:0.6957\n",
      "Epoch  590\n",
      "Accuracy ---->  0.7279435694217682\n",
      "Iter:590 train_rmse:3.926 test_loss:118.3 test_rmse:0.05053 test_acc:0.6958\n",
      "Epoch  591\n",
      "Accuracy ---->  0.7279805839061737\n",
      "Iter:591 train_rmse:3.925 test_loss:118.3 test_rmse:0.05053 test_acc:0.6958\n",
      "Epoch  592\n",
      "Accuracy ---->  0.7280175387859344\n",
      "Iter:592 train_rmse:3.925 test_loss:118.3 test_rmse:0.05052 test_acc:0.6958\n",
      "Epoch  593\n",
      "Accuracy ---->  0.7280543446540833\n",
      "Iter:593 train_rmse:3.924 test_loss:118.3 test_rmse:0.05051 test_acc:0.6959\n",
      "Epoch  594\n",
      "Accuracy ---->  0.7280910015106201\n",
      "Iter:594 train_rmse:3.924 test_loss:118.2 test_rmse:0.05051 test_acc:0.6959\n",
      "Epoch  595\n",
      "Accuracy ---->  0.7281276881694794\n",
      "Iter:595 train_rmse:3.923 test_loss:118.2 test_rmse:0.0505 test_acc:0.696\n",
      "Epoch  596\n",
      "Accuracy ---->  0.7281642556190491\n",
      "Iter:596 train_rmse:3.923 test_loss:118.2 test_rmse:0.0505 test_acc:0.696\n",
      "Epoch  597\n",
      "Accuracy ---->  0.7282006740570068\n",
      "Iter:597 train_rmse:3.922 test_loss:118.1 test_rmse:0.05049 test_acc:0.696\n",
      "Epoch  598\n",
      "Accuracy ---->  0.7282369136810303\n",
      "Iter:598 train_rmse:3.922 test_loss:118.1 test_rmse:0.05048 test_acc:0.6961\n",
      "Epoch  599\n",
      "Accuracy ---->  0.7282733619213104\n",
      "Iter:599 train_rmse:3.921 test_loss:118.1 test_rmse:0.05048 test_acc:0.6961\n",
      "Epoch  600\n",
      "Accuracy ---->  0.7283096015453339\n",
      "Iter:600 train_rmse:3.921 test_loss:118.1 test_rmse:0.05047 test_acc:0.6961\n",
      "Epoch  601\n",
      "Accuracy ---->  0.7283458113670349\n",
      "Iter:601 train_rmse:3.92 test_loss:118.0 test_rmse:0.05046 test_acc:0.6962\n",
      "Epoch  602\n",
      "Accuracy ---->  0.728381872177124\n",
      "Iter:602 train_rmse:3.92 test_loss:118.0 test_rmse:0.05046 test_acc:0.6962\n",
      "Epoch  603\n",
      "Accuracy ---->  0.728417843580246\n",
      "Iter:603 train_rmse:3.919 test_loss:118.0 test_rmse:0.05045 test_acc:0.6963\n",
      "Epoch  604\n",
      "Accuracy ---->  0.7284537851810455\n",
      "Iter:604 train_rmse:3.919 test_loss:117.9 test_rmse:0.05045 test_acc:0.6963\n",
      "Epoch  605\n",
      "Accuracy ---->  0.7284895181655884\n",
      "Iter:605 train_rmse:3.918 test_loss:117.9 test_rmse:0.05044 test_acc:0.6963\n",
      "Epoch  606\n",
      "Accuracy ---->  0.7285252213478088\n",
      "Iter:606 train_rmse:3.918 test_loss:117.9 test_rmse:0.05043 test_acc:0.6964\n",
      "Epoch  607\n",
      "Accuracy ---->  0.7285610437393188\n",
      "Iter:607 train_rmse:3.917 test_loss:117.9 test_rmse:0.05043 test_acc:0.6964\n",
      "Epoch  608\n",
      "Accuracy ---->  0.7285966575145721\n",
      "Iter:608 train_rmse:3.917 test_loss:117.8 test_rmse:0.05042 test_acc:0.6964\n",
      "Epoch  609\n",
      "Accuracy ---->  0.728632241487503\n",
      "Iter:609 train_rmse:3.916 test_loss:117.8 test_rmse:0.05042 test_acc:0.6965\n",
      "Epoch  610\n",
      "Accuracy ---->  0.7286677360534668\n",
      "Iter:610 train_rmse:3.916 test_loss:117.8 test_rmse:0.05041 test_acc:0.6965\n",
      "Epoch  611\n",
      "Accuracy ---->  0.7287031710147858\n",
      "Iter:611 train_rmse:3.915 test_loss:117.7 test_rmse:0.0504 test_acc:0.6965\n",
      "Epoch  612\n",
      "Accuracy ---->  0.7287385761737823\n",
      "Iter:612 train_rmse:3.914 test_loss:117.7 test_rmse:0.0504 test_acc:0.6966\n",
      "Epoch  613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.7287739813327789\n",
      "Iter:613 train_rmse:3.914 test_loss:117.7 test_rmse:0.05039 test_acc:0.6966\n",
      "Epoch  614\n",
      "Accuracy ---->  0.728809267282486\n",
      "Iter:614 train_rmse:3.913 test_loss:117.7 test_rmse:0.05039 test_acc:0.6966\n",
      "Epoch  615\n",
      "Accuracy ---->  0.7288444936275482\n",
      "Iter:615 train_rmse:3.913 test_loss:117.6 test_rmse:0.05038 test_acc:0.6967\n",
      "Epoch  616\n",
      "Accuracy ---->  0.7288795709609985\n",
      "Iter:616 train_rmse:3.912 test_loss:117.6 test_rmse:0.05037 test_acc:0.6967\n",
      "Epoch  617\n",
      "Accuracy ---->  0.7289147675037384\n",
      "Iter:617 train_rmse:3.912 test_loss:117.6 test_rmse:0.05037 test_acc:0.6968\n",
      "Epoch  618\n",
      "Accuracy ---->  0.7289498150348663\n",
      "Iter:618 train_rmse:3.911 test_loss:117.6 test_rmse:0.05036 test_acc:0.6968\n",
      "Epoch  619\n",
      "Accuracy ---->  0.7289847135543823\n",
      "Iter:619 train_rmse:3.911 test_loss:117.5 test_rmse:0.05036 test_acc:0.6968\n",
      "Epoch  620\n",
      "Accuracy ---->  0.7290197610855103\n",
      "Iter:620 train_rmse:3.91 test_loss:117.5 test_rmse:0.05035 test_acc:0.6969\n",
      "Epoch  621\n",
      "Accuracy ---->  0.7290547788143158\n",
      "Iter:621 train_rmse:3.91 test_loss:117.5 test_rmse:0.05034 test_acc:0.6969\n",
      "Epoch  622\n",
      "Accuracy ---->  0.7290897369384766\n",
      "Iter:622 train_rmse:3.909 test_loss:117.4 test_rmse:0.05034 test_acc:0.6969\n",
      "Epoch  623\n",
      "Accuracy ---->  0.7291244268417358\n",
      "Iter:623 train_rmse:3.909 test_loss:117.4 test_rmse:0.05033 test_acc:0.697\n",
      "Epoch  624\n",
      "Accuracy ---->  0.7291591763496399\n",
      "Iter:624 train_rmse:3.908 test_loss:117.4 test_rmse:0.05033 test_acc:0.697\n",
      "Epoch  625\n",
      "Accuracy ---->  0.7291939556598663\n",
      "Iter:625 train_rmse:3.908 test_loss:117.4 test_rmse:0.05032 test_acc:0.697\n",
      "Epoch  626\n",
      "Accuracy ---->  0.7292287051677704\n",
      "Iter:626 train_rmse:3.907 test_loss:117.3 test_rmse:0.05032 test_acc:0.6971\n",
      "Epoch  627\n",
      "Accuracy ---->  0.7292633056640625\n",
      "Iter:627 train_rmse:3.907 test_loss:117.3 test_rmse:0.05031 test_acc:0.6971\n",
      "Epoch  628\n",
      "Accuracy ---->  0.7292979061603546\n",
      "Iter:628 train_rmse:3.906 test_loss:117.3 test_rmse:0.0503 test_acc:0.6971\n",
      "Epoch  629\n",
      "Accuracy ---->  0.7293324768543243\n",
      "Iter:629 train_rmse:3.906 test_loss:117.3 test_rmse:0.0503 test_acc:0.6972\n",
      "Epoch  630\n",
      "Accuracy ---->  0.7293670177459717\n",
      "Iter:630 train_rmse:3.905 test_loss:117.2 test_rmse:0.05029 test_acc:0.6972\n",
      "Epoch  631\n",
      "Accuracy ---->  0.7294014096260071\n",
      "Iter:631 train_rmse:3.905 test_loss:117.2 test_rmse:0.05029 test_acc:0.6973\n",
      "Epoch  632\n",
      "Accuracy ---->  0.7294360399246216\n",
      "Iter:632 train_rmse:3.904 test_loss:117.2 test_rmse:0.05028 test_acc:0.6973\n",
      "Epoch  633\n",
      "Accuracy ---->  0.7294703722000122\n",
      "Iter:633 train_rmse:3.904 test_loss:117.1 test_rmse:0.05027 test_acc:0.6973\n",
      "Epoch  634\n",
      "Accuracy ---->  0.72950479388237\n",
      "Iter:634 train_rmse:3.903 test_loss:117.1 test_rmse:0.05027 test_acc:0.6974\n",
      "Epoch  635\n",
      "Accuracy ---->  0.7295390963554382\n",
      "Iter:635 train_rmse:3.903 test_loss:117.1 test_rmse:0.05026 test_acc:0.6974\n",
      "Epoch  636\n",
      "Accuracy ---->  0.7295735478401184\n",
      "Iter:636 train_rmse:3.902 test_loss:117.1 test_rmse:0.05026 test_acc:0.6974\n",
      "Epoch  637\n",
      "Accuracy ---->  0.7296077013015747\n",
      "Iter:637 train_rmse:3.902 test_loss:117.0 test_rmse:0.05025 test_acc:0.6975\n",
      "Epoch  638\n",
      "Accuracy ---->  0.7296417355537415\n",
      "Iter:638 train_rmse:3.901 test_loss:117.0 test_rmse:0.05025 test_acc:0.6975\n",
      "Epoch  639\n",
      "Accuracy ---->  0.7296760380268097\n",
      "Iter:639 train_rmse:3.901 test_loss:117.0 test_rmse:0.05024 test_acc:0.6975\n",
      "Epoch  640\n",
      "Accuracy ---->  0.7297102510929108\n",
      "Iter:640 train_rmse:3.9 test_loss:117.0 test_rmse:0.05023 test_acc:0.6976\n",
      "Epoch  641\n",
      "Accuracy ---->  0.7297444939613342\n",
      "Iter:641 train_rmse:3.9 test_loss:116.9 test_rmse:0.05023 test_acc:0.6976\n",
      "Epoch  642\n",
      "Accuracy ---->  0.729778379201889\n",
      "Iter:642 train_rmse:3.899 test_loss:116.9 test_rmse:0.05022 test_acc:0.6976\n",
      "Epoch  643\n",
      "Accuracy ---->  0.7298126220703125\n",
      "Iter:643 train_rmse:3.899 test_loss:116.9 test_rmse:0.05022 test_acc:0.6977\n",
      "Epoch  644\n",
      "Accuracy ---->  0.7298467755317688\n",
      "Iter:644 train_rmse:3.898 test_loss:116.8 test_rmse:0.05021 test_acc:0.6977\n",
      "Epoch  645\n",
      "Accuracy ---->  0.7298807799816132\n",
      "Iter:645 train_rmse:3.898 test_loss:116.8 test_rmse:0.05021 test_acc:0.6977\n",
      "Epoch  646\n",
      "Accuracy ---->  0.7299146056175232\n",
      "Iter:646 train_rmse:3.898 test_loss:116.8 test_rmse:0.0502 test_acc:0.6978\n",
      "Epoch  647\n",
      "Accuracy ---->  0.7299485802650452\n",
      "Iter:647 train_rmse:3.897 test_loss:116.8 test_rmse:0.05019 test_acc:0.6978\n",
      "Epoch  648\n",
      "Accuracy ---->  0.7299825251102448\n",
      "Iter:648 train_rmse:3.897 test_loss:116.7 test_rmse:0.05019 test_acc:0.6978\n",
      "Epoch  649\n",
      "Accuracy ---->  0.7300165593624115\n",
      "Iter:649 train_rmse:3.896 test_loss:116.7 test_rmse:0.05018 test_acc:0.6979\n",
      "Epoch  650\n",
      "Accuracy ---->  0.7300503551959991\n",
      "Iter:650 train_rmse:3.896 test_loss:116.7 test_rmse:0.05018 test_acc:0.6979\n",
      "Epoch  651\n",
      "Accuracy ---->  0.7300842106342316\n",
      "Iter:651 train_rmse:3.895 test_loss:116.7 test_rmse:0.05017 test_acc:0.6979\n",
      "Epoch  652\n",
      "Accuracy ---->  0.7301181852817535\n",
      "Iter:652 train_rmse:3.895 test_loss:116.6 test_rmse:0.05017 test_acc:0.698\n",
      "Epoch  653\n",
      "Accuracy ---->  0.7301520109176636\n",
      "Iter:653 train_rmse:3.894 test_loss:116.6 test_rmse:0.05016 test_acc:0.698\n",
      "Epoch  654\n",
      "Accuracy ---->  0.7301857769489288\n",
      "Iter:654 train_rmse:3.894 test_loss:116.6 test_rmse:0.05015 test_acc:0.698\n",
      "Epoch  655\n",
      "Accuracy ---->  0.730219691991806\n",
      "Iter:655 train_rmse:3.893 test_loss:116.6 test_rmse:0.05015 test_acc:0.6981\n",
      "Epoch  656\n",
      "Accuracy ---->  0.7302533388137817\n",
      "Iter:656 train_rmse:3.893 test_loss:116.5 test_rmse:0.05014 test_acc:0.6981\n",
      "Epoch  657\n",
      "Accuracy ---->  0.7302870750427246\n",
      "Iter:657 train_rmse:3.892 test_loss:116.5 test_rmse:0.05014 test_acc:0.6981\n",
      "Epoch  658\n",
      "Accuracy ---->  0.730320930480957\n",
      "Iter:658 train_rmse:3.892 test_loss:116.5 test_rmse:0.05013 test_acc:0.6982\n",
      "Epoch  659\n",
      "Accuracy ---->  0.7303546667098999\n",
      "Iter:659 train_rmse:3.891 test_loss:116.5 test_rmse:0.05013 test_acc:0.6982\n",
      "Epoch  660\n",
      "Accuracy ---->  0.7303885221481323\n",
      "Iter:660 train_rmse:3.891 test_loss:116.4 test_rmse:0.05012 test_acc:0.6982\n",
      "Epoch  661\n",
      "Accuracy ---->  0.7304220795631409\n",
      "Iter:661 train_rmse:3.89 test_loss:116.4 test_rmse:0.05012 test_acc:0.6983\n",
      "Epoch  662\n",
      "Accuracy ---->  0.730455756187439\n",
      "Iter:662 train_rmse:3.89 test_loss:116.4 test_rmse:0.05011 test_acc:0.6983\n",
      "Epoch  663\n",
      "Accuracy ---->  0.7304895222187042\n",
      "Iter:663 train_rmse:3.889 test_loss:116.4 test_rmse:0.0501 test_acc:0.6983\n",
      "Epoch  664\n",
      "Accuracy ---->  0.7305232286453247\n",
      "Iter:664 train_rmse:3.889 test_loss:116.3 test_rmse:0.0501 test_acc:0.6984\n",
      "Epoch  665\n",
      "Accuracy ---->  0.7305567860603333\n",
      "Iter:665 train_rmse:3.888 test_loss:116.3 test_rmse:0.05009 test_acc:0.6984\n",
      "Epoch  666\n",
      "Accuracy ---->  0.730590432882309\n",
      "Iter:666 train_rmse:3.888 test_loss:116.3 test_rmse:0.05009 test_acc:0.6984\n",
      "Epoch  667\n",
      "Accuracy ---->  0.7306241095066071\n",
      "Iter:667 train_rmse:3.887 test_loss:116.3 test_rmse:0.05008 test_acc:0.6985\n",
      "Epoch  668\n",
      "Accuracy ---->  0.7306578457355499\n",
      "Iter:668 train_rmse:3.887 test_loss:116.2 test_rmse:0.05008 test_acc:0.6985\n",
      "Epoch  669\n",
      "Accuracy ---->  0.7306913137435913\n",
      "Iter:669 train_rmse:3.886 test_loss:116.2 test_rmse:0.05007 test_acc:0.6985\n",
      "Epoch  670\n",
      "Accuracy ---->  0.7307249903678894\n",
      "Iter:670 train_rmse:3.886 test_loss:116.2 test_rmse:0.05007 test_acc:0.6986\n",
      "Epoch  671\n",
      "Accuracy ---->  0.7307584881782532\n",
      "Iter:671 train_rmse:3.885 test_loss:116.1 test_rmse:0.05006 test_acc:0.6986\n",
      "Epoch  672\n",
      "Accuracy ---->  0.7307921946048737\n",
      "Iter:672 train_rmse:3.885 test_loss:116.1 test_rmse:0.05005 test_acc:0.6986\n",
      "Epoch  673\n",
      "Accuracy ---->  0.7308257818222046\n",
      "Iter:673 train_rmse:3.884 test_loss:116.1 test_rmse:0.05005 test_acc:0.6987\n",
      "Epoch  674\n",
      "Accuracy ---->  0.7308592796325684\n",
      "Iter:674 train_rmse:3.884 test_loss:116.1 test_rmse:0.05004 test_acc:0.6987\n",
      "Time taken :  36719.56564640999 s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epoch):\n",
    "    print(\"Epoch \", epoch)\n",
    "    for m in range(totalbatch):\n",
    "        mini_batch = trainX[m * batch_size : (m+1) * batch_size]\n",
    "        mini_label = trainY[m * batch_size : (m+1) * batch_size]\n",
    "        _, loss1, rmse1, train_output = sess.run([optimizer, loss, error, y_pred],\n",
    "                                                 feed_dict = {inputs:mini_batch, labels:mini_label})\n",
    "        batch_loss.append(loss1)\n",
    "        batch_rmse.append(rmse1 * max_value)\n",
    "        train_label=np.reshape(mini_label,[-1,num_nodes])\n",
    "     #print(mini_label.shape,train_output.shape) (32, 1, 156) (32, 156)\n",
    "     # Test completely at every epoch\n",
    "    print(\"Accuracy ----> \", evaluation(train_label,train_output)[2])\n",
    "    loss2, rmse2, test_output = sess.run([loss, error, y_pred],\n",
    "                                         feed_dict = {inputs:testX, labels:testY})\n",
    "    #train_label=np.reshape(trainY,[-1,num_nodes])\n",
    "    #train_acc=acc(train_label,train_output)\n",
    "    test_label = np.reshape(testY,[-1,num_nodes])\n",
    "    rmse, mae, acc, r2_score, var_score = evaluation(test_label, test_output)\n",
    "    test_label1 = test_label * max_value#Inverse normalization\n",
    "    test_output1 = test_output * max_value\n",
    "    test_loss.append(loss2)\n",
    "    test_rmse.append(rmse * max_value)\n",
    "    test_mae.append(mae * max_value)\n",
    "    test_acc.append(acc)\n",
    "    test_r2.append(r2_score)\n",
    "    test_var.append(var_score)\n",
    "    test_pred.append(test_output1)\n",
    "    #print(mini_label.shape,train_output.shape)\n",
    "    print('Iter:{}'.format(epoch),\n",
    "          'train_rmse:{:.4}'.format(batch_rmse[-1]),\n",
    "          'test_loss:{:.4}'.format(loss2),\n",
    "          'test_rmse:{:.4}'.format(rmse),\n",
    "          'test_acc:{:.4}'.format(acc))\n",
    "    if (epoch % 500 == 0):        \n",
    "        saver.save(sess, path+'/model_100TGCN_pre_%r'%epoch, global_step = epoch)\n",
    "        \n",
    "time_end = time.time()\n",
    "print('Time taken : ',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = int(len(batch_rmse)/totalbatch)\n",
    "batch_rmse1 = [i for i in batch_rmse]\n",
    "train_rmse = [(sum(batch_rmse1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "batch_loss1 = [i for i in batch_loss]\n",
    "train_loss = [(sum(batch_loss1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "\n",
    "index = test_rmse.index(np.min(test_rmse))\n",
    "test_result = test_pred[index]\n",
    "var = pd.DataFrame(test_result)\n",
    "var.to_csv(path+'/test_result.csv',index = False,header = False)\n",
    "#plot_result(test_result,test_label1,path)\n",
    "#plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "min_rmse:4.325233810770117 min_mae:3.0416026 max_acc:0.6987120509147644 r2:0.8283854722976685 var:0.828388512134552\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing:\")\n",
    "print('min_rmse:%r'%(np.min(test_rmse)),\n",
    "      'min_mae:%r'%(test_mae[index]),\n",
    "      'max_acc:%r'%(test_acc[index]),\n",
    "      'r2:%r'%(test_r2[index]),\n",
    "      'var:%r'%test_var[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "min_rmse:0.04493717005781643 min_mae:0.031516045 max_acc:0.7308592796325684 r2:0.8535912930965424 var:0.8545002937316895\n"
     ]
    }
   ],
   "source": [
    "print(\"Training:\")\n",
    "rmse, mae, acc, r2_score, var_score = evaluation(train_label,train_output)\n",
    "print('min_rmse:%r'%(rmse),\n",
    "      'min_mae:%r'%(mae),\n",
    "      'max_acc:%r'%(acc),\n",
    "      'r2:%r'%(r2_score),\n",
    "      'var:%r'%(var_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_rmse:3.8838836232538636 min_mae:2.7239065 max_acc:0.7308592796325684 r2:0.8535912930965424 var:0.8545002937316895\n"
     ]
    }
   ],
   "source": [
    "#inverse normalisation\n",
    "print('min_rmse:%r'%(rmse*max_value),\n",
    "      'min_mae:%r'%(mae*max_value),\n",
    "      'max_acc:%r'%(acc),\n",
    "      'r2:%r'%(r2_score),\n",
    "      'var:%r'%(var_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
