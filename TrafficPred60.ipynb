{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from tensorflow.contrib.rnn import RNNCell\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "#import matplotlib.pyplot as plt\n",
    "import time\n",
    "time_start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of Dataset-SZ Traffic\n",
    "def load_sz_data():\n",
    "    sz_adj = pd.read_csv('sz_adj.csv',header=None)\n",
    "    adj = np.mat(sz_adj)\n",
    "    sz_tf = pd.read_csv('sz_speed.csv')\n",
    "    return sz_tf, adj\n",
    "\n",
    "data, adj = load_sz_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.(2976, 156)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "time_len=data.shape[0] # Time sequence length\n",
    "num_nodes=data.shape[1] #Number of Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the variables\n",
    "output_dim=pre_len=2\n",
    "seq_len=4\n",
    "num_units=64\n",
    "train_rate=0.8\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0980221  0.21353212 0.23823702 ... 0.19194394 0.37707424 0.        ]\n",
      " [0.09032986 0.18181142 0.31845367 ... 0.45834997 0.37705195 0.        ]\n",
      " [0.10192686 0.10389599 0.23464748 ... 0.3856561  0.43354756 0.        ]\n",
      " ...\n",
      " [0.37947276 0.141638   0.10453826 ... 0.13605069 0.1998609  0.        ]\n",
      " [0.39722532 0.18600048 0.121989   ... 0.16306393 0.16957766 0.        ]\n",
      " [0.38101357 0.14001252 0.10420388 ... 0.19054307 0.1845446  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Normalization : Traffic Speed Data\n",
    "\n",
    "data1 =np.mat(data,dtype=np.float32)\n",
    "\n",
    "max_value = np.max(data1)\n",
    "data1  = data1/max_value\n",
    "print(data1)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 156) -----> (596, 156)\n",
      "Train Test Split Details :\n",
      "Train x ---->  2374\n",
      "Train y ---->  2374\n",
      "(2374, 4, 156)\n",
      "Test x ---->  590\n",
      "Test y ---->  590\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data, time_len, rate, seq_len, pre_len):\n",
    "    train_size = int(time_len * rate) #2976 *0.8 =2380\n",
    "    train_data = data[0:train_size] #  [0:2380]\n",
    "    test_data = data[train_size:time_len] #[2380:2976]\n",
    "    print(train_data.shape,'----->',test_data.shape)\n",
    "\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(train_data) - seq_len - pre_len): #(2380-4-1)=2375\n",
    "        a = train_data[i: i + seq_len + pre_len] #[0:0+4+1] \n",
    "        trainX.append(a[0 : seq_len]) #a[0:4] 4 time * 156 roads\n",
    "        trainY.append(a[seq_len : seq_len + pre_len]) #a[4:4+1] 1 time*156 \n",
    "    for i in range(len(test_data) - seq_len -pre_len):\n",
    "        b = test_data[i: i + seq_len + pre_len]\n",
    "        testX.append(b[0 : seq_len])\n",
    "        testY.append(b[seq_len : seq_len + pre_len])\n",
    "      \n",
    "    trainX1 = np.array(trainX) \n",
    "    trainY1 = np.array(trainY)\n",
    "    testX1 = np.array(testX)\n",
    "    testY1 = np.array(testY)\n",
    "    return trainX1, trainY1, testX1, testY1\n",
    "\n",
    "trainX, trainY, testX, testY = preprocess_data(data1, time_len, train_rate, seq_len, pre_len)\n",
    "\n",
    "totalbatch = int(trainX.shape[0]/batch_size)\n",
    "training_data_count = len(trainX)  \n",
    "print('Train Test Split Details :')\n",
    "print('Train x ----> ',len(trainX))\n",
    "print('Train y ----> ',len(trainY))\n",
    "print(trainX.shape)\n",
    "print('Test x ----> ',len(testX))\n",
    "print('Test y ----> ',len(testY))\n",
    "#print('\\nTrain Sample Details :')\n",
    "#print(trainX[0],'--->',trainY[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
    "        init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "        initial = tf.random_uniform([input_dim, output_dim], minval=-init_range, maxval=init_range, dtype=tf.float32)\n",
    "        return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stgcnCell(RNNCell):\n",
    "    \"\"\"Temporal Graph Convolutional Network \"\"\"\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __init__(self, num_units, adj, num_nodes, input_size=None,\n",
    "                 act=tf.nn.tanh, reuse=None):\n",
    "\n",
    "        super(stgcnCell, self).__init__(_reuse=reuse)\n",
    "        self._act = act\n",
    "        self._nodes = num_nodes\n",
    "        self._units = num_units\n",
    "        self._adj = []\n",
    "        self._adj.append(self.calculate_laplacian(adj))\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_sparse_matrix(L):\n",
    "        L = L.tocoo()\n",
    "        indices = np.column_stack((L.row, L.col))\n",
    "        L = tf.SparseTensor(indices, L.data, L.shape)\n",
    "        return tf.sparse_reorder(L)\n",
    "\n",
    "    def calculate_laplacian(self,adj, lambda_max=1):  \n",
    "        adj = self.normalized_adj(adj + sp.eye(adj.shape[0])) # normalisation(self identity matrix + adj)\n",
    "        adj = sp.csr_matrix(adj) #compressed sparse matrix\n",
    "        adj = adj.astype(np.float32)\n",
    "        return self.sparse_to_tuple(adj)\n",
    "    \n",
    "    def normalized_adj(self,adj):\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        degree = np.array(adj.sum(1)) # Degree Matrix row wise sum\n",
    "        d_inv_sqrt = np.power(degree, -0.5).flatten() # D inv = Degree ^-0.5 \n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt) #substitution of the 1D array degree in a 2D matrix diagonals\n",
    "        normalized_adj = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo() # norm= D^-0.5 * adj * D^-0.5\n",
    "        normalized_adj = normalized_adj.astype(np.float32) \n",
    "        return normalized_adj\n",
    "    \n",
    "    def sparse_to_tuple(self,mx):\n",
    "        mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose() #coordinate stacking row and column wise and transpose\n",
    "        L = tf.SparseTensor(coords, mx.data, mx.shape) # mx.shape= (156,156)\n",
    "        #print('shape ---->',mx.shape)\n",
    "        return tf.sparse_reorder(L) #row major ordering\n",
    "        \n",
    "    def init_state(self,batch_size):       \n",
    "        state = tf.zeros(shape=[batch_size, self._num_nodes*self._num_units], dtype=tf.float32)\n",
    "        return state  \n",
    "               \n",
    "    @staticmethod\n",
    "    def _concat(x, x_):\n",
    "        x_ = tf.expand_dims(x_, 0)\n",
    "        return tf.concat([x, x_], axis=0)   \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._nodes * self._units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "\n",
    "        with tf.variable_scope(scope or \"tgcn\"):\n",
    "            with tf.variable_scope(\"gates\"):  \n",
    "                value = tf.nn.sigmoid(\n",
    "                    self._gc(inputs, state, 2 * self._units, bias=1.0, scope=scope)) #ut (or) rt = sigma(Wu [f(A;Xt); h{t-1}] + bu)\n",
    "                r, u = tf.split(value=value, num_or_size_splits=2, axis=1)\n",
    "            with tf.variable_scope(\"candidate\"):\n",
    "                r_state = r * state #r* h{t-1}\n",
    "                c = self._act(self._gc(inputs, r_state, self._units, scope=scope))#ct = tanh(Wc [f(A;Xt); r_state] + bc) \n",
    "            new_h = u * state + (1 - u) * c #ht = ut * h{t-1} + (1 - u{t}) * ct\n",
    "        return new_h, new_h\n",
    "\n",
    "\n",
    "    def _gc(self, inputs, state, output_size, bias=0.0, scope=None):\n",
    "        ## inputs:(-1,num_nodes)\n",
    "        inputs = tf.expand_dims(inputs, 2)#None,156,None\n",
    "        ## state:(batch,num_node,gru_units)\n",
    "        state = tf.reshape(state, (-1, self._nodes, self._units)) #32,156,64\n",
    "        ## concat\n",
    "        x_s = tf.concat([inputs, state], axis=2) #32,156,65\n",
    "        input_size = x_s.get_shape()[2].value #65\n",
    "        ## (num_node,input_size,-1)\n",
    "        x0 = tf.transpose(x_s, perm=[1, 2, 0]) #156,65,32\n",
    "        x0 = tf.reshape(x0, shape=[self._nodes, -1]) #156,65*32\n",
    "        scope = tf.get_variable_scope()\n",
    "        with tf.variable_scope(scope):\n",
    "            for m in self._adj:#1,156\n",
    "                x1 = tf.sparse_tensor_dense_matmul(m, x0) #1,65*32\n",
    "#                print(x1)\n",
    "            x = tf.reshape(x1, shape=[self._nodes, input_size,-1]) #156,65,32\n",
    "            x = tf.transpose(x,perm=[2,0,1]) #32,156,65\n",
    "            x = tf.reshape(x, shape=[-1, input_size]) #156*32,65\n",
    "            weights = tf.get_variable( # 65,64\n",
    "                'weights', [input_size, output_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            x = tf.matmul(x, weights)  # (batch_size * self._nodes, output_size) \n",
    "            biases = tf.get_variable( #64\n",
    "                \"biases\", [output_size], initializer=tf.constant_initializer(bias, dtype=tf.float32))\n",
    "            x = tf.nn.bias_add(x, biases) #biases added\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes, output_size]) #32,156,64\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes * output_size])#32,156*64\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STGCN(_X, _weights, _biases):\n",
    "    ###\n",
    "    cell_1 = stgcnCell(num_units, adj, num_nodes=num_nodes)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([cell_1], state_is_tuple=True) #stack rnn cells\n",
    "    _X = tf.unstack(_X, axis=1) # 4 tensorflow arrays of shape None,156 (seq_len=4)\n",
    "    outputs, states = tf.nn.static_rnn(cell, _X, dtype=tf.float32) #Creates a recurrent neural network specified by RNNCell cell\n",
    "    #4 ouputs and 1 state None,9984(156*64)\n",
    "    m = []\n",
    "    for i in outputs:\n",
    "        o = tf.reshape(i,shape=[-1,num_nodes,num_units])#None,156,64\n",
    "        o = tf.reshape(o,shape=[-1,num_units])#None*156,64\n",
    "        m.append(o) #4 objects\n",
    "    last_output = m[-1] #last one\n",
    "    output = tf.matmul(last_output, _weights['out']) + _biases['out'] #multiply with weights and add bias None*156,1+len(1)=156,1\n",
    "    output = tf.reshape(output,shape=[-1,num_nodes,pre_len]) # None,156,1\n",
    "    output = tf.transpose(output, perm=[0,2,1])#None,1,156\n",
    "    output = tf.reshape(output, shape=[-1,num_nodes]) #None*1,156\n",
    "    return output, m, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Lema Labs ML Workshop x64\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "WARNING:tensorflow:From <ipython-input-9-dfd1196d70e3>:4: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-dfd1196d70e3>:6: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=[None, seq_len, num_nodes])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, pre_len, num_nodes])\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_units, pre_len], mean=1.0), name='weight_o')} #64,1\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([pre_len]),name='bias_o')} #1\n",
    "print(type(inputs))\n",
    "pred,ttts,ttto = STGCN(inputs, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_loss = 0.0015\n",
    "Lreg = lambda_loss * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "label = tf.reshape(labels, [-1,num_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.l2_loss(y_pred-label) + Lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = tf.sqrt(tf.reduce_mean(tf.square(y_pred-label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tf.global_variables()\n",
    "training_epoch=1000\n",
    "saver = tf.train.Saver(tf.global_variables()) #\n",
    "#sess = tf.Session()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "out = 'out/%s'%(\"STGCN\")\n",
    "#out = 'out/%s_%s'%(model_name,'perturbation')\n",
    "path1 = '%s_%s_lr%r_batch%r_unit%r_seq%r_pre%r_epoch%r'%(\"S60TGCN\",\"sz\",lr,batch_size,num_units,seq_len,pre_len,training_epoch)\n",
    "path = os.path.join(out,path1)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(a,b):\n",
    "    rmse = math.sqrt(mean_squared_error(a,b))\n",
    "    mae = mean_absolute_error(a, b)\n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    r2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\n",
    "    var = 1-(np.var(a-b))/np.var(a)\n",
    "    return rmse, mae, 1-F_norm, r2, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axe,batch_loss,batch_rmse,batch_pred = [], [], [], []\n",
    "test_loss,test_rmse,test_mae,test_acc,test_r2,test_var,test_pred = [],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(a,b):  \n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    train_acc=1-F_norm\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy ---->  0.5915797650814056\n",
      "Iter:0 train_rmse:5.889 test_loss:484.7 test_rmse:0.07254 test_acc:0.5632\n",
      "Epoch  1\n",
      "Accuracy ---->  0.6059670746326447\n",
      "Iter:1 train_rmse:5.681 test_loss:453.0 test_rmse:0.07013 test_acc:0.5778\n",
      "Epoch  2\n",
      "Accuracy ---->  0.6091456413269043\n",
      "Iter:2 train_rmse:5.636 test_loss:444.6 test_rmse:0.06947 test_acc:0.5817\n",
      "Epoch  3\n",
      "Accuracy ---->  0.6115569472312927\n",
      "Iter:3 train_rmse:5.601 test_loss:438.7 test_rmse:0.06901 test_acc:0.5845\n",
      "Epoch  4\n",
      "Accuracy ---->  0.613364964723587\n",
      "Iter:4 train_rmse:5.575 test_loss:434.5 test_rmse:0.06868 test_acc:0.5865\n",
      "Epoch  5\n",
      "Accuracy ---->  0.6147112846374512\n",
      "Iter:5 train_rmse:5.555 test_loss:431.2 test_rmse:0.06841 test_acc:0.5881\n",
      "Epoch  6\n",
      "Accuracy ---->  0.6158072352409363\n",
      "Iter:6 train_rmse:5.54 test_loss:428.4 test_rmse:0.06819 test_acc:0.5894\n",
      "Epoch  7\n",
      "Accuracy ---->  0.61700040102005\n",
      "Iter:7 train_rmse:5.522 test_loss:425.9 test_rmse:0.068 test_acc:0.5906\n",
      "Epoch  8\n",
      "Accuracy ---->  0.6181682050228119\n",
      "Iter:8 train_rmse:5.506 test_loss:423.8 test_rmse:0.06782 test_acc:0.5916\n",
      "Epoch  9\n",
      "Accuracy ---->  0.6191806793212891\n",
      "Iter:9 train_rmse:5.491 test_loss:421.9 test_rmse:0.06767 test_acc:0.5926\n",
      "Epoch  10\n",
      "Accuracy ---->  0.6200055778026581\n",
      "Iter:10 train_rmse:5.479 test_loss:420.2 test_rmse:0.06754 test_acc:0.5934\n",
      "Epoch  11\n",
      "Accuracy ---->  0.6207488477230072\n",
      "Iter:11 train_rmse:5.468 test_loss:418.8 test_rmse:0.06742 test_acc:0.5941\n",
      "Epoch  12\n",
      "Accuracy ---->  0.6215623915195465\n",
      "Iter:12 train_rmse:5.457 test_loss:417.5 test_rmse:0.06732 test_acc:0.5947\n",
      "Epoch  13\n",
      "Accuracy ---->  0.6223516464233398\n",
      "Iter:13 train_rmse:5.445 test_loss:416.2 test_rmse:0.06722 test_acc:0.5953\n",
      "Epoch  14\n",
      "Accuracy ---->  0.6230980753898621\n",
      "Iter:14 train_rmse:5.434 test_loss:415.0 test_rmse:0.06712 test_acc:0.5959\n",
      "Epoch  15\n",
      "Accuracy ---->  0.6237964034080505\n",
      "Iter:15 train_rmse:5.424 test_loss:413.7 test_rmse:0.06701 test_acc:0.5965\n",
      "Epoch  16\n",
      "Accuracy ---->  0.624477356672287\n",
      "Iter:16 train_rmse:5.415 test_loss:412.5 test_rmse:0.06691 test_acc:0.5971\n",
      "Epoch  17\n",
      "Accuracy ---->  0.6253003478050232\n",
      "Iter:17 train_rmse:5.403 test_loss:411.2 test_rmse:0.06681 test_acc:0.5978\n",
      "Epoch  18\n",
      "Accuracy ---->  0.6262655854225159\n",
      "Iter:18 train_rmse:5.389 test_loss:410.0 test_rmse:0.06671 test_acc:0.5984\n",
      "Epoch  19\n",
      "Accuracy ---->  0.6271705031394958\n",
      "Iter:19 train_rmse:5.376 test_loss:408.7 test_rmse:0.0666 test_acc:0.599\n",
      "Epoch  20\n",
      "Accuracy ---->  0.6280031800270081\n",
      "Iter:20 train_rmse:5.364 test_loss:407.3 test_rmse:0.06649 test_acc:0.5997\n",
      "Epoch  21\n",
      "Accuracy ---->  0.6288121342658997\n",
      "Iter:21 train_rmse:5.352 test_loss:406.1 test_rmse:0.06639 test_acc:0.6003\n",
      "Epoch  22\n",
      "Accuracy ---->  0.6296773254871368\n",
      "Iter:22 train_rmse:5.34 test_loss:404.9 test_rmse:0.0663 test_acc:0.6009\n",
      "Epoch  23\n",
      "Accuracy ---->  0.6305539309978485\n",
      "Iter:23 train_rmse:5.327 test_loss:403.9 test_rmse:0.06621 test_acc:0.6014\n",
      "Epoch  24\n",
      "Accuracy ---->  0.6313699781894684\n",
      "Iter:24 train_rmse:5.315 test_loss:402.9 test_rmse:0.06613 test_acc:0.6019\n",
      "Epoch  25\n",
      "Accuracy ---->  0.6321099400520325\n",
      "Iter:25 train_rmse:5.305 test_loss:401.7 test_rmse:0.06603 test_acc:0.6024\n",
      "Epoch  26\n",
      "Accuracy ---->  0.6327983438968658\n",
      "Iter:26 train_rmse:5.295 test_loss:400.7 test_rmse:0.06595 test_acc:0.603\n",
      "Epoch  27\n",
      "Accuracy ---->  0.6334087550640106\n",
      "Iter:27 train_rmse:5.286 test_loss:399.7 test_rmse:0.06587 test_acc:0.6034\n",
      "Epoch  28\n",
      "Accuracy ---->  0.6339865326881409\n",
      "Iter:28 train_rmse:5.277 test_loss:399.0 test_rmse:0.0658 test_acc:0.6038\n",
      "Epoch  29\n",
      "Accuracy ---->  0.6345975399017334\n",
      "Iter:29 train_rmse:5.269 test_loss:398.3 test_rmse:0.06575 test_acc:0.6041\n",
      "Epoch  30\n",
      "Accuracy ---->  0.6351860463619232\n",
      "Iter:30 train_rmse:5.26 test_loss:397.7 test_rmse:0.0657 test_acc:0.6045\n",
      "Epoch  31\n",
      "Accuracy ---->  0.6357048749923706\n",
      "Iter:31 train_rmse:5.253 test_loss:396.9 test_rmse:0.06563 test_acc:0.6048\n",
      "Epoch  32\n",
      "Accuracy ---->  0.6361905634403229\n",
      "Iter:32 train_rmse:5.246 test_loss:396.0 test_rmse:0.06556 test_acc:0.6053\n",
      "Epoch  33\n",
      "Accuracy ---->  0.6366724967956543\n",
      "Iter:33 train_rmse:5.239 test_loss:395.2 test_rmse:0.06549 test_acc:0.6057\n",
      "Epoch  34\n",
      "Accuracy ---->  0.6371538937091827\n",
      "Iter:34 train_rmse:5.232 test_loss:394.5 test_rmse:0.06543 test_acc:0.6061\n",
      "Epoch  35\n",
      "Accuracy ---->  0.6376118063926697\n",
      "Iter:35 train_rmse:5.225 test_loss:393.8 test_rmse:0.06537 test_acc:0.6064\n",
      "Epoch  36\n",
      "Accuracy ---->  0.638040155172348\n",
      "Iter:36 train_rmse:5.219 test_loss:393.1 test_rmse:0.06532 test_acc:0.6068\n",
      "Epoch  37\n",
      "Accuracy ---->  0.6384666860103607\n",
      "Iter:37 train_rmse:5.213 test_loss:392.4 test_rmse:0.06526 test_acc:0.6071\n",
      "Epoch  38\n",
      "Accuracy ---->  0.6389091312885284\n",
      "Iter:38 train_rmse:5.206 test_loss:391.7 test_rmse:0.0652 test_acc:0.6074\n",
      "Epoch  39\n",
      "Accuracy ---->  0.6393558084964752\n",
      "Iter:39 train_rmse:5.2 test_loss:391.1 test_rmse:0.06514 test_acc:0.6078\n",
      "Epoch  40\n",
      "Accuracy ---->  0.6397921741008759\n",
      "Iter:40 train_rmse:5.194 test_loss:390.3 test_rmse:0.06508 test_acc:0.6081\n",
      "Epoch  41\n",
      "Accuracy ---->  0.6402187347412109\n",
      "Iter:41 train_rmse:5.188 test_loss:389.6 test_rmse:0.06502 test_acc:0.6085\n",
      "Epoch  42\n",
      "Accuracy ---->  0.6406372487545013\n",
      "Iter:42 train_rmse:5.182 test_loss:388.9 test_rmse:0.06496 test_acc:0.6089\n",
      "Epoch  43\n",
      "Accuracy ---->  0.641042023897171\n",
      "Iter:43 train_rmse:5.176 test_loss:388.2 test_rmse:0.0649 test_acc:0.6092\n",
      "Epoch  44\n",
      "Accuracy ---->  0.6414304375648499\n",
      "Iter:44 train_rmse:5.17 test_loss:387.5 test_rmse:0.06484 test_acc:0.6096\n",
      "Epoch  45\n",
      "Accuracy ---->  0.6418081223964691\n",
      "Iter:45 train_rmse:5.165 test_loss:386.8 test_rmse:0.06478 test_acc:0.61\n",
      "Epoch  46\n",
      "Accuracy ---->  0.6421838104724884\n",
      "Iter:46 train_rmse:5.159 test_loss:386.1 test_rmse:0.06472 test_acc:0.6103\n",
      "Epoch  47\n",
      "Accuracy ---->  0.6425661444664001\n",
      "Iter:47 train_rmse:5.154 test_loss:385.3 test_rmse:0.06466 test_acc:0.6107\n",
      "Epoch  48\n",
      "Accuracy ---->  0.6429615020751953\n",
      "Iter:48 train_rmse:5.148 test_loss:384.6 test_rmse:0.0646 test_acc:0.6111\n",
      "Epoch  49\n",
      "Accuracy ---->  0.6433717012405396\n",
      "Iter:49 train_rmse:5.142 test_loss:383.9 test_rmse:0.06454 test_acc:0.6114\n",
      "Epoch  50\n",
      "Accuracy ---->  0.6437956690788269\n",
      "Iter:50 train_rmse:5.136 test_loss:383.2 test_rmse:0.06448 test_acc:0.6118\n",
      "Epoch  51\n",
      "Accuracy ---->  0.6442321538925171\n",
      "Iter:51 train_rmse:5.13 test_loss:382.5 test_rmse:0.06442 test_acc:0.6121\n",
      "Epoch  52\n",
      "Accuracy ---->  0.6446798741817474\n",
      "Iter:52 train_rmse:5.123 test_loss:381.8 test_rmse:0.06436 test_acc:0.6125\n",
      "Epoch  53\n",
      "Accuracy ---->  0.6451383531093597\n",
      "Iter:53 train_rmse:5.117 test_loss:381.1 test_rmse:0.0643 test_acc:0.6129\n",
      "Epoch  54\n",
      "Accuracy ---->  0.6456083357334137\n",
      "Iter:54 train_rmse:5.11 test_loss:380.3 test_rmse:0.06423 test_acc:0.6133\n",
      "Epoch  55\n",
      "Accuracy ---->  0.6460919678211212\n",
      "Iter:55 train_rmse:5.103 test_loss:379.5 test_rmse:0.06416 test_acc:0.6137\n",
      "Epoch  56\n",
      "Accuracy ---->  0.6465919315814972\n",
      "Iter:56 train_rmse:5.096 test_loss:378.7 test_rmse:0.06409 test_acc:0.6141\n",
      "Epoch  57\n",
      "Accuracy ---->  0.6471109688282013\n",
      "Iter:57 train_rmse:5.088 test_loss:377.8 test_rmse:0.06402 test_acc:0.6146\n",
      "Epoch  58\n",
      "Accuracy ---->  0.6476512551307678\n",
      "Iter:58 train_rmse:5.08 test_loss:376.9 test_rmse:0.06394 test_acc:0.615\n",
      "Epoch  59\n",
      "Accuracy ---->  0.648215115070343\n",
      "Iter:59 train_rmse:5.072 test_loss:375.9 test_rmse:0.06386 test_acc:0.6155\n",
      "Epoch  60\n",
      "Accuracy ---->  0.6488057076931\n",
      "Iter:60 train_rmse:5.064 test_loss:374.9 test_rmse:0.06377 test_acc:0.616\n",
      "Epoch  61\n",
      "Accuracy ---->  0.6494270861148834\n",
      "Iter:61 train_rmse:5.055 test_loss:373.8 test_rmse:0.06368 test_acc:0.6166\n",
      "Epoch  62\n",
      "Accuracy ---->  0.6500830054283142\n",
      "Iter:62 train_rmse:5.045 test_loss:372.7 test_rmse:0.06358 test_acc:0.6172\n",
      "Epoch  63\n",
      "Accuracy ---->  0.6507764160633087\n",
      "Iter:63 train_rmse:5.035 test_loss:371.5 test_rmse:0.06348 test_acc:0.6178\n",
      "Epoch  64\n",
      "Accuracy ---->  0.6515109837055206\n",
      "Iter:64 train_rmse:5.025 test_loss:370.2 test_rmse:0.06337 test_acc:0.6185\n",
      "Epoch  65\n",
      "Accuracy ---->  0.6522918939590454\n",
      "Iter:65 train_rmse:5.014 test_loss:368.9 test_rmse:0.06325 test_acc:0.6192\n",
      "Epoch  66\n",
      "Accuracy ---->  0.6531204879283905\n",
      "Iter:66 train_rmse:5.002 test_loss:367.6 test_rmse:0.06314 test_acc:0.6199\n",
      "Epoch  67\n",
      "Accuracy ---->  0.6539751887321472\n",
      "Iter:67 train_rmse:4.989 test_loss:366.2 test_rmse:0.06302 test_acc:0.6206\n",
      "Epoch  68\n",
      "Accuracy ---->  0.6548084318637848\n",
      "Iter:68 train_rmse:4.977 test_loss:364.6 test_rmse:0.06289 test_acc:0.6214\n",
      "Epoch  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6556130945682526\n",
      "Iter:69 train_rmse:4.966 test_loss:363.0 test_rmse:0.06274 test_acc:0.6223\n",
      "Epoch  70\n",
      "Accuracy ---->  0.6564001441001892\n",
      "Iter:70 train_rmse:4.954 test_loss:361.2 test_rmse:0.06259 test_acc:0.6232\n",
      "Epoch  71\n",
      "Accuracy ---->  0.6571885943412781\n",
      "Iter:71 train_rmse:4.943 test_loss:359.4 test_rmse:0.06242 test_acc:0.6242\n",
      "Epoch  72\n",
      "Accuracy ---->  0.6580646336078644\n",
      "Iter:72 train_rmse:4.93 test_loss:357.5 test_rmse:0.06226 test_acc:0.6251\n",
      "Epoch  73\n",
      "Accuracy ---->  0.6590360701084137\n",
      "Iter:73 train_rmse:4.916 test_loss:355.7 test_rmse:0.0621 test_acc:0.6261\n",
      "Epoch  74\n",
      "Accuracy ---->  0.660041481256485\n",
      "Iter:74 train_rmse:4.902 test_loss:353.8 test_rmse:0.06194 test_acc:0.6271\n",
      "Epoch  75\n",
      "Accuracy ---->  0.6610373258590698\n",
      "Iter:75 train_rmse:4.887 test_loss:352.0 test_rmse:0.06178 test_acc:0.6281\n",
      "Epoch  76\n",
      "Accuracy ---->  0.662004142999649\n",
      "Iter:76 train_rmse:4.873 test_loss:350.2 test_rmse:0.06162 test_acc:0.629\n",
      "Epoch  77\n",
      "Accuracy ---->  0.6629354059696198\n",
      "Iter:77 train_rmse:4.86 test_loss:348.5 test_rmse:0.06147 test_acc:0.6299\n",
      "Epoch  78\n",
      "Accuracy ---->  0.663831353187561\n",
      "Iter:78 train_rmse:4.847 test_loss:346.9 test_rmse:0.06132 test_acc:0.6308\n",
      "Epoch  79\n",
      "Accuracy ---->  0.6646957099437714\n",
      "Iter:79 train_rmse:4.835 test_loss:345.3 test_rmse:0.06119 test_acc:0.6316\n",
      "Epoch  80\n",
      "Accuracy ---->  0.6655329465866089\n",
      "Iter:80 train_rmse:4.823 test_loss:343.9 test_rmse:0.06106 test_acc:0.6324\n",
      "Epoch  81\n",
      "Accuracy ---->  0.6663458049297333\n",
      "Iter:81 train_rmse:4.811 test_loss:342.5 test_rmse:0.06094 test_acc:0.6331\n",
      "Epoch  82\n",
      "Accuracy ---->  0.6671336591243744\n",
      "Iter:82 train_rmse:4.8 test_loss:341.3 test_rmse:0.06083 test_acc:0.6338\n",
      "Epoch  83\n",
      "Accuracy ---->  0.6678919792175293\n",
      "Iter:83 train_rmse:4.789 test_loss:340.2 test_rmse:0.06073 test_acc:0.6344\n",
      "Epoch  84\n",
      "Accuracy ---->  0.6686135232448578\n",
      "Iter:84 train_rmse:4.778 test_loss:339.2 test_rmse:0.06064 test_acc:0.6349\n",
      "Epoch  85\n",
      "Accuracy ---->  0.6692898571491241\n",
      "Iter:85 train_rmse:4.768 test_loss:338.3 test_rmse:0.06055 test_acc:0.6354\n",
      "Epoch  86\n",
      "Accuracy ---->  0.6699149012565613\n",
      "Iter:86 train_rmse:4.759 test_loss:337.4 test_rmse:0.06048 test_acc:0.6359\n",
      "Epoch  87\n",
      "Accuracy ---->  0.6704885065555573\n",
      "Iter:87 train_rmse:4.751 test_loss:336.6 test_rmse:0.0604 test_acc:0.6363\n",
      "Epoch  88\n",
      "Accuracy ---->  0.6710177063941956\n",
      "Iter:88 train_rmse:4.744 test_loss:335.8 test_rmse:0.06033 test_acc:0.6367\n",
      "Epoch  89\n",
      "Accuracy ---->  0.6715151071548462\n",
      "Iter:89 train_rmse:4.736 test_loss:335.1 test_rmse:0.06027 test_acc:0.6371\n",
      "Epoch  90\n",
      "Accuracy ---->  0.6719934344291687\n",
      "Iter:90 train_rmse:4.729 test_loss:334.5 test_rmse:0.06021 test_acc:0.6375\n",
      "Epoch  91\n",
      "Accuracy ---->  0.6724579632282257\n",
      "Iter:91 train_rmse:4.723 test_loss:333.9 test_rmse:0.06016 test_acc:0.6378\n",
      "Epoch  92\n",
      "Accuracy ---->  0.6728982627391815\n",
      "Iter:92 train_rmse:4.716 test_loss:333.3 test_rmse:0.06011 test_acc:0.6381\n",
      "Epoch  93\n",
      "Accuracy ---->  0.673280656337738\n",
      "Iter:93 train_rmse:4.711 test_loss:332.7 test_rmse:0.06005 test_acc:0.6385\n",
      "Epoch  94\n",
      "Accuracy ---->  0.6735837161540985\n",
      "Iter:94 train_rmse:4.707 test_loss:332.0 test_rmse:0.05999 test_acc:0.6388\n",
      "Epoch  95\n",
      "Accuracy ---->  0.6739042699337006\n",
      "Iter:95 train_rmse:4.702 test_loss:331.5 test_rmse:0.05995 test_acc:0.6391\n",
      "Epoch  96\n",
      "Accuracy ---->  0.6742623448371887\n",
      "Iter:96 train_rmse:4.697 test_loss:331.2 test_rmse:0.05992 test_acc:0.6392\n",
      "Epoch  97\n",
      "Accuracy ---->  0.6745690703392029\n",
      "Iter:97 train_rmse:4.692 test_loss:330.8 test_rmse:0.05988 test_acc:0.6395\n",
      "Epoch  98\n",
      "Accuracy ---->  0.6748685240745544\n",
      "Iter:98 train_rmse:4.688 test_loss:330.3 test_rmse:0.05984 test_acc:0.6397\n",
      "Epoch  99\n",
      "Accuracy ---->  0.6751701831817627\n",
      "Iter:99 train_rmse:4.684 test_loss:329.8 test_rmse:0.0598 test_acc:0.64\n",
      "Epoch  100\n",
      "Accuracy ---->  0.6754704117774963\n",
      "Iter:100 train_rmse:4.679 test_loss:329.4 test_rmse:0.05976 test_acc:0.6402\n",
      "Epoch  101\n",
      "Accuracy ---->  0.6757672131061554\n",
      "Iter:101 train_rmse:4.675 test_loss:329.0 test_rmse:0.05972 test_acc:0.6405\n",
      "Epoch  102\n",
      "Accuracy ---->  0.6760596632957458\n",
      "Iter:102 train_rmse:4.671 test_loss:328.6 test_rmse:0.05968 test_acc:0.6407\n",
      "Epoch  103\n",
      "Accuracy ---->  0.676347017288208\n",
      "Iter:103 train_rmse:4.667 test_loss:328.2 test_rmse:0.05964 test_acc:0.6409\n",
      "Epoch  104\n",
      "Accuracy ---->  0.6766289472579956\n",
      "Iter:104 train_rmse:4.663 test_loss:327.8 test_rmse:0.05961 test_acc:0.6411\n",
      "Epoch  105\n",
      "Accuracy ---->  0.6769052147865295\n",
      "Iter:105 train_rmse:4.659 test_loss:327.3 test_rmse:0.05957 test_acc:0.6414\n",
      "Epoch  106\n",
      "Accuracy ---->  0.6771758496761322\n",
      "Iter:106 train_rmse:4.655 test_loss:326.9 test_rmse:0.05953 test_acc:0.6416\n",
      "Epoch  107\n",
      "Accuracy ---->  0.6774410605430603\n",
      "Iter:107 train_rmse:4.651 test_loss:326.5 test_rmse:0.05949 test_acc:0.6418\n",
      "Epoch  108\n",
      "Accuracy ---->  0.6777012050151825\n",
      "Iter:108 train_rmse:4.647 test_loss:326.1 test_rmse:0.05946 test_acc:0.642\n",
      "Epoch  109\n",
      "Accuracy ---->  0.677956759929657\n",
      "Iter:109 train_rmse:4.643 test_loss:325.7 test_rmse:0.05942 test_acc:0.6423\n",
      "Epoch  110\n",
      "Accuracy ---->  0.6782083213329315\n",
      "Iter:110 train_rmse:4.64 test_loss:325.3 test_rmse:0.05938 test_acc:0.6425\n",
      "Epoch  111\n",
      "Accuracy ---->  0.6784563958644867\n",
      "Iter:111 train_rmse:4.636 test_loss:324.8 test_rmse:0.05934 test_acc:0.6427\n",
      "Epoch  112\n",
      "Accuracy ---->  0.6787013709545135\n",
      "Iter:112 train_rmse:4.633 test_loss:324.4 test_rmse:0.0593 test_acc:0.643\n",
      "Epoch  113\n",
      "Accuracy ---->  0.6789436042308807\n",
      "Iter:113 train_rmse:4.629 test_loss:323.9 test_rmse:0.05926 test_acc:0.6432\n",
      "Epoch  114\n",
      "Accuracy ---->  0.6791832447052002\n",
      "Iter:114 train_rmse:4.626 test_loss:323.5 test_rmse:0.05922 test_acc:0.6435\n",
      "Epoch  115\n",
      "Accuracy ---->  0.6794204115867615\n",
      "Iter:115 train_rmse:4.622 test_loss:323.0 test_rmse:0.05917 test_acc:0.6437\n",
      "Epoch  116\n",
      "Accuracy ---->  0.6796550750732422\n",
      "Iter:116 train_rmse:4.619 test_loss:322.6 test_rmse:0.05913 test_acc:0.644\n",
      "Epoch  117\n",
      "Accuracy ---->  0.6798871755599976\n",
      "Iter:117 train_rmse:4.616 test_loss:322.1 test_rmse:0.05909 test_acc:0.6442\n",
      "Epoch  118\n",
      "Accuracy ---->  0.680116593837738\n",
      "Iter:118 train_rmse:4.612 test_loss:321.6 test_rmse:0.05905 test_acc:0.6445\n",
      "Epoch  119\n",
      "Accuracy ---->  0.6803433895111084\n",
      "Iter:119 train_rmse:4.609 test_loss:321.2 test_rmse:0.05901 test_acc:0.6447\n",
      "Epoch  120\n",
      "Accuracy ---->  0.6805676221847534\n",
      "Iter:120 train_rmse:4.606 test_loss:320.8 test_rmse:0.05896 test_acc:0.645\n",
      "Epoch  121\n",
      "Accuracy ---->  0.6807897388935089\n",
      "Iter:121 train_rmse:4.603 test_loss:320.3 test_rmse:0.05893 test_acc:0.6452\n",
      "Epoch  122\n",
      "Accuracy ---->  0.6810103952884674\n",
      "Iter:122 train_rmse:4.599 test_loss:319.9 test_rmse:0.05889 test_acc:0.6455\n",
      "Epoch  123\n",
      "Accuracy ---->  0.6812302768230438\n",
      "Iter:123 train_rmse:4.596 test_loss:319.5 test_rmse:0.05885 test_acc:0.6457\n",
      "Epoch  124\n",
      "Accuracy ---->  0.6814498603343964\n",
      "Iter:124 train_rmse:4.593 test_loss:319.1 test_rmse:0.05882 test_acc:0.6459\n",
      "Epoch  125\n",
      "Accuracy ---->  0.6816681027412415\n",
      "Iter:125 train_rmse:4.59 test_loss:318.8 test_rmse:0.05878 test_acc:0.6461\n",
      "Epoch  126\n",
      "Accuracy ---->  0.6818808317184448\n",
      "Iter:126 train_rmse:4.587 test_loss:318.4 test_rmse:0.05875 test_acc:0.6463\n",
      "Epoch  127\n",
      "Accuracy ---->  0.6820788085460663\n",
      "Iter:127 train_rmse:4.584 test_loss:318.1 test_rmse:0.05872 test_acc:0.6465\n",
      "Epoch  128\n",
      "Accuracy ---->  0.6822504699230194\n",
      "Iter:128 train_rmse:4.582 test_loss:317.7 test_rmse:0.05868 test_acc:0.6467\n",
      "Epoch  129\n",
      "Accuracy ---->  0.6823948323726654\n",
      "Iter:129 train_rmse:4.579 test_loss:317.2 test_rmse:0.05864 test_acc:0.647\n",
      "Epoch  130\n",
      "Accuracy ---->  0.6825380623340607\n",
      "Iter:130 train_rmse:4.577 test_loss:316.7 test_rmse:0.05859 test_acc:0.6473\n",
      "Epoch  131\n",
      "Accuracy ---->  0.6827179193496704\n",
      "Iter:131 train_rmse:4.575 test_loss:316.2 test_rmse:0.05854 test_acc:0.6475\n",
      "Epoch  132\n",
      "Accuracy ---->  0.6829403042793274\n",
      "Iter:132 train_rmse:4.572 test_loss:315.7 test_rmse:0.0585 test_acc:0.6478\n",
      "Epoch  133\n",
      "Accuracy ---->  0.6831771731376648\n",
      "Iter:133 train_rmse:4.568 test_loss:315.3 test_rmse:0.05846 test_acc:0.6481\n",
      "Epoch  134\n",
      "Accuracy ---->  0.6834011971950531\n",
      "Iter:134 train_rmse:4.565 test_loss:314.9 test_rmse:0.05842 test_acc:0.6483\n",
      "Epoch  135\n",
      "Accuracy ---->  0.6836045980453491\n",
      "Iter:135 train_rmse:4.562 test_loss:314.5 test_rmse:0.05838 test_acc:0.6485\n",
      "Epoch  136\n",
      "Accuracy ---->  0.6837963163852692\n",
      "Iter:136 train_rmse:4.559 test_loss:314.1 test_rmse:0.05834 test_acc:0.6487\n",
      "Epoch  137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6839904189109802\n",
      "Iter:137 train_rmse:4.556 test_loss:313.6 test_rmse:0.05831 test_acc:0.649\n",
      "Epoch  138\n",
      "Accuracy ---->  0.6841964721679688\n",
      "Iter:138 train_rmse:4.553 test_loss:313.2 test_rmse:0.05827 test_acc:0.6492\n",
      "Epoch  139\n",
      "Accuracy ---->  0.6844159960746765\n",
      "Iter:139 train_rmse:4.55 test_loss:312.8 test_rmse:0.05823 test_acc:0.6494\n",
      "Epoch  140\n",
      "Accuracy ---->  0.6846457719802856\n",
      "Iter:140 train_rmse:4.547 test_loss:312.4 test_rmse:0.05819 test_acc:0.6497\n",
      "Epoch  141\n",
      "Accuracy ---->  0.6848816275596619\n",
      "Iter:141 train_rmse:4.544 test_loss:312.0 test_rmse:0.05815 test_acc:0.6499\n",
      "Epoch  142\n",
      "Accuracy ---->  0.6851203143596649\n",
      "Iter:142 train_rmse:4.54 test_loss:311.5 test_rmse:0.05811 test_acc:0.6501\n",
      "Epoch  143\n",
      "Accuracy ---->  0.6853595077991486\n",
      "Iter:143 train_rmse:4.537 test_loss:311.1 test_rmse:0.05807 test_acc:0.6504\n",
      "Epoch  144\n",
      "Accuracy ---->  0.685598224401474\n",
      "Iter:144 train_rmse:4.533 test_loss:310.7 test_rmse:0.05803 test_acc:0.6506\n",
      "Epoch  145\n",
      "Accuracy ---->  0.6858357787132263\n",
      "Iter:145 train_rmse:4.53 test_loss:310.2 test_rmse:0.05799 test_acc:0.6509\n",
      "Epoch  146\n",
      "Accuracy ---->  0.6860718727111816\n",
      "Iter:146 train_rmse:4.526 test_loss:309.8 test_rmse:0.05795 test_acc:0.6511\n",
      "Epoch  147\n",
      "Accuracy ---->  0.6863062381744385\n",
      "Iter:147 train_rmse:4.523 test_loss:309.4 test_rmse:0.0579 test_acc:0.6514\n",
      "Epoch  148\n",
      "Accuracy ---->  0.6865387856960297\n",
      "Iter:148 train_rmse:4.52 test_loss:308.9 test_rmse:0.05786 test_acc:0.6516\n",
      "Epoch  149\n",
      "Accuracy ---->  0.6867693960666656\n",
      "Iter:149 train_rmse:4.516 test_loss:308.5 test_rmse:0.05782 test_acc:0.6519\n",
      "Epoch  150\n",
      "Accuracy ---->  0.6869979202747345\n",
      "Iter:150 train_rmse:4.513 test_loss:308.1 test_rmse:0.05778 test_acc:0.6521\n",
      "Epoch  151\n",
      "Accuracy ---->  0.6872246563434601\n",
      "Iter:151 train_rmse:4.51 test_loss:307.6 test_rmse:0.05774 test_acc:0.6523\n",
      "Epoch  152\n",
      "Accuracy ---->  0.6874493658542633\n",
      "Iter:152 train_rmse:4.507 test_loss:307.2 test_rmse:0.0577 test_acc:0.6526\n",
      "Epoch  153\n",
      "Accuracy ---->  0.6876720786094666\n",
      "Iter:153 train_rmse:4.503 test_loss:306.8 test_rmse:0.05766 test_acc:0.6528\n",
      "Epoch  154\n",
      "Accuracy ---->  0.6878930628299713\n",
      "Iter:154 train_rmse:4.5 test_loss:306.4 test_rmse:0.05763 test_acc:0.6531\n",
      "Epoch  155\n",
      "Accuracy ---->  0.6881120204925537\n",
      "Iter:155 train_rmse:4.497 test_loss:306.0 test_rmse:0.05759 test_acc:0.6533\n",
      "Epoch  156\n",
      "Accuracy ---->  0.6883289515972137\n",
      "Iter:156 train_rmse:4.494 test_loss:305.6 test_rmse:0.05755 test_acc:0.6535\n",
      "Epoch  157\n",
      "Accuracy ---->  0.6885440349578857\n",
      "Iter:157 train_rmse:4.491 test_loss:305.2 test_rmse:0.05751 test_acc:0.6537\n",
      "Epoch  158\n",
      "Accuracy ---->  0.6887570917606354\n",
      "Iter:158 train_rmse:4.488 test_loss:304.9 test_rmse:0.05748 test_acc:0.6539\n",
      "Epoch  159\n",
      "Accuracy ---->  0.6889678835868835\n",
      "Iter:159 train_rmse:4.485 test_loss:304.5 test_rmse:0.05744 test_acc:0.6541\n",
      "Epoch  160\n",
      "Accuracy ---->  0.6891763806343079\n",
      "Iter:160 train_rmse:4.482 test_loss:304.1 test_rmse:0.05741 test_acc:0.6544\n",
      "Epoch  161\n",
      "Accuracy ---->  0.6893821954727173\n",
      "Iter:161 train_rmse:4.479 test_loss:303.8 test_rmse:0.05738 test_acc:0.6546\n",
      "Epoch  162\n",
      "Accuracy ---->  0.6895850002765656\n",
      "Iter:162 train_rmse:4.476 test_loss:303.4 test_rmse:0.05734 test_acc:0.6548\n",
      "Epoch  163\n",
      "Accuracy ---->  0.6897842884063721\n",
      "Iter:163 train_rmse:4.473 test_loss:303.1 test_rmse:0.05731 test_acc:0.655\n",
      "Epoch  164\n",
      "Accuracy ---->  0.6899795830249786\n",
      "Iter:164 train_rmse:4.47 test_loss:302.7 test_rmse:0.05728 test_acc:0.6551\n",
      "Epoch  165\n",
      "Accuracy ---->  0.690170168876648\n",
      "Iter:165 train_rmse:4.467 test_loss:302.4 test_rmse:0.05725 test_acc:0.6553\n",
      "Epoch  166\n",
      "Accuracy ---->  0.6903553009033203\n",
      "Iter:166 train_rmse:4.465 test_loss:302.1 test_rmse:0.05722 test_acc:0.6555\n",
      "Epoch  167\n",
      "Accuracy ---->  0.6905341148376465\n",
      "Iter:167 train_rmse:4.462 test_loss:301.8 test_rmse:0.05719 test_acc:0.6557\n",
      "Epoch  168\n",
      "Accuracy ---->  0.6907059848308563\n",
      "Iter:168 train_rmse:4.46 test_loss:301.5 test_rmse:0.05716 test_acc:0.6559\n",
      "Epoch  169\n",
      "Accuracy ---->  0.6908705234527588\n",
      "Iter:169 train_rmse:4.457 test_loss:301.2 test_rmse:0.05713 test_acc:0.6561\n",
      "Epoch  170\n",
      "Accuracy ---->  0.6910280287265778\n",
      "Iter:170 train_rmse:4.455 test_loss:300.9 test_rmse:0.0571 test_acc:0.6562\n",
      "Epoch  171\n",
      "Accuracy ---->  0.6911799907684326\n",
      "Iter:171 train_rmse:4.453 test_loss:300.6 test_rmse:0.05707 test_acc:0.6564\n",
      "Epoch  172\n",
      "Accuracy ---->  0.6913294792175293\n",
      "Iter:172 train_rmse:4.451 test_loss:300.4 test_rmse:0.05705 test_acc:0.6565\n",
      "Epoch  173\n",
      "Accuracy ---->  0.6914811134338379\n",
      "Iter:173 train_rmse:4.448 test_loss:300.1 test_rmse:0.05703 test_acc:0.6566\n",
      "Epoch  174\n",
      "Accuracy ---->  0.6916403472423553\n",
      "Iter:174 train_rmse:4.446 test_loss:300.0 test_rmse:0.05701 test_acc:0.6567\n",
      "Epoch  175\n",
      "Accuracy ---->  0.6918125450611115\n",
      "Iter:175 train_rmse:4.444 test_loss:299.8 test_rmse:0.057 test_acc:0.6568\n",
      "Epoch  176\n",
      "Accuracy ---->  0.6920004189014435\n",
      "Iter:176 train_rmse:4.441 test_loss:299.8 test_rmse:0.05699 test_acc:0.6569\n",
      "Epoch  177\n",
      "Accuracy ---->  0.6922006011009216\n",
      "Iter:177 train_rmse:4.438 test_loss:299.7 test_rmse:0.05699 test_acc:0.6569\n",
      "Epoch  178\n",
      "Accuracy ---->  0.6923978328704834\n",
      "Iter:178 train_rmse:4.435 test_loss:299.7 test_rmse:0.05699 test_acc:0.6569\n",
      "Epoch  179\n",
      "Accuracy ---->  0.6925548315048218\n",
      "Iter:179 train_rmse:4.433 test_loss:299.6 test_rmse:0.05697 test_acc:0.657\n",
      "Epoch  180\n",
      "Accuracy ---->  0.6926076114177704\n",
      "Iter:180 train_rmse:4.432 test_loss:299.2 test_rmse:0.05694 test_acc:0.6572\n",
      "Epoch  181\n",
      "Accuracy ---->  0.692513108253479\n",
      "Iter:181 train_rmse:4.434 test_loss:298.6 test_rmse:0.05688 test_acc:0.6575\n",
      "Epoch  182\n",
      "Accuracy ---->  0.6924001574516296\n",
      "Iter:182 train_rmse:4.435 test_loss:297.7 test_rmse:0.0568 test_acc:0.658\n",
      "Epoch  183\n",
      "Accuracy ---->  0.6925235688686371\n",
      "Iter:183 train_rmse:4.433 test_loss:297.1 test_rmse:0.05674 test_acc:0.6584\n",
      "Epoch  184\n",
      "Accuracy ---->  0.692809671163559\n",
      "Iter:184 train_rmse:4.429 test_loss:296.8 test_rmse:0.05671 test_acc:0.6586\n",
      "Epoch  185\n",
      "Accuracy ---->  0.6930504143238068\n",
      "Iter:185 train_rmse:4.426 test_loss:296.6 test_rmse:0.05669 test_acc:0.6587\n",
      "Epoch  186\n",
      "Accuracy ---->  0.6932291686534882\n",
      "Iter:186 train_rmse:4.423 test_loss:296.3 test_rmse:0.05667 test_acc:0.6588\n",
      "Epoch  187\n",
      "Accuracy ---->  0.693378210067749\n",
      "Iter:187 train_rmse:4.421 test_loss:296.1 test_rmse:0.05664 test_acc:0.659\n",
      "Epoch  188\n",
      "Accuracy ---->  0.6935136914253235\n",
      "Iter:188 train_rmse:4.419 test_loss:295.8 test_rmse:0.05662 test_acc:0.6591\n",
      "Epoch  189\n",
      "Accuracy ---->  0.6936421692371368\n",
      "Iter:189 train_rmse:4.417 test_loss:295.6 test_rmse:0.0566 test_acc:0.6592\n",
      "Epoch  190\n",
      "Accuracy ---->  0.6937668025493622\n",
      "Iter:190 train_rmse:4.415 test_loss:295.4 test_rmse:0.05657 test_acc:0.6594\n",
      "Epoch  191\n",
      "Accuracy ---->  0.6938891112804413\n",
      "Iter:191 train_rmse:4.414 test_loss:295.1 test_rmse:0.05655 test_acc:0.6595\n",
      "Epoch  192\n",
      "Accuracy ---->  0.694009929895401\n",
      "Iter:192 train_rmse:4.412 test_loss:294.9 test_rmse:0.05653 test_acc:0.6597\n",
      "Epoch  193\n",
      "Accuracy ---->  0.6941299140453339\n",
      "Iter:193 train_rmse:4.41 test_loss:294.7 test_rmse:0.05651 test_acc:0.6598\n",
      "Epoch  194\n",
      "Accuracy ---->  0.6942493915557861\n",
      "Iter:194 train_rmse:4.409 test_loss:294.5 test_rmse:0.05649 test_acc:0.6599\n",
      "Epoch  195\n",
      "Accuracy ---->  0.6943687200546265\n",
      "Iter:195 train_rmse:4.407 test_loss:294.2 test_rmse:0.05646 test_acc:0.6601\n",
      "Epoch  196\n",
      "Accuracy ---->  0.694488137960434\n",
      "Iter:196 train_rmse:4.405 test_loss:294.0 test_rmse:0.05644 test_acc:0.6602\n",
      "Epoch  197\n",
      "Accuracy ---->  0.6946077644824982\n",
      "Iter:197 train_rmse:4.403 test_loss:293.8 test_rmse:0.05642 test_acc:0.6603\n",
      "Epoch  198\n",
      "Accuracy ---->  0.6947278082370758\n",
      "Iter:198 train_rmse:4.402 test_loss:293.6 test_rmse:0.0564 test_acc:0.6604\n",
      "Epoch  199\n",
      "Accuracy ---->  0.6948482394218445\n",
      "Iter:199 train_rmse:4.4 test_loss:293.4 test_rmse:0.05638 test_acc:0.6606\n",
      "Epoch  200\n",
      "Accuracy ---->  0.6949689388275146\n",
      "Iter:200 train_rmse:4.398 test_loss:293.1 test_rmse:0.05636 test_acc:0.6607\n",
      "Epoch  201\n",
      "Accuracy ---->  0.6950893998146057\n",
      "Iter:201 train_rmse:4.396 test_loss:292.9 test_rmse:0.05634 test_acc:0.6608\n",
      "Epoch  202\n",
      "Accuracy ---->  0.695208877325058\n",
      "Iter:202 train_rmse:4.395 test_loss:292.7 test_rmse:0.05632 test_acc:0.6609\n",
      "Epoch  203\n",
      "Accuracy ---->  0.695326030254364\n",
      "Iter:203 train_rmse:4.393 test_loss:292.5 test_rmse:0.0563 test_acc:0.6611\n",
      "Epoch  204\n",
      "Accuracy ---->  0.6954396069049835\n",
      "Iter:204 train_rmse:4.391 test_loss:292.3 test_rmse:0.05627 test_acc:0.6612\n",
      "Epoch  205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6955492496490479\n",
      "Iter:205 train_rmse:4.39 test_loss:292.0 test_rmse:0.05625 test_acc:0.6613\n",
      "Epoch  206\n",
      "Accuracy ---->  0.6956576406955719\n",
      "Iter:206 train_rmse:4.388 test_loss:291.8 test_rmse:0.05623 test_acc:0.6615\n",
      "Epoch  207\n",
      "Accuracy ---->  0.695770800113678\n",
      "Iter:207 train_rmse:4.387 test_loss:291.6 test_rmse:0.05621 test_acc:0.6616\n",
      "Epoch  208\n",
      "Accuracy ---->  0.6958894431591034\n",
      "Iter:208 train_rmse:4.385 test_loss:291.4 test_rmse:0.05619 test_acc:0.6617\n",
      "Epoch  209\n",
      "Accuracy ---->  0.6960035562515259\n",
      "Iter:209 train_rmse:4.383 test_loss:291.3 test_rmse:0.05618 test_acc:0.6618\n",
      "Epoch  210\n",
      "Accuracy ---->  0.6961077153682709\n",
      "Iter:210 train_rmse:4.382 test_loss:291.1 test_rmse:0.05616 test_acc:0.6619\n",
      "Epoch  211\n",
      "Accuracy ---->  0.6962072253227234\n",
      "Iter:211 train_rmse:4.38 test_loss:290.9 test_rmse:0.05614 test_acc:0.662\n",
      "Epoch  212\n",
      "Accuracy ---->  0.6963070034980774\n",
      "Iter:212 train_rmse:4.379 test_loss:290.8 test_rmse:0.05613 test_acc:0.662\n",
      "Epoch  213\n",
      "Accuracy ---->  0.6964088082313538\n",
      "Iter:213 train_rmse:4.377 test_loss:290.7 test_rmse:0.05612 test_acc:0.6621\n",
      "Epoch  214\n",
      "Accuracy ---->  0.6965116858482361\n",
      "Iter:214 train_rmse:4.376 test_loss:290.7 test_rmse:0.05612 test_acc:0.6621\n",
      "Epoch  215\n",
      "Accuracy ---->  0.6966082155704498\n",
      "Iter:215 train_rmse:4.375 test_loss:290.6 test_rmse:0.05612 test_acc:0.6621\n",
      "Epoch  216\n",
      "Accuracy ---->  0.6966753005981445\n",
      "Iter:216 train_rmse:4.374 test_loss:290.6 test_rmse:0.05611 test_acc:0.6622\n",
      "Epoch  217\n",
      "Accuracy ---->  0.6966579556465149\n",
      "Iter:217 train_rmse:4.374 test_loss:290.5 test_rmse:0.0561 test_acc:0.6622\n",
      "Epoch  218\n",
      "Accuracy ---->  0.6964651942253113\n",
      "Iter:218 train_rmse:4.377 test_loss:290.1 test_rmse:0.05606 test_acc:0.6625\n",
      "Epoch  219\n",
      "Accuracy ---->  0.6961226761341095\n",
      "Iter:219 train_rmse:4.382 test_loss:289.5 test_rmse:0.056 test_acc:0.6628\n",
      "Epoch  220\n",
      "Accuracy ---->  0.696220725774765\n",
      "Iter:220 train_rmse:4.38 test_loss:289.3 test_rmse:0.05598 test_acc:0.6629\n",
      "Epoch  221\n",
      "Accuracy ---->  0.6969304978847504\n",
      "Iter:221 train_rmse:4.37 test_loss:289.3 test_rmse:0.05599 test_acc:0.6629\n",
      "Epoch  222\n",
      "Accuracy ---->  0.6972295343875885\n",
      "Iter:222 train_rmse:4.366 test_loss:289.1 test_rmse:0.05597 test_acc:0.663\n",
      "Epoch  223\n",
      "Accuracy ---->  0.697326123714447\n",
      "Iter:223 train_rmse:4.364 test_loss:288.9 test_rmse:0.05595 test_acc:0.6631\n",
      "Epoch  224\n",
      "Accuracy ---->  0.697409451007843\n",
      "Iter:224 train_rmse:4.363 test_loss:288.8 test_rmse:0.05594 test_acc:0.6632\n",
      "Epoch  225\n",
      "Accuracy ---->  0.6974912881851196\n",
      "Iter:225 train_rmse:4.362 test_loss:288.7 test_rmse:0.05592 test_acc:0.6633\n",
      "Epoch  226\n",
      "Accuracy ---->  0.6975705325603485\n",
      "Iter:226 train_rmse:4.361 test_loss:288.5 test_rmse:0.05591 test_acc:0.6634\n",
      "Epoch  227\n",
      "Accuracy ---->  0.697646826505661\n",
      "Iter:227 train_rmse:4.36 test_loss:288.4 test_rmse:0.0559 test_acc:0.6635\n",
      "Epoch  228\n",
      "Accuracy ---->  0.6977204382419586\n",
      "Iter:228 train_rmse:4.358 test_loss:288.2 test_rmse:0.05588 test_acc:0.6635\n",
      "Epoch  229\n",
      "Accuracy ---->  0.6977925002574921\n",
      "Iter:229 train_rmse:4.357 test_loss:288.1 test_rmse:0.05587 test_acc:0.6636\n",
      "Epoch  230\n",
      "Accuracy ---->  0.6978640258312225\n",
      "Iter:230 train_rmse:4.356 test_loss:287.9 test_rmse:0.05585 test_acc:0.6637\n",
      "Epoch  231\n",
      "Accuracy ---->  0.697936087846756\n",
      "Iter:231 train_rmse:4.355 test_loss:287.8 test_rmse:0.05584 test_acc:0.6638\n",
      "Epoch  232\n",
      "Accuracy ---->  0.6980094909667969\n",
      "Iter:232 train_rmse:4.354 test_loss:287.6 test_rmse:0.05582 test_acc:0.6639\n",
      "Epoch  233\n",
      "Accuracy ---->  0.6980844438076019\n",
      "Iter:233 train_rmse:4.353 test_loss:287.4 test_rmse:0.05581 test_acc:0.664\n",
      "Epoch  234\n",
      "Accuracy ---->  0.6981613039970398\n",
      "Iter:234 train_rmse:4.352 test_loss:287.3 test_rmse:0.05579 test_acc:0.6641\n",
      "Epoch  235\n",
      "Accuracy ---->  0.6982401609420776\n",
      "Iter:235 train_rmse:4.351 test_loss:287.1 test_rmse:0.05578 test_acc:0.6642\n",
      "Epoch  236\n",
      "Accuracy ---->  0.698322057723999\n",
      "Iter:236 train_rmse:4.35 test_loss:287.0 test_rmse:0.05576 test_acc:0.6643\n",
      "Epoch  237\n",
      "Accuracy ---->  0.698409378528595\n",
      "Iter:237 train_rmse:4.349 test_loss:286.8 test_rmse:0.05575 test_acc:0.6644\n",
      "Epoch  238\n",
      "Accuracy ---->  0.6985063850879669\n",
      "Iter:238 train_rmse:4.347 test_loss:286.7 test_rmse:0.05573 test_acc:0.6645\n",
      "Epoch  239\n",
      "Accuracy ---->  0.6986157596111298\n",
      "Iter:239 train_rmse:4.346 test_loss:286.5 test_rmse:0.05572 test_acc:0.6645\n",
      "Epoch  240\n",
      "Accuracy ---->  0.6987337172031403\n",
      "Iter:240 train_rmse:4.344 test_loss:286.4 test_rmse:0.0557 test_acc:0.6646\n",
      "Epoch  241\n",
      "Accuracy ---->  0.6988506019115448\n",
      "Iter:241 train_rmse:4.342 test_loss:286.2 test_rmse:0.05568 test_acc:0.6647\n",
      "Epoch  242\n",
      "Accuracy ---->  0.6989592611789703\n",
      "Iter:242 train_rmse:4.341 test_loss:286.0 test_rmse:0.05567 test_acc:0.6649\n",
      "Epoch  243\n",
      "Accuracy ---->  0.6990590691566467\n",
      "Iter:243 train_rmse:4.339 test_loss:285.8 test_rmse:0.05565 test_acc:0.665\n",
      "Epoch  244\n",
      "Accuracy ---->  0.6991523504257202\n",
      "Iter:244 train_rmse:4.338 test_loss:285.7 test_rmse:0.05563 test_acc:0.6651\n",
      "Epoch  245\n",
      "Accuracy ---->  0.6992410719394684\n",
      "Iter:245 train_rmse:4.337 test_loss:285.5 test_rmse:0.05562 test_acc:0.6652\n",
      "Epoch  246\n",
      "Accuracy ---->  0.6993263363838196\n",
      "Iter:246 train_rmse:4.335 test_loss:285.3 test_rmse:0.0556 test_acc:0.6653\n",
      "Epoch  247\n",
      "Accuracy ---->  0.699408769607544\n",
      "Iter:247 train_rmse:4.334 test_loss:285.2 test_rmse:0.05558 test_acc:0.6653\n",
      "Epoch  248\n",
      "Accuracy ---->  0.6994888484477997\n",
      "Iter:248 train_rmse:4.333 test_loss:285.0 test_rmse:0.05557 test_acc:0.6654\n",
      "Epoch  249\n",
      "Accuracy ---->  0.6995668113231659\n",
      "Iter:249 train_rmse:4.332 test_loss:284.8 test_rmse:0.05555 test_acc:0.6655\n",
      "Epoch  250\n",
      "Accuracy ---->  0.6996431648731232\n",
      "Iter:250 train_rmse:4.331 test_loss:284.7 test_rmse:0.05553 test_acc:0.6656\n",
      "Epoch  251\n",
      "Accuracy ---->  0.6997183561325073\n",
      "Iter:251 train_rmse:4.33 test_loss:284.5 test_rmse:0.05552 test_acc:0.6657\n",
      "Epoch  252\n",
      "Accuracy ---->  0.6997927725315094\n",
      "Iter:252 train_rmse:4.329 test_loss:284.3 test_rmse:0.0555 test_acc:0.6658\n",
      "Epoch  253\n",
      "Accuracy ---->  0.6998670399188995\n",
      "Iter:253 train_rmse:4.328 test_loss:284.2 test_rmse:0.05548 test_acc:0.6659\n",
      "Epoch  254\n",
      "Accuracy ---->  0.6999413371086121\n",
      "Iter:254 train_rmse:4.326 test_loss:284.0 test_rmse:0.05547 test_acc:0.6661\n",
      "Epoch  255\n",
      "Accuracy ---->  0.7000161409378052\n",
      "Iter:255 train_rmse:4.325 test_loss:283.8 test_rmse:0.05545 test_acc:0.6662\n",
      "Epoch  256\n",
      "Accuracy ---->  0.7000916302204132\n",
      "Iter:256 train_rmse:4.324 test_loss:283.6 test_rmse:0.05543 test_acc:0.6663\n",
      "Epoch  257\n",
      "Accuracy ---->  0.7001683413982391\n",
      "Iter:257 train_rmse:4.323 test_loss:283.5 test_rmse:0.05542 test_acc:0.6664\n",
      "Epoch  258\n",
      "Accuracy ---->  0.7002468705177307\n",
      "Iter:258 train_rmse:4.322 test_loss:283.3 test_rmse:0.0554 test_acc:0.6665\n",
      "Epoch  259\n",
      "Accuracy ---->  0.7003282010555267\n",
      "Iter:259 train_rmse:4.321 test_loss:283.1 test_rmse:0.05538 test_acc:0.6666\n",
      "Epoch  260\n",
      "Accuracy ---->  0.7004134058952332\n",
      "Iter:260 train_rmse:4.32 test_loss:282.9 test_rmse:0.05536 test_acc:0.6667\n",
      "Epoch  261\n",
      "Accuracy ---->  0.7005034387111664\n",
      "Iter:261 train_rmse:4.318 test_loss:282.8 test_rmse:0.05535 test_acc:0.6668\n",
      "Epoch  262\n",
      "Accuracy ---->  0.7005981206893921\n",
      "Iter:262 train_rmse:4.317 test_loss:282.6 test_rmse:0.05533 test_acc:0.6669\n",
      "Epoch  263\n",
      "Accuracy ---->  0.7006959021091461\n",
      "Iter:263 train_rmse:4.316 test_loss:282.4 test_rmse:0.05531 test_acc:0.667\n",
      "Epoch  264\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epoch):\n",
    "    print(\"Epoch \", epoch)\n",
    "    for m in range(totalbatch):\n",
    "        mini_batch = trainX[m * batch_size : (m+1) * batch_size]\n",
    "        mini_label = trainY[m * batch_size : (m+1) * batch_size]\n",
    "        _, loss1, rmse1, train_output = sess.run([optimizer, loss, error, y_pred],\n",
    "                                                 feed_dict = {inputs:mini_batch, labels:mini_label})\n",
    "        batch_loss.append(loss1)\n",
    "        batch_rmse.append(rmse1 * max_value)\n",
    "        train_label=np.reshape(mini_label,[-1,num_nodes])\n",
    "     #print(mini_label.shape,train_output.shape) (32, 1, 156) (32, 156)\n",
    "     # Test completely at every epoch\n",
    "    print(\"Accuracy ----> \", evaluation(train_label,train_output)[2])\n",
    "    loss2, rmse2, test_output = sess.run([loss, error, y_pred],\n",
    "                                         feed_dict = {inputs:testX, labels:testY})\n",
    "    #train_label=np.reshape(trainY,[-1,num_nodes])\n",
    "    #train_acc=acc(train_label,train_output)\n",
    "    test_label = np.reshape(testY,[-1,num_nodes])\n",
    "    rmse, mae, acc, r2_score, var_score = evaluation(test_label, test_output)\n",
    "    test_label1 = test_label * max_value#Inverse normalization\n",
    "    test_output1 = test_output * max_value\n",
    "    test_loss.append(loss2)\n",
    "    test_rmse.append(rmse * max_value)\n",
    "    test_mae.append(mae * max_value)\n",
    "    test_acc.append(acc)\n",
    "    test_r2.append(r2_score)\n",
    "    test_var.append(var_score)\n",
    "    test_pred.append(test_output1)\n",
    "    #print(mini_label.shape,train_output.shape)\n",
    "    print('Iter:{}'.format(epoch),\n",
    "          'train_rmse:{:.4}'.format(batch_rmse[-1]),\n",
    "          'test_loss:{:.4}'.format(loss2),\n",
    "          'test_rmse:{:.4}'.format(rmse),\n",
    "          'test_acc:{:.4}'.format(acc))\n",
    "    if (epoch % 500 == 0):        \n",
    "        saver.save(sess, path+'/model_10060TGCN_pre_%r'%epoch, global_step = epoch)\n",
    "        \n",
    "time_end = time.time()\n",
    "print('Time taken : ',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = int(len(batch_rmse)/totalbatch)\n",
    "batch_rmse1 = [i for i in batch_rmse]\n",
    "train_rmse = [(sum(batch_rmse1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "batch_loss1 = [i for i in batch_loss]\n",
    "train_loss = [(sum(batch_loss1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "\n",
    "index = test_rmse.index(np.min(test_rmse))\n",
    "test_result = test_pred[index]\n",
    "var = pd.DataFrame(test_result)\n",
    "var.to_csv(path+'/test_result60.csv',index = False,header = False)\n",
    "#plot_result(test_result,test_label1,path)\n",
    "#plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing:\")\n",
    "print('min_rmse:%r'%(np.min(test_rmse)),\n",
    "      'min_mae:%r'%(test_mae[index]),\n",
    "      'max_acc:%r'%(test_acc[index]),\n",
    "      'r2:%r'%(test_r2[index]),\n",
    "      'var:%r'%test_var[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training:\")\n",
    "rmse, mae, acc, r2_score, var_score = evaluation(train_label,train_output)\n",
    "print('min_rmse:%r'%(rmse),\n",
    "      'min_mae:%r'%(mae),\n",
    "      'max_acc:%r'%(acc),\n",
    "      'r2:%r'%(r2_score),\n",
    "      'var:%r'%(var_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse normalisation\n",
    "print('min_rmse:%r'%(rmse*max_value),\n",
    "      'min_mae:%r'%(mae*max_value),\n",
    "      'max_acc:%r'%(acc),\n",
    "      'r2:%r'%(r2_score),\n",
    "      'var:%r'%(var_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(test_result,test_label1,path):\n",
    "    ##all test result visualization\n",
    "    fig1 = plt.figure(figsize=(7,1.5))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "    a_pred = test_result[:,0]\n",
    "    a_true = test_label1[:,0]\n",
    "    plt.plot(a_pred,'r-',label='prediction')\n",
    "    plt.plot(a_true,'b-',label='true')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_all.jpg')\n",
    "    plt.show()\n",
    "    ## oneday test result visualization\n",
    "    fig1 = plt.figure(figsize=(7,1.5))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "    a_pred = test_result[0:96,0]\n",
    "    a_true = test_label1[0:96,0]\n",
    "    plt.plot(a_pred,'r-',label=\"prediction\")\n",
    "    plt.plot(a_true,'b-',label=\"true\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_oneday.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path):\n",
    "    ###train_rmse & test_rmse \n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_rmse, 'r-', label=\"train_rmse\")\n",
    "    plt.plot(test_rmse, 'b-', label=\"test_rmse\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/rmse.jpg')\n",
    "    plt.show()\n",
    "    #### train_loss & train_rmse\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_loss,'b-', label='train_loss')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_loss.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_rmse,'b-', label='train_rmse')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_rmse.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    ### accuracy\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_acc, 'b-', label=\"test_acc\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_acc.jpg')\n",
    "    plt.show()\n",
    "    ### rmse\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_rmse, 'b-', label=\"test_rmse\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_rmse.jpg')\n",
    "    plt.show()\n",
    "    ### mae\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_mae, 'b-', label=\"test_mae\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_mae.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(test_result,test_label1,path)\n",
    "plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
