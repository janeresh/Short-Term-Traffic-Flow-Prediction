{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from tensorflow.contrib.rnn import RNNCell\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "#import matplotlib.pyplot as plt\n",
    "import time\n",
    "time_start=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of Dataset-SZ Traffic\n",
    "def load_sz_data():\n",
    "    sz_adj = pd.read_csv('sz_adj.csv',header=None)\n",
    "    adj = np.mat(sz_adj)\n",
    "    sz_tf = pd.read_csv('sz_speed.csv')\n",
    "    return sz_tf, adj\n",
    "\n",
    "data, adj = load_sz_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2976, 156)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "time_len=data.shape[0] # Time sequence length\n",
    "num_nodes=data.shape[1] #Number of Roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the variables\n",
    "output_dim=pre_len=2\n",
    "seq_len=4\n",
    "num_units=64\n",
    "train_rate=0.8\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0980221  0.21353212 0.23823702 ... 0.19194394 0.37707424 0.        ]\n",
      " [0.09032986 0.18181142 0.31845367 ... 0.45834997 0.37705195 0.        ]\n",
      " [0.10192686 0.10389599 0.23464748 ... 0.3856561  0.43354756 0.        ]\n",
      " ...\n",
      " [0.37947276 0.141638   0.10453826 ... 0.13605069 0.1998609  0.        ]\n",
      " [0.39722532 0.18600048 0.121989   ... 0.16306393 0.16957766 0.        ]\n",
      " [0.38101357 0.14001252 0.10420388 ... 0.19054307 0.1845446  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Normalization : Traffic Speed Data\n",
    "\n",
    "data1 =np.mat(data,dtype=np.float32)\n",
    "\n",
    "max_value = np.max(data1)\n",
    "data1  = data1/max_value\n",
    "print(data1)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2380, 156) -----> (596, 156)\n",
      "Train Test Split Details :\n",
      "Train x ---->  2374\n",
      "Train y ---->  2374\n",
      "(2374, 4, 156)\n",
      "Test x ---->  590\n",
      "Test y ---->  590\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data, time_len, rate, seq_len, pre_len):\n",
    "    train_size = int(time_len * rate) #2976 *0.8 =2380\n",
    "    train_data = data[0:train_size] #  [0:2380]\n",
    "    test_data = data[train_size:time_len] #[2380:2976]\n",
    "    print(train_data.shape,'----->',test_data.shape)\n",
    "\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(train_data) - seq_len - pre_len): #(2380-4-1)=2375\n",
    "        a = train_data[i: i + seq_len + pre_len] #[0:0+4+1] \n",
    "        trainX.append(a[0 : seq_len]) #a[0:4] 4 time * 156 roads\n",
    "        trainY.append(a[seq_len : seq_len + pre_len]) #a[4:4+1] 1 time*156 \n",
    "    for i in range(len(test_data) - seq_len -pre_len):\n",
    "        b = test_data[i: i + seq_len + pre_len]\n",
    "        testX.append(b[0 : seq_len])\n",
    "        testY.append(b[seq_len : seq_len + pre_len])\n",
    "      \n",
    "    trainX1 = np.array(trainX) \n",
    "    trainY1 = np.array(trainY)\n",
    "    testX1 = np.array(testX)\n",
    "    testY1 = np.array(testY)\n",
    "    return trainX1, trainY1, testX1, testY1\n",
    "\n",
    "trainX, trainY, testX, testY = preprocess_data(data1, time_len, train_rate, seq_len, pre_len)\n",
    "\n",
    "totalbatch = int(trainX.shape[0]/batch_size)\n",
    "training_data_count = len(trainX)  \n",
    "print('Train Test Split Details :')\n",
    "print('Train x ----> ',len(trainX))\n",
    "print('Train y ----> ',len(trainY))\n",
    "print(trainX.shape)\n",
    "print('Test x ----> ',len(testX))\n",
    "print('Test y ----> ',len(testY))\n",
    "#print('\\nTrain Sample Details :')\n",
    "#print(trainX[0],'--->',trainY[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
    "        init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "        initial = tf.random_uniform([input_dim, output_dim], minval=-init_range, maxval=init_range, dtype=tf.float32)\n",
    "        return tf.Variable(initial,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stgcnCell(RNNCell):\n",
    "    \"\"\"Temporal Graph Convolutional Network \"\"\"\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __init__(self, num_units, adj, num_nodes, input_size=None,\n",
    "                 act=tf.nn.tanh, reuse=None):\n",
    "\n",
    "        super(stgcnCell, self).__init__(_reuse=reuse)\n",
    "        self._act = act\n",
    "        self._nodes = num_nodes\n",
    "        self._units = num_units\n",
    "        self._adj = []\n",
    "        self._adj.append(self.calculate_laplacian(adj))\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_sparse_matrix(L):\n",
    "        L = L.tocoo()\n",
    "        indices = np.column_stack((L.row, L.col))\n",
    "        L = tf.SparseTensor(indices, L.data, L.shape)\n",
    "        return tf.sparse_reorder(L)\n",
    "\n",
    "    def calculate_laplacian(self,adj, lambda_max=1):  \n",
    "        adj = self.normalized_adj(adj + sp.eye(adj.shape[0])) # normalisation(self identity matrix + adj)\n",
    "        adj = sp.csr_matrix(adj) #compressed sparse matrix\n",
    "        adj = adj.astype(np.float32)\n",
    "        return self.sparse_to_tuple(adj)\n",
    "    \n",
    "    def normalized_adj(self,adj):\n",
    "        adj = sp.coo_matrix(adj)\n",
    "        degree = np.array(adj.sum(1)) # Degree Matrix row wise sum\n",
    "        d_inv_sqrt = np.power(degree, -0.5).flatten() # D inv = Degree ^-0.5 \n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt) #substitution of the 1D array degree in a 2D matrix diagonals\n",
    "        normalized_adj = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo() # norm= D^-0.5 * adj * D^-0.5\n",
    "        normalized_adj = normalized_adj.astype(np.float32) \n",
    "        return normalized_adj\n",
    "    \n",
    "    def sparse_to_tuple(self,mx):\n",
    "        mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose() #coordinate stacking row and column wise and transpose\n",
    "        L = tf.SparseTensor(coords, mx.data, mx.shape) # mx.shape= (156,156)\n",
    "        #print('shape ---->',mx.shape)\n",
    "        return tf.sparse_reorder(L) #row major ordering\n",
    "        \n",
    "    def init_state(self,batch_size):       \n",
    "        state = tf.zeros(shape=[batch_size, self._num_nodes*self._num_units], dtype=tf.float32)\n",
    "        return state  \n",
    "               \n",
    "    @staticmethod\n",
    "    def _concat(x, x_):\n",
    "        x_ = tf.expand_dims(x_, 0)\n",
    "        return tf.concat([x, x_], axis=0)   \n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._nodes * self._units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._units\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "\n",
    "        with tf.variable_scope(scope or \"tgcn\"):\n",
    "            with tf.variable_scope(\"gates\"):  \n",
    "                value = tf.nn.sigmoid(\n",
    "                    self._gc(inputs, state, 2 * self._units, bias=1.0, scope=scope)) #ut (or) rt = sigma(Wu [f(A;Xt); h{t-1}] + bu)\n",
    "                r, u = tf.split(value=value, num_or_size_splits=2, axis=1)\n",
    "            with tf.variable_scope(\"candidate\"):\n",
    "                r_state = r * state #r* h{t-1}\n",
    "                c = self._act(self._gc(inputs, r_state, self._units, scope=scope))#ct = tanh(Wc [f(A;Xt); r_state] + bc) \n",
    "            new_h = u * state + (1 - u) * c #ht = ut * h{t-1} + (1 - u{t}) * ct\n",
    "        return new_h, new_h\n",
    "\n",
    "\n",
    "    def _gc(self, inputs, state, output_size, bias=0.0, scope=None):\n",
    "        ## inputs:(-1,num_nodes)\n",
    "        inputs = tf.expand_dims(inputs, 2)#None,156,None\n",
    "        ## state:(batch,num_node,gru_units)\n",
    "        state = tf.reshape(state, (-1, self._nodes, self._units)) #32,156,64\n",
    "        ## concat\n",
    "        x_s = tf.concat([inputs, state], axis=2) #32,156,65\n",
    "        input_size = x_s.get_shape()[2].value #65\n",
    "        ## (num_node,input_size,-1)\n",
    "        x0 = tf.transpose(x_s, perm=[1, 2, 0]) #156,65,32\n",
    "        x0 = tf.reshape(x0, shape=[self._nodes, -1]) #156,65*32\n",
    "        scope = tf.get_variable_scope()\n",
    "        with tf.variable_scope(scope):\n",
    "            for m in self._adj:#1,156\n",
    "                x1 = tf.sparse_tensor_dense_matmul(m, x0) #1,65*32\n",
    "#                print(x1)\n",
    "            x = tf.reshape(x1, shape=[self._nodes, input_size,-1]) #156,65,32\n",
    "            x = tf.transpose(x,perm=[2,0,1]) #32,156,65\n",
    "            x = tf.reshape(x, shape=[-1, input_size]) #156*32,65\n",
    "            weights = tf.get_variable( # 65,64\n",
    "                'weights', [input_size, output_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            x = tf.matmul(x, weights)  # (batch_size * self._nodes, output_size) \n",
    "            biases = tf.get_variable( #64\n",
    "                \"biases\", [output_size], initializer=tf.constant_initializer(bias, dtype=tf.float32))\n",
    "            x = tf.nn.bias_add(x, biases) #biases added\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes, output_size]) #32,156,64\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes * output_size])#32,156*64\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STGCN(_X, _weights, _biases):\n",
    "    ###\n",
    "    cell_1 = stgcnCell(num_units, adj, num_nodes=num_nodes)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([cell_1], state_is_tuple=True) #stack rnn cells\n",
    "    _X = tf.unstack(_X, axis=1) # 4 tensorflow arrays of shape None,156 (seq_len=4)\n",
    "    outputs, states = tf.nn.static_rnn(cell, _X, dtype=tf.float32) #Creates a recurrent neural network specified by RNNCell cell\n",
    "    #4 ouputs and 1 state None,9984(156*64)\n",
    "    m = []\n",
    "    for i in outputs:\n",
    "        o = tf.reshape(i,shape=[-1,num_nodes,num_units])#None,156,64\n",
    "        o = tf.reshape(o,shape=[-1,num_units])#None*156,64\n",
    "        m.append(o) #4 objects\n",
    "    last_output = m[-1] #last one\n",
    "    output = tf.matmul(last_output, _weights['out']) + _biases['out'] #multiply with weights and add bias None*156,1+len(1)=156,1\n",
    "    output = tf.reshape(output,shape=[-1,num_nodes,pre_len]) # None,156,1\n",
    "    output = tf.transpose(output, perm=[0,2,1])#None,1,156\n",
    "    output = tf.reshape(output, shape=[-1,num_nodes]) #None*1,156\n",
    "    return output, m, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Lema Labs ML Workshop x64\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "WARNING:tensorflow:From <ipython-input-9-dfd1196d70e3>:4: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-9-dfd1196d70e3>:6: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=[None, seq_len, num_nodes])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, pre_len, num_nodes])\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_units, pre_len], mean=1.0), name='weight_o')} #64,1\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([pre_len]),name='bias_o')} #1\n",
    "print(type(inputs))\n",
    "pred,ttts,ttto = STGCN(inputs, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_loss = 0.0015\n",
    "Lreg = lambda_loss * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "label = tf.reshape(labels, [-1,num_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.l2_loss(y_pred-label) + Lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = tf.sqrt(tf.reduce_mean(tf.square(y_pred-label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "optimizer = tf.train.AdamOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tf.global_variables()\n",
    "training_epoch=1000\n",
    "saver = tf.train.Saver(tf.global_variables()) #\n",
    "#sess = tf.Session()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "out = 'out/%s'%(\"STGCN\")\n",
    "#out = 'out/%s_%s'%(model_name,'perturbation')\n",
    "path1 = '%s_%s_lr%r_batch%r_unit%r_seq%r_pre%r_epoch%r'%(\"S30TGCN\",\"sz\",lr,batch_size,num_units,seq_len,pre_len,training_epoch)\n",
    "path = os.path.join(out,path1)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(a,b):\n",
    "    rmse = math.sqrt(mean_squared_error(a,b))\n",
    "    mae = mean_absolute_error(a, b)\n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    r2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\n",
    "    var = 1-(np.var(a-b))/np.var(a)\n",
    "    return rmse, mae, 1-F_norm, r2, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axe,batch_loss,batch_rmse,batch_pred = [], [], [], []\n",
    "test_loss,test_rmse,test_mae,test_acc,test_r2,test_var,test_pred = [],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(a,b):  \n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    train_acc=1-F_norm\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Accuracy ---->  0.0012172460556030273\n",
      "Iter:0 train_rmse:14.4 test_loss:2.592e+03 test_rmse:0.1678 test_acc:-0.01034\n",
      "Epoch  1\n",
      "Accuracy ---->  0.5134625136852264\n",
      "Iter:1 train_rmse:7.015 test_loss:656.3 test_rmse:0.08442 test_acc:0.4917\n",
      "Epoch  2\n",
      "Accuracy ---->  0.5360048711299896\n",
      "Iter:2 train_rmse:6.69 test_loss:602.7 test_rmse:0.0809 test_acc:0.5129\n",
      "Epoch  3\n",
      "Accuracy ---->  0.5502955615520477\n",
      "Iter:3 train_rmse:6.484 test_loss:568.8 test_rmse:0.07859 test_acc:0.5269\n",
      "Epoch  4\n",
      "Accuracy ---->  0.5637805461883545\n",
      "Iter:4 train_rmse:6.29 test_loss:537.8 test_rmse:0.07641 test_acc:0.5399\n",
      "Epoch  5\n",
      "Accuracy ---->  0.5761028528213501\n",
      "Iter:5 train_rmse:6.112 test_loss:510.7 test_rmse:0.07446 test_acc:0.5517\n",
      "Epoch  6\n",
      "Accuracy ---->  0.5867531001567841\n",
      "Iter:6 train_rmse:5.958 test_loss:487.9 test_rmse:0.07278 test_acc:0.5618\n",
      "Epoch  7\n",
      "Accuracy ---->  0.5954928994178772\n",
      "Iter:7 train_rmse:5.832 test_loss:469.5 test_rmse:0.07139 test_acc:0.5702\n",
      "Epoch  8\n",
      "Accuracy ---->  0.6023658812046051\n",
      "Iter:8 train_rmse:5.733 test_loss:455.3 test_rmse:0.0703 test_acc:0.5767\n",
      "Epoch  9\n",
      "Accuracy ---->  0.6077007353305817\n",
      "Iter:9 train_rmse:5.656 test_loss:444.7 test_rmse:0.06948 test_acc:0.5817\n",
      "Epoch  10\n",
      "Accuracy ---->  0.6115780472755432\n",
      "Iter:10 train_rmse:5.601 test_loss:437.1 test_rmse:0.06888 test_acc:0.5853\n",
      "Epoch  11\n",
      "Accuracy ---->  0.6142852902412415\n",
      "Iter:11 train_rmse:5.562 test_loss:431.7 test_rmse:0.06845 test_acc:0.5879\n",
      "Epoch  12\n",
      "Accuracy ---->  0.6162250936031342\n",
      "Iter:12 train_rmse:5.534 test_loss:427.8 test_rmse:0.06814 test_acc:0.5898\n",
      "Epoch  13\n",
      "Accuracy ---->  0.6178220510482788\n",
      "Iter:13 train_rmse:5.511 test_loss:425.0 test_rmse:0.06792 test_acc:0.5911\n",
      "Epoch  14\n",
      "Accuracy ---->  0.6190928220748901\n",
      "Iter:14 train_rmse:5.492 test_loss:422.8 test_rmse:0.06774 test_acc:0.5922\n",
      "Epoch  15\n",
      "Accuracy ---->  0.6200730204582214\n",
      "Iter:15 train_rmse:5.478 test_loss:420.8 test_rmse:0.06758 test_acc:0.5931\n",
      "Epoch  16\n",
      "Accuracy ---->  0.6208841800689697\n",
      "Iter:16 train_rmse:5.466 test_loss:419.2 test_rmse:0.06745 test_acc:0.5939\n",
      "Epoch  17\n",
      "Accuracy ---->  0.6217391192913055\n",
      "Iter:17 train_rmse:5.454 test_loss:417.7 test_rmse:0.06733 test_acc:0.5946\n",
      "Epoch  18\n",
      "Accuracy ---->  0.6226292848587036\n",
      "Iter:18 train_rmse:5.441 test_loss:416.3 test_rmse:0.06722 test_acc:0.5953\n",
      "Epoch  19\n",
      "Accuracy ---->  0.623459666967392\n",
      "Iter:19 train_rmse:5.429 test_loss:414.8 test_rmse:0.0671 test_acc:0.596\n",
      "Epoch  20\n",
      "Accuracy ---->  0.6242625117301941\n",
      "Iter:20 train_rmse:5.418 test_loss:413.3 test_rmse:0.06697 test_acc:0.5968\n",
      "Epoch  21\n",
      "Accuracy ---->  0.6250423789024353\n",
      "Iter:21 train_rmse:5.406 test_loss:411.8 test_rmse:0.06685 test_acc:0.5975\n",
      "Epoch  22\n",
      "Accuracy ---->  0.6258060336112976\n",
      "Iter:22 train_rmse:5.395 test_loss:410.4 test_rmse:0.06674 test_acc:0.5982\n",
      "Epoch  23\n",
      "Accuracy ---->  0.6266547441482544\n",
      "Iter:23 train_rmse:5.383 test_loss:409.1 test_rmse:0.06664 test_acc:0.5988\n",
      "Epoch  24\n",
      "Accuracy ---->  0.6275220513343811\n",
      "Iter:24 train_rmse:5.371 test_loss:407.9 test_rmse:0.06653 test_acc:0.5994\n",
      "Epoch  25\n",
      "Accuracy ---->  0.6283340454101562\n",
      "Iter:25 train_rmse:5.359 test_loss:406.4 test_rmse:0.06641 test_acc:0.6001\n",
      "Epoch  26\n",
      "Accuracy ---->  0.6291638612747192\n",
      "Iter:26 train_rmse:5.347 test_loss:404.9 test_rmse:0.06629 test_acc:0.6009\n",
      "Epoch  27\n",
      "Accuracy ---->  0.6299887299537659\n",
      "Iter:27 train_rmse:5.335 test_loss:403.5 test_rmse:0.06618 test_acc:0.6016\n",
      "Epoch  28\n",
      "Accuracy ---->  0.6307537853717804\n",
      "Iter:28 train_rmse:5.324 test_loss:402.2 test_rmse:0.06607 test_acc:0.6022\n",
      "Epoch  29\n",
      "Accuracy ---->  0.6315216720104218\n",
      "Iter:29 train_rmse:5.313 test_loss:401.0 test_rmse:0.06597 test_acc:0.6028\n",
      "Epoch  30\n",
      "Accuracy ---->  0.6323262155056\n",
      "Iter:30 train_rmse:5.301 test_loss:399.9 test_rmse:0.06588 test_acc:0.6034\n",
      "Epoch  31\n",
      "Accuracy ---->  0.6330873668193817\n",
      "Iter:31 train_rmse:5.29 test_loss:398.8 test_rmse:0.06579 test_acc:0.6039\n",
      "Epoch  32\n",
      "Accuracy ---->  0.6337844133377075\n",
      "Iter:32 train_rmse:5.28 test_loss:397.8 test_rmse:0.0657 test_acc:0.6044\n",
      "Epoch  33\n",
      "Accuracy ---->  0.634418249130249\n",
      "Iter:33 train_rmse:5.271 test_loss:396.9 test_rmse:0.06563 test_acc:0.6049\n",
      "Epoch  34\n",
      "Accuracy ---->  0.6349741518497467\n",
      "Iter:34 train_rmse:5.263 test_loss:396.0 test_rmse:0.06556 test_acc:0.6053\n",
      "Epoch  35\n",
      "Accuracy ---->  0.6354893147945404\n",
      "Iter:35 train_rmse:5.256 test_loss:395.2 test_rmse:0.06549 test_acc:0.6057\n",
      "Epoch  36\n",
      "Accuracy ---->  0.6360235214233398\n",
      "Iter:36 train_rmse:5.248 test_loss:394.4 test_rmse:0.06542 test_acc:0.6061\n",
      "Epoch  37\n",
      "Accuracy ---->  0.6365921497344971\n",
      "Iter:37 train_rmse:5.24 test_loss:393.7 test_rmse:0.06537 test_acc:0.6065\n",
      "Epoch  38\n",
      "Accuracy ---->  0.6371565163135529\n",
      "Iter:38 train_rmse:5.232 test_loss:393.0 test_rmse:0.06531 test_acc:0.6068\n",
      "Epoch  39\n",
      "Accuracy ---->  0.6376782059669495\n",
      "Iter:39 train_rmse:5.224 test_loss:392.4 test_rmse:0.06525 test_acc:0.6071\n",
      "Epoch  40\n",
      "Accuracy ---->  0.6381568610668182\n",
      "Iter:40 train_rmse:5.217 test_loss:391.6 test_rmse:0.06519 test_acc:0.6075\n",
      "Epoch  41\n",
      "Accuracy ---->  0.6386071443557739\n",
      "Iter:41 train_rmse:5.211 test_loss:390.9 test_rmse:0.06513 test_acc:0.6079\n",
      "Epoch  42\n",
      "Accuracy ---->  0.639040619134903\n",
      "Iter:42 train_rmse:5.205 test_loss:390.2 test_rmse:0.06507 test_acc:0.6082\n",
      "Epoch  43\n",
      "Accuracy ---->  0.6394654810428619\n",
      "Iter:43 train_rmse:5.198 test_loss:389.5 test_rmse:0.06501 test_acc:0.6086\n",
      "Epoch  44\n",
      "Accuracy ---->  0.639886349439621\n",
      "Iter:44 train_rmse:5.192 test_loss:388.8 test_rmse:0.06496 test_acc:0.6089\n",
      "Epoch  45\n",
      "Accuracy ---->  0.6403022706508636\n",
      "Iter:45 train_rmse:5.186 test_loss:388.2 test_rmse:0.0649 test_acc:0.6092\n",
      "Epoch  46\n",
      "Accuracy ---->  0.6407075524330139\n",
      "Iter:46 train_rmse:5.181 test_loss:387.5 test_rmse:0.06485 test_acc:0.6096\n",
      "Epoch  47\n",
      "Accuracy ---->  0.6410947740077972\n",
      "Iter:47 train_rmse:5.175 test_loss:386.9 test_rmse:0.06479 test_acc:0.6099\n",
      "Epoch  48\n",
      "Accuracy ---->  0.6414591670036316\n",
      "Iter:48 train_rmse:5.17 test_loss:386.2 test_rmse:0.06474 test_acc:0.6102\n",
      "Epoch  49\n",
      "Accuracy ---->  0.641802579164505\n",
      "Iter:49 train_rmse:5.165 test_loss:385.5 test_rmse:0.06468 test_acc:0.6106\n",
      "Epoch  50\n",
      "Accuracy ---->  0.6421332061290741\n",
      "Iter:50 train_rmse:5.16 test_loss:384.8 test_rmse:0.06461 test_acc:0.611\n",
      "Epoch  51\n",
      "Accuracy ---->  0.6424612700939178\n",
      "Iter:51 train_rmse:5.155 test_loss:384.0 test_rmse:0.06455 test_acc:0.6114\n",
      "Epoch  52\n",
      "Accuracy ---->  0.6427953541278839\n",
      "Iter:52 train_rmse:5.15 test_loss:383.2 test_rmse:0.06448 test_acc:0.6118\n",
      "Epoch  53\n",
      "Accuracy ---->  0.6431440114974976\n",
      "Iter:53 train_rmse:5.145 test_loss:382.4 test_rmse:0.06441 test_acc:0.6122\n",
      "Epoch  54\n",
      "Accuracy ---->  0.6435157060623169\n",
      "Iter:54 train_rmse:5.14 test_loss:381.6 test_rmse:0.06434 test_acc:0.6126\n",
      "Epoch  55\n",
      "Accuracy ---->  0.6439156830310822\n",
      "Iter:55 train_rmse:5.134 test_loss:380.7 test_rmse:0.06427 test_acc:0.613\n",
      "Epoch  56\n",
      "Accuracy ---->  0.6443447768688202\n",
      "Iter:56 train_rmse:5.128 test_loss:379.9 test_rmse:0.0642 test_acc:0.6135\n",
      "Epoch  57\n",
      "Accuracy ---->  0.6448020339012146\n",
      "Iter:57 train_rmse:5.121 test_loss:379.0 test_rmse:0.06413 test_acc:0.6139\n",
      "Epoch  58\n",
      "Accuracy ---->  0.6452862322330475\n",
      "Iter:58 train_rmse:5.115 test_loss:378.2 test_rmse:0.06405 test_acc:0.6144\n",
      "Epoch  59\n",
      "Accuracy ---->  0.6457982659339905\n",
      "Iter:59 train_rmse:5.107 test_loss:377.3 test_rmse:0.06397 test_acc:0.6148\n",
      "Epoch  60\n",
      "Accuracy ---->  0.6463409960269928\n",
      "Iter:60 train_rmse:5.099 test_loss:376.3 test_rmse:0.06389 test_acc:0.6153\n",
      "Epoch  61\n",
      "Accuracy ---->  0.646917313337326\n",
      "Iter:61 train_rmse:5.091 test_loss:375.4 test_rmse:0.06381 test_acc:0.6158\n",
      "Epoch  62\n",
      "Accuracy ---->  0.6475283205509186\n",
      "Iter:62 train_rmse:5.082 test_loss:374.4 test_rmse:0.06373 test_acc:0.6163\n",
      "Epoch  63\n",
      "Accuracy ---->  0.6481722891330719\n",
      "Iter:63 train_rmse:5.073 test_loss:373.4 test_rmse:0.06364 test_acc:0.6169\n",
      "Epoch  64\n",
      "Accuracy ---->  0.6488450467586517\n",
      "Iter:64 train_rmse:5.063 test_loss:372.3 test_rmse:0.06355 test_acc:0.6174\n",
      "Epoch  65\n",
      "Accuracy ---->  0.6495415270328522\n",
      "Iter:65 train_rmse:5.053 test_loss:371.1 test_rmse:0.06345 test_acc:0.618\n",
      "Epoch  66\n",
      "Accuracy ---->  0.6502571105957031\n",
      "Iter:66 train_rmse:5.043 test_loss:370.0 test_rmse:0.06335 test_acc:0.6186\n",
      "Epoch  67\n",
      "Accuracy ---->  0.6509879529476166\n",
      "Iter:67 train_rmse:5.032 test_loss:368.7 test_rmse:0.06324 test_acc:0.6193\n",
      "Epoch  68\n",
      "Accuracy ---->  0.6517306268215179\n",
      "Iter:68 train_rmse:5.022 test_loss:367.5 test_rmse:0.06313 test_acc:0.6199\n",
      "Epoch  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6524823307991028\n",
      "Iter:69 train_rmse:5.011 test_loss:366.2 test_rmse:0.06302 test_acc:0.6206\n",
      "Epoch  70\n",
      "Accuracy ---->  0.6532422304153442\n",
      "Iter:70 train_rmse:5.0 test_loss:364.8 test_rmse:0.0629 test_acc:0.6213\n",
      "Epoch  71\n",
      "Accuracy ---->  0.6540099084377289\n",
      "Iter:71 train_rmse:4.989 test_loss:363.5 test_rmse:0.06278 test_acc:0.622\n",
      "Epoch  72\n",
      "Accuracy ---->  0.6547838449478149\n",
      "Iter:72 train_rmse:4.978 test_loss:362.1 test_rmse:0.06266 test_acc:0.6227\n",
      "Epoch  73\n",
      "Accuracy ---->  0.6555603444576263\n",
      "Iter:73 train_rmse:4.966 test_loss:360.7 test_rmse:0.06254 test_acc:0.6234\n",
      "Epoch  74\n",
      "Accuracy ---->  0.6563359200954437\n",
      "Iter:74 train_rmse:4.955 test_loss:359.4 test_rmse:0.06242 test_acc:0.6242\n",
      "Epoch  75\n",
      "Accuracy ---->  0.6571097373962402\n",
      "Iter:75 train_rmse:4.944 test_loss:358.0 test_rmse:0.0623 test_acc:0.6249\n",
      "Epoch  76\n",
      "Accuracy ---->  0.6578827500343323\n",
      "Iter:76 train_rmse:4.933 test_loss:356.6 test_rmse:0.06218 test_acc:0.6256\n",
      "Epoch  77\n",
      "Accuracy ---->  0.6586531698703766\n",
      "Iter:77 train_rmse:4.922 test_loss:355.3 test_rmse:0.06206 test_acc:0.6263\n",
      "Epoch  78\n",
      "Accuracy ---->  0.65941521525383\n",
      "Iter:78 train_rmse:4.911 test_loss:354.0 test_rmse:0.06195 test_acc:0.627\n",
      "Epoch  79\n",
      "Accuracy ---->  0.6601627469062805\n",
      "Iter:79 train_rmse:4.9 test_loss:352.7 test_rmse:0.06184 test_acc:0.6277\n",
      "Epoch  80\n",
      "Accuracy ---->  0.6608904600143433\n",
      "Iter:80 train_rmse:4.89 test_loss:351.5 test_rmse:0.06173 test_acc:0.6284\n",
      "Epoch  81\n",
      "Accuracy ---->  0.6615930795669556\n",
      "Iter:81 train_rmse:4.879 test_loss:350.3 test_rmse:0.06162 test_acc:0.629\n",
      "Epoch  82\n",
      "Accuracy ---->  0.6622657179832458\n",
      "Iter:82 train_rmse:4.87 test_loss:349.1 test_rmse:0.06152 test_acc:0.6296\n",
      "Epoch  83\n",
      "Accuracy ---->  0.6629049777984619\n",
      "Iter:83 train_rmse:4.86 test_loss:348.0 test_rmse:0.06143 test_acc:0.6302\n",
      "Epoch  84\n",
      "Accuracy ---->  0.6635102331638336\n",
      "Iter:84 train_rmse:4.852 test_loss:347.0 test_rmse:0.06133 test_acc:0.6307\n",
      "Epoch  85\n",
      "Accuracy ---->  0.6640828251838684\n",
      "Iter:85 train_rmse:4.843 test_loss:346.0 test_rmse:0.06124 test_acc:0.6313\n",
      "Epoch  86\n",
      "Accuracy ---->  0.6646260917186737\n",
      "Iter:86 train_rmse:4.836 test_loss:345.1 test_rmse:0.06116 test_acc:0.6318\n",
      "Epoch  87\n",
      "Accuracy ---->  0.6651434004306793\n",
      "Iter:87 train_rmse:4.828 test_loss:344.1 test_rmse:0.06108 test_acc:0.6323\n",
      "Epoch  88\n",
      "Accuracy ---->  0.6656374931335449\n",
      "Iter:88 train_rmse:4.821 test_loss:343.3 test_rmse:0.061 test_acc:0.6327\n",
      "Epoch  89\n",
      "Accuracy ---->  0.6661101281642914\n",
      "Iter:89 train_rmse:4.814 test_loss:342.4 test_rmse:0.06093 test_acc:0.6332\n",
      "Epoch  90\n",
      "Accuracy ---->  0.6665624678134918\n",
      "Iter:90 train_rmse:4.808 test_loss:341.7 test_rmse:0.06086 test_acc:0.6336\n",
      "Epoch  91\n",
      "Accuracy ---->  0.6669950783252716\n",
      "Iter:91 train_rmse:4.802 test_loss:340.9 test_rmse:0.06079 test_acc:0.634\n",
      "Epoch  92\n",
      "Accuracy ---->  0.6674084961414337\n",
      "Iter:92 train_rmse:4.796 test_loss:340.2 test_rmse:0.06073 test_acc:0.6344\n",
      "Epoch  93\n",
      "Accuracy ---->  0.667803168296814\n",
      "Iter:93 train_rmse:4.79 test_loss:339.5 test_rmse:0.06067 test_acc:0.6347\n",
      "Epoch  94\n",
      "Accuracy ---->  0.6681792140007019\n",
      "Iter:94 train_rmse:4.784 test_loss:338.9 test_rmse:0.06061 test_acc:0.6351\n",
      "Epoch  95\n",
      "Accuracy ---->  0.6685375869274139\n",
      "Iter:95 train_rmse:4.779 test_loss:338.3 test_rmse:0.06056 test_acc:0.6354\n",
      "Epoch  96\n",
      "Accuracy ---->  0.6688795983791351\n",
      "Iter:96 train_rmse:4.774 test_loss:337.7 test_rmse:0.0605 test_acc:0.6357\n",
      "Epoch  97\n",
      "Accuracy ---->  0.669207364320755\n",
      "Iter:97 train_rmse:4.77 test_loss:337.2 test_rmse:0.06046 test_acc:0.636\n",
      "Epoch  98\n",
      "Accuracy ---->  0.6695234179496765\n",
      "Iter:98 train_rmse:4.765 test_loss:336.7 test_rmse:0.06041 test_acc:0.6363\n",
      "Epoch  99\n",
      "Accuracy ---->  0.669829785823822\n",
      "Iter:99 train_rmse:4.761 test_loss:336.2 test_rmse:0.06036 test_acc:0.6366\n",
      "Epoch  100\n",
      "Accuracy ---->  0.6701285541057587\n",
      "Iter:100 train_rmse:4.756 test_loss:335.7 test_rmse:0.06032 test_acc:0.6368\n",
      "Epoch  101\n",
      "Accuracy ---->  0.6704212129116058\n",
      "Iter:101 train_rmse:4.752 test_loss:335.2 test_rmse:0.06028 test_acc:0.6371\n",
      "Epoch  102\n",
      "Accuracy ---->  0.6707085072994232\n",
      "Iter:102 train_rmse:4.748 test_loss:334.8 test_rmse:0.06024 test_acc:0.6373\n",
      "Epoch  103\n",
      "Accuracy ---->  0.6709912419319153\n",
      "Iter:103 train_rmse:4.744 test_loss:334.4 test_rmse:0.0602 test_acc:0.6375\n",
      "Epoch  104\n",
      "Accuracy ---->  0.6712695360183716\n",
      "Iter:104 train_rmse:4.74 test_loss:334.0 test_rmse:0.06017 test_acc:0.6378\n",
      "Epoch  105\n",
      "Accuracy ---->  0.6715434491634369\n",
      "Iter:105 train_rmse:4.736 test_loss:333.6 test_rmse:0.06013 test_acc:0.638\n",
      "Epoch  106\n",
      "Accuracy ---->  0.6718131601810455\n",
      "Iter:106 train_rmse:4.732 test_loss:333.2 test_rmse:0.0601 test_acc:0.6382\n",
      "Epoch  107\n",
      "Accuracy ---->  0.6720785200595856\n",
      "Iter:107 train_rmse:4.728 test_loss:332.9 test_rmse:0.06007 test_acc:0.6384\n",
      "Epoch  108\n",
      "Accuracy ---->  0.6723396182060242\n",
      "Iter:108 train_rmse:4.724 test_loss:332.5 test_rmse:0.06003 test_acc:0.6386\n",
      "Epoch  109\n",
      "Accuracy ---->  0.672596275806427\n",
      "Iter:109 train_rmse:4.721 test_loss:332.2 test_rmse:0.06 test_acc:0.6387\n",
      "Epoch  110\n",
      "Accuracy ---->  0.6728486120700836\n",
      "Iter:110 train_rmse:4.717 test_loss:331.8 test_rmse:0.05997 test_acc:0.6389\n",
      "Epoch  111\n",
      "Accuracy ---->  0.6730963587760925\n",
      "Iter:111 train_rmse:4.714 test_loss:331.5 test_rmse:0.05994 test_acc:0.6391\n",
      "Epoch  112\n",
      "Accuracy ---->  0.6733395159244537\n",
      "Iter:112 train_rmse:4.71 test_loss:331.2 test_rmse:0.05991 test_acc:0.6393\n",
      "Epoch  113\n",
      "Accuracy ---->  0.6735779345035553\n",
      "Iter:113 train_rmse:4.707 test_loss:330.9 test_rmse:0.05989 test_acc:0.6394\n",
      "Epoch  114\n",
      "Accuracy ---->  0.6738113462924957\n",
      "Iter:114 train_rmse:4.703 test_loss:330.6 test_rmse:0.05986 test_acc:0.6396\n",
      "Epoch  115\n",
      "Accuracy ---->  0.6740395426750183\n",
      "Iter:115 train_rmse:4.7 test_loss:330.3 test_rmse:0.05983 test_acc:0.6398\n",
      "Epoch  116\n",
      "Accuracy ---->  0.6742624342441559\n",
      "Iter:116 train_rmse:4.697 test_loss:330.0 test_rmse:0.0598 test_acc:0.6399\n",
      "Epoch  117\n",
      "Accuracy ---->  0.6744797229766846\n",
      "Iter:117 train_rmse:4.694 test_loss:329.7 test_rmse:0.05978 test_acc:0.6401\n",
      "Epoch  118\n",
      "Accuracy ---->  0.6746911108493805\n",
      "Iter:118 train_rmse:4.691 test_loss:329.4 test_rmse:0.05975 test_acc:0.6402\n",
      "Epoch  119\n",
      "Accuracy ---->  0.6748964488506317\n",
      "Iter:119 train_rmse:4.688 test_loss:329.2 test_rmse:0.05973 test_acc:0.6404\n",
      "Epoch  120\n",
      "Accuracy ---->  0.6750958263874054\n",
      "Iter:120 train_rmse:4.685 test_loss:328.9 test_rmse:0.05971 test_acc:0.6405\n",
      "Epoch  121\n",
      "Accuracy ---->  0.675289124250412\n",
      "Iter:121 train_rmse:4.682 test_loss:328.6 test_rmse:0.05968 test_acc:0.6407\n",
      "Epoch  122\n",
      "Accuracy ---->  0.6754766404628754\n",
      "Iter:122 train_rmse:4.679 test_loss:328.4 test_rmse:0.05966 test_acc:0.6408\n",
      "Epoch  123\n",
      "Accuracy ---->  0.6756588518619537\n",
      "Iter:123 train_rmse:4.677 test_loss:328.1 test_rmse:0.05964 test_acc:0.6409\n",
      "Epoch  124\n",
      "Accuracy ---->  0.6758361756801605\n",
      "Iter:124 train_rmse:4.674 test_loss:327.9 test_rmse:0.05961 test_acc:0.6411\n",
      "Epoch  125\n",
      "Accuracy ---->  0.6760092675685883\n",
      "Iter:125 train_rmse:4.672 test_loss:327.7 test_rmse:0.05959 test_acc:0.6412\n",
      "Epoch  126\n",
      "Accuracy ---->  0.6761790215969086\n",
      "Iter:126 train_rmse:4.669 test_loss:327.4 test_rmse:0.05957 test_acc:0.6413\n",
      "Epoch  127\n",
      "Accuracy ---->  0.6763462126255035\n",
      "Iter:127 train_rmse:4.667 test_loss:327.2 test_rmse:0.05955 test_acc:0.6415\n",
      "Epoch  128\n",
      "Accuracy ---->  0.6765116453170776\n",
      "Iter:128 train_rmse:4.664 test_loss:327.0 test_rmse:0.05953 test_acc:0.6416\n",
      "Epoch  129\n",
      "Accuracy ---->  0.6766760647296906\n",
      "Iter:129 train_rmse:4.662 test_loss:326.8 test_rmse:0.05951 test_acc:0.6417\n",
      "Epoch  130\n",
      "Accuracy ---->  0.6768401861190796\n",
      "Iter:130 train_rmse:4.66 test_loss:326.6 test_rmse:0.0595 test_acc:0.6418\n",
      "Epoch  131\n",
      "Accuracy ---->  0.6770047843456268\n",
      "Iter:131 train_rmse:4.657 test_loss:326.4 test_rmse:0.05948 test_acc:0.6419\n",
      "Epoch  132\n",
      "Accuracy ---->  0.6771705150604248\n",
      "Iter:132 train_rmse:4.655 test_loss:326.2 test_rmse:0.05946 test_acc:0.642\n",
      "Epoch  133\n",
      "Accuracy ---->  0.6773376166820526\n",
      "Iter:133 train_rmse:4.652 test_loss:326.1 test_rmse:0.05945 test_acc:0.6421\n",
      "Epoch  134\n",
      "Accuracy ---->  0.677506148815155\n",
      "Iter:134 train_rmse:4.65 test_loss:325.9 test_rmse:0.05943 test_acc:0.6422\n",
      "Epoch  135\n",
      "Accuracy ---->  0.6776756346225739\n",
      "Iter:135 train_rmse:4.648 test_loss:325.7 test_rmse:0.05942 test_acc:0.6423\n",
      "Epoch  136\n",
      "Accuracy ---->  0.6778442859649658\n",
      "Iter:136 train_rmse:4.645 test_loss:325.6 test_rmse:0.0594 test_acc:0.6424\n",
      "Epoch  137\n",
      "Accuracy ---->  0.6780082881450653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:137 train_rmse:4.643 test_loss:325.4 test_rmse:0.05939 test_acc:0.6424\n",
      "Epoch  138\n",
      "Accuracy ---->  0.6781609356403351\n",
      "Iter:138 train_rmse:4.641 test_loss:325.2 test_rmse:0.05937 test_acc:0.6425\n",
      "Epoch  139\n",
      "Accuracy ---->  0.6782919466495514\n",
      "Iter:139 train_rmse:4.639 test_loss:325.0 test_rmse:0.05935 test_acc:0.6427\n",
      "Epoch  140\n",
      "Accuracy ---->  0.6783902943134308\n",
      "Iter:140 train_rmse:4.637 test_loss:324.7 test_rmse:0.05932 test_acc:0.6428\n",
      "Epoch  141\n",
      "Accuracy ---->  0.6784535348415375\n",
      "Iter:141 train_rmse:4.636 test_loss:324.3 test_rmse:0.05929 test_acc:0.6431\n",
      "Epoch  142\n",
      "Accuracy ---->  0.6785008907318115\n",
      "Iter:142 train_rmse:4.636 test_loss:323.9 test_rmse:0.05925 test_acc:0.6433\n",
      "Epoch  143\n",
      "Accuracy ---->  0.6785703301429749\n",
      "Iter:143 train_rmse:4.635 test_loss:323.5 test_rmse:0.05921 test_acc:0.6435\n",
      "Epoch  144\n",
      "Accuracy ---->  0.6786833703517914\n",
      "Iter:144 train_rmse:4.633 test_loss:323.2 test_rmse:0.05918 test_acc:0.6437\n",
      "Epoch  145\n",
      "Accuracy ---->  0.6788252592086792\n",
      "Iter:145 train_rmse:4.631 test_loss:322.9 test_rmse:0.05916 test_acc:0.6438\n",
      "Epoch  146\n",
      "Accuracy ---->  0.6789722442626953\n",
      "Iter:146 train_rmse:4.629 test_loss:322.7 test_rmse:0.05914 test_acc:0.6439\n",
      "Epoch  147\n",
      "Accuracy ---->  0.6791136264801025\n",
      "Iter:147 train_rmse:4.627 test_loss:322.5 test_rmse:0.05912 test_acc:0.6441\n",
      "Epoch  148\n",
      "Accuracy ---->  0.6792485117912292\n",
      "Iter:148 train_rmse:4.625 test_loss:322.3 test_rmse:0.0591 test_acc:0.6442\n",
      "Epoch  149\n",
      "Accuracy ---->  0.6793787181377411\n",
      "Iter:149 train_rmse:4.623 test_loss:322.1 test_rmse:0.05908 test_acc:0.6443\n",
      "Epoch  150\n",
      "Accuracy ---->  0.6795057654380798\n",
      "Iter:150 train_rmse:4.621 test_loss:321.9 test_rmse:0.05906 test_acc:0.6444\n",
      "Epoch  151\n",
      "Accuracy ---->  0.679630696773529\n",
      "Iter:151 train_rmse:4.619 test_loss:321.7 test_rmse:0.05904 test_acc:0.6445\n",
      "Epoch  152\n",
      "Accuracy ---->  0.6797541975975037\n",
      "Iter:152 train_rmse:4.618 test_loss:321.5 test_rmse:0.05902 test_acc:0.6446\n",
      "Epoch  153\n",
      "Accuracy ---->  0.6798765957355499\n",
      "Iter:153 train_rmse:4.616 test_loss:321.2 test_rmse:0.05901 test_acc:0.6447\n",
      "Epoch  154\n",
      "Accuracy ---->  0.6799982190132141\n",
      "Iter:154 train_rmse:4.614 test_loss:321.0 test_rmse:0.05899 test_acc:0.6449\n",
      "Epoch  155\n",
      "Accuracy ---->  0.680119127035141\n",
      "Iter:155 train_rmse:4.612 test_loss:320.8 test_rmse:0.05897 test_acc:0.645\n",
      "Epoch  156\n",
      "Accuracy ---->  0.6802394688129425\n",
      "Iter:156 train_rmse:4.611 test_loss:320.6 test_rmse:0.05895 test_acc:0.6451\n",
      "Epoch  157\n",
      "Accuracy ---->  0.6803592443466187\n",
      "Iter:157 train_rmse:4.609 test_loss:320.4 test_rmse:0.05893 test_acc:0.6452\n",
      "Epoch  158\n",
      "Accuracy ---->  0.6804785430431366\n",
      "Iter:158 train_rmse:4.607 test_loss:320.2 test_rmse:0.05891 test_acc:0.6453\n",
      "Epoch  159\n",
      "Accuracy ---->  0.6805974841117859\n",
      "Iter:159 train_rmse:4.605 test_loss:319.9 test_rmse:0.05889 test_acc:0.6455\n",
      "Epoch  160\n",
      "Accuracy ---->  0.680715948343277\n",
      "Iter:160 train_rmse:4.604 test_loss:319.7 test_rmse:0.05886 test_acc:0.6456\n",
      "Epoch  161\n",
      "Accuracy ---->  0.680834025144577\n",
      "Iter:161 train_rmse:4.602 test_loss:319.5 test_rmse:0.05884 test_acc:0.6457\n",
      "Epoch  162\n",
      "Accuracy ---->  0.6809517443180084\n",
      "Iter:162 train_rmse:4.6 test_loss:319.3 test_rmse:0.05882 test_acc:0.6458\n",
      "Epoch  163\n",
      "Accuracy ---->  0.6810690760612488\n",
      "Iter:163 train_rmse:4.599 test_loss:319.1 test_rmse:0.0588 test_acc:0.646\n",
      "Epoch  164\n",
      "Accuracy ---->  0.6811860203742981\n",
      "Iter:164 train_rmse:4.597 test_loss:318.8 test_rmse:0.05878 test_acc:0.6461\n",
      "Epoch  165\n",
      "Accuracy ---->  0.6813026070594788\n",
      "Iter:165 train_rmse:4.595 test_loss:318.6 test_rmse:0.05876 test_acc:0.6462\n",
      "Epoch  166\n",
      "Accuracy ---->  0.6814187467098236\n",
      "Iter:166 train_rmse:4.594 test_loss:318.4 test_rmse:0.05874 test_acc:0.6463\n",
      "Epoch  167\n",
      "Accuracy ---->  0.6815344989299774\n",
      "Iter:167 train_rmse:4.592 test_loss:318.2 test_rmse:0.05872 test_acc:0.6465\n",
      "Epoch  168\n",
      "Accuracy ---->  0.6816498637199402\n",
      "Iter:168 train_rmse:4.59 test_loss:317.9 test_rmse:0.0587 test_acc:0.6466\n",
      "Epoch  169\n",
      "Accuracy ---->  0.6817646324634552\n",
      "Iter:169 train_rmse:4.589 test_loss:317.7 test_rmse:0.05868 test_acc:0.6467\n",
      "Epoch  170\n",
      "Accuracy ---->  0.6818791031837463\n",
      "Iter:170 train_rmse:4.587 test_loss:317.5 test_rmse:0.05866 test_acc:0.6469\n",
      "Epoch  171\n",
      "Accuracy ---->  0.6819929480552673\n",
      "Iter:171 train_rmse:4.585 test_loss:317.2 test_rmse:0.05863 test_acc:0.647\n",
      "Epoch  172\n",
      "Accuracy ---->  0.6821062564849854\n",
      "Iter:172 train_rmse:4.584 test_loss:317.0 test_rmse:0.05861 test_acc:0.6471\n",
      "Epoch  173\n",
      "Accuracy ---->  0.6822190582752228\n",
      "Iter:173 train_rmse:4.582 test_loss:316.8 test_rmse:0.05859 test_acc:0.6472\n",
      "Epoch  174\n",
      "Accuracy ---->  0.6823313236236572\n",
      "Iter:174 train_rmse:4.58 test_loss:316.6 test_rmse:0.05857 test_acc:0.6474\n",
      "Epoch  175\n",
      "Accuracy ---->  0.6824429631233215\n",
      "Iter:175 train_rmse:4.579 test_loss:316.3 test_rmse:0.05855 test_acc:0.6475\n",
      "Epoch  176\n",
      "Accuracy ---->  0.6825540661811829\n",
      "Iter:176 train_rmse:4.577 test_loss:316.1 test_rmse:0.05853 test_acc:0.6476\n",
      "Epoch  177\n",
      "Accuracy ---->  0.6826644837856293\n",
      "Iter:177 train_rmse:4.576 test_loss:315.9 test_rmse:0.05851 test_acc:0.6477\n",
      "Epoch  178\n",
      "Accuracy ---->  0.6827743947505951\n",
      "Iter:178 train_rmse:4.574 test_loss:315.7 test_rmse:0.05849 test_acc:0.6479\n",
      "Epoch  179\n",
      "Accuracy ---->  0.6828837096691132\n",
      "Iter:179 train_rmse:4.572 test_loss:315.4 test_rmse:0.05847 test_acc:0.648\n",
      "Epoch  180\n",
      "Accuracy ---->  0.6829924881458282\n",
      "Iter:180 train_rmse:4.571 test_loss:315.2 test_rmse:0.05844 test_acc:0.6481\n",
      "Epoch  181\n",
      "Accuracy ---->  0.6831007301807404\n",
      "Iter:181 train_rmse:4.569 test_loss:315.0 test_rmse:0.05842 test_acc:0.6482\n",
      "Epoch  182\n",
      "Accuracy ---->  0.6832084953784943\n",
      "Iter:182 train_rmse:4.568 test_loss:314.8 test_rmse:0.0584 test_acc:0.6484\n",
      "Epoch  183\n",
      "Accuracy ---->  0.6833158433437347\n",
      "Iter:183 train_rmse:4.566 test_loss:314.5 test_rmse:0.05838 test_acc:0.6485\n",
      "Epoch  184\n",
      "Accuracy ---->  0.6834227442741394\n",
      "Iter:184 train_rmse:4.565 test_loss:314.3 test_rmse:0.05836 test_acc:0.6486\n",
      "Epoch  185\n",
      "Accuracy ---->  0.6835294365882874\n",
      "Iter:185 train_rmse:4.563 test_loss:314.1 test_rmse:0.05834 test_acc:0.6488\n",
      "Epoch  186\n",
      "Accuracy ---->  0.6836358308792114\n",
      "Iter:186 train_rmse:4.562 test_loss:313.9 test_rmse:0.05832 test_acc:0.6489\n",
      "Epoch  187\n",
      "Accuracy ---->  0.6837421655654907\n",
      "Iter:187 train_rmse:4.56 test_loss:313.6 test_rmse:0.0583 test_acc:0.649\n",
      "Epoch  188\n",
      "Accuracy ---->  0.6838484704494476\n",
      "Iter:188 train_rmse:4.559 test_loss:313.4 test_rmse:0.05828 test_acc:0.6491\n",
      "Epoch  189\n",
      "Accuracy ---->  0.6839548647403717\n",
      "Iter:189 train_rmse:4.557 test_loss:313.2 test_rmse:0.05826 test_acc:0.6493\n",
      "Epoch  190\n",
      "Accuracy ---->  0.6840614974498749\n",
      "Iter:190 train_rmse:4.555 test_loss:313.0 test_rmse:0.05824 test_acc:0.6494\n",
      "Epoch  191\n",
      "Accuracy ---->  0.6841684877872467\n",
      "Iter:191 train_rmse:4.554 test_loss:312.8 test_rmse:0.05822 test_acc:0.6495\n",
      "Epoch  192\n",
      "Accuracy ---->  0.684275895357132\n",
      "Iter:192 train_rmse:4.552 test_loss:312.5 test_rmse:0.0582 test_acc:0.6496\n",
      "Epoch  193\n",
      "Accuracy ---->  0.684383898973465\n",
      "Iter:193 train_rmse:4.551 test_loss:312.3 test_rmse:0.05817 test_acc:0.6497\n",
      "Epoch  194\n",
      "Accuracy ---->  0.6844926178455353\n",
      "Iter:194 train_rmse:4.549 test_loss:312.1 test_rmse:0.05815 test_acc:0.6499\n",
      "Epoch  195\n",
      "Accuracy ---->  0.6846020519733429\n",
      "Iter:195 train_rmse:4.548 test_loss:311.9 test_rmse:0.05813 test_acc:0.65\n",
      "Epoch  196\n",
      "Accuracy ---->  0.6847125291824341\n",
      "Iter:196 train_rmse:4.546 test_loss:311.6 test_rmse:0.05811 test_acc:0.6501\n",
      "Epoch  197\n",
      "Accuracy ---->  0.6848238408565521\n",
      "Iter:197 train_rmse:4.544 test_loss:311.4 test_rmse:0.05809 test_acc:0.6502\n",
      "Epoch  198\n",
      "Accuracy ---->  0.6849362850189209\n",
      "Iter:198 train_rmse:4.543 test_loss:311.2 test_rmse:0.05807 test_acc:0.6504\n",
      "Epoch  199\n",
      "Accuracy ---->  0.6850497126579285\n",
      "Iter:199 train_rmse:4.541 test_loss:311.0 test_rmse:0.05805 test_acc:0.6505\n",
      "Epoch  200\n",
      "Accuracy ---->  0.6851643025875092\n",
      "Iter:200 train_rmse:4.54 test_loss:310.8 test_rmse:0.05803 test_acc:0.6506\n",
      "Epoch  201\n",
      "Accuracy ---->  0.6852798759937286\n",
      "Iter:201 train_rmse:4.538 test_loss:310.5 test_rmse:0.05801 test_acc:0.6507\n",
      "Epoch  202\n",
      "Accuracy ---->  0.6853966414928436\n",
      "Iter:202 train_rmse:4.536 test_loss:310.3 test_rmse:0.05799 test_acc:0.6509\n",
      "Epoch  203\n",
      "Accuracy ---->  0.6855143904685974\n",
      "Iter:203 train_rmse:4.534 test_loss:310.1 test_rmse:0.05797 test_acc:0.651\n",
      "Epoch  204\n",
      "Accuracy ---->  0.6856332123279572\n",
      "Iter:204 train_rmse:4.533 test_loss:309.9 test_rmse:0.05795 test_acc:0.6511\n",
      "Epoch  205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ---->  0.6857529282569885\n",
      "Iter:205 train_rmse:4.531 test_loss:309.7 test_rmse:0.05793 test_acc:0.6512\n",
      "Epoch  206\n",
      "Accuracy ---->  0.6858735978603363\n",
      "Iter:206 train_rmse:4.529 test_loss:309.4 test_rmse:0.0579 test_acc:0.6514\n",
      "Epoch  207\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epoch):\n",
    "    print(\"Epoch \", epoch)\n",
    "    for m in range(totalbatch):\n",
    "        mini_batch = trainX[m * batch_size : (m+1) * batch_size]\n",
    "        mini_label = trainY[m * batch_size : (m+1) * batch_size]\n",
    "        _, loss1, rmse1, train_output = sess.run([optimizer, loss, error, y_pred],\n",
    "                                                 feed_dict = {inputs:mini_batch, labels:mini_label})\n",
    "        batch_loss.append(loss1)\n",
    "        batch_rmse.append(rmse1 * max_value)\n",
    "        train_label=np.reshape(mini_label,[-1,num_nodes])\n",
    "     #print(mini_label.shape,train_output.shape) (32, 1, 156) (32, 156)\n",
    "     # Test completely at every epoch\n",
    "    print(\"Accuracy ----> \", evaluation(train_label,train_output)[2])\n",
    "    loss2, rmse2, test_output = sess.run([loss, error, y_pred],\n",
    "                                         feed_dict = {inputs:testX, labels:testY})\n",
    "    #train_label=np.reshape(trainY,[-1,num_nodes])\n",
    "    #train_acc=acc(train_label,train_output)\n",
    "    test_label = np.reshape(testY,[-1,num_nodes])\n",
    "    rmse, mae, acc, r2_score, var_score = evaluation(test_label, test_output)\n",
    "    test_label1 = test_label * max_value#Inverse normalization\n",
    "    test_output1 = test_output * max_value\n",
    "    test_loss.append(loss2)\n",
    "    test_rmse.append(rmse * max_value)\n",
    "    test_mae.append(mae * max_value)\n",
    "    test_acc.append(acc)\n",
    "    test_r2.append(r2_score)\n",
    "    test_var.append(var_score)\n",
    "    test_pred.append(test_output1)\n",
    "    #print(mini_label.shape,train_output.shape)\n",
    "    print('Iter:{}'.format(epoch),\n",
    "          'train_rmse:{:.4}'.format(batch_rmse[-1]),\n",
    "          'test_loss:{:.4}'.format(loss2),\n",
    "          'test_rmse:{:.4}'.format(rmse),\n",
    "          'test_acc:{:.4}'.format(acc))\n",
    "    if (epoch % 500 == 0):        \n",
    "        saver.save(sess, path+'/model_10030TGCN_pre_%r'%epoch, global_step = epoch)\n",
    "        \n",
    "time_end = time.time()\n",
    "print('Time taken : ',time_end-time_start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = int(len(batch_rmse)/totalbatch)\n",
    "batch_rmse1 = [i for i in batch_rmse]\n",
    "train_rmse = [(sum(batch_rmse1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "batch_loss1 = [i for i in batch_loss]\n",
    "train_loss = [(sum(batch_loss1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "\n",
    "index = test_rmse.index(np.min(test_rmse))\n",
    "test_result = test_pred[index]\n",
    "var = pd.DataFrame(test_result)\n",
    "var.to_csv(path+'/test_result30.csv',index = False,header = False)\n",
    "#plot_result(test_result,test_label1,path)\n",
    "#plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing:\")\n",
    "print('min_rmse:%r'%(np.min(test_rmse)),\n",
    "      'min_mae:%r'%(test_mae[index]),\n",
    "      'max_acc:%r'%(test_acc[index]),\n",
    "      'r2:%r'%(test_r2[index]),\n",
    "      'var:%r'%test_var[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training:\")\n",
    "rmse, mae, acc, r2_score, var_score = evaluation(train_label,train_output)\n",
    "print('min_rmse:%r'%(rmse),\n",
    "      'min_mae:%r'%(mae),\n",
    "      'max_acc:%r'%(acc),\n",
    "      'r2:%r'%(r2_score),\n",
    "      'var:%r'%(var_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse normalisation\n",
    "print('min_rmse:%r'%(rmse*max_value),\n",
    "      'min_mae:%r'%(mae*max_value),\n",
    "      'max_acc:%r'%(acc),\n",
    "      'r2:%r'%(r2_score),\n",
    "      'var:%r'%(var_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(test_result,test_label1,path):\n",
    "    ##all test result visualization\n",
    "    fig1 = plt.figure(figsize=(7,1.5))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "    a_pred = test_result[:,0]\n",
    "    a_true = test_label1[:,0]\n",
    "    plt.plot(a_pred,'r-',label='prediction')\n",
    "    plt.plot(a_true,'b-',label='true')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_all.jpg')\n",
    "    plt.show()\n",
    "    ## oneday test result visualization\n",
    "    fig1 = plt.figure(figsize=(7,1.5))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "    a_pred = test_result[0:96,0]\n",
    "    a_true = test_label1[0:96,0]\n",
    "    plt.plot(a_pred,'r-',label=\"prediction\")\n",
    "    plt.plot(a_true,'b-',label=\"true\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_oneday.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path):\n",
    "    ###train_rmse & test_rmse \n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_rmse, 'r-', label=\"train_rmse\")\n",
    "    plt.plot(test_rmse, 'b-', label=\"test_rmse\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/rmse.jpg')\n",
    "    plt.show()\n",
    "    #### train_loss & train_rmse\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_loss,'b-', label='train_loss')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_loss.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_rmse,'b-', label='train_rmse')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_rmse.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    ### accuracy\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_acc, 'b-', label=\"test_acc\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_acc.jpg')\n",
    "    plt.show()\n",
    "    ### rmse\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_rmse, 'b-', label=\"test_rmse\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_rmse.jpg')\n",
    "    plt.show()\n",
    "    ### mae\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_mae, 'b-', label=\"test_mae\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_mae.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(test_result,test_label1,path)\n",
    "plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
